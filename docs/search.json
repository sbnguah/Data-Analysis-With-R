[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practical data analysis with R",
    "section": "",
    "text": "This compilation is dedicated to all who desire to learn!!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Practical data analysis with R</span>"
    ]
  },
  {
    "objectID": "missing-data.html",
    "href": "missing-data.html",
    "title": "2  Visualization",
    "section": "",
    "text": "2.1 Importing data\nCode\nlibrary(tidyverse)\ndf_hpt &lt;- \n    readxl::read_xlsx(path = \"C:/Dataset/hptdata.xlsx\") %&gt;% \n    janitor::clean_names() %&gt;% \n    mutate(\n        sex = factor(sex),\n        educ = factor(\n            educ, \n            levels = c(\"None\", \"Primary\", \"JHS/Form 4\", \"SHS/Secondary\", \"Tertiary\")\n            ),\n        hpt = case_when(\n            (syst1 &gt;= 140 | syst2 &gt;= 140 | diast1 &gt;= 90 | diast2 &gt;= 90) ~ \"Yes\",\n            (syst1 &lt; 140 & syst2 &lt; 140 & diast1 &lt; 90 & diast2 &lt; 90) ~ \"No\"\n            ) %&gt;% factor()\n        )",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Missiing Data</span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "missing-data.html#labelling-data",
    "href": "missing-data.html#labelling-data",
    "title": "2  Visualization",
    "section": "2.2 Labelling data",
    "text": "2.2 Labelling data\n\n\nCode\ndf_hpt &lt;- \n    df_hpt %&gt;% \n    labelled::set_variable_labels(\n        sid = \"Study ID\",\n        ageyrs = \"Age (years)\",\n        sex = \"Sex\",\n        educ = \"Educational level\",\n        wgt = \"Body Weight\",\n        waist = \"Waist circumference (cm)\",\n        hgt = \"Height (cm)\",\n        syst1 = \"Systolic BP 1st\",\n        diast1 = \"Diastolic BP 1st\",\n        syst2 = \"Systolic BP 2nd\",\n        diast2 = \"Diastolic BP 2nd\",\n        recdate = \"Record date\",\n        hpt = \"Hypertension\"\n    )",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Missiing Data</span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "missing-data.html#summarizing-data",
    "href": "missing-data.html#summarizing-data",
    "title": "2  Visualization",
    "section": "2.3 Summarizing data",
    "text": "2.3 Summarizing data\n\n\nCode\ndf_hpt %&gt;% \n    summarytools::dfSummary(graph.col = F, labels.col = F)\n\n\nData Frame Summary  \ndf_hpt  \nDimensions: 250 x 13  \nDuplicates: 0  \n\n-----------------------------------------------------------------------------------------------\nNo   Variable            Stats / Values              Freqs (% of Valid)    Valid      Missing  \n---- ------------------- --------------------------- --------------------- ---------- ---------\n1    sid                 1. H001                       1 ( 0.4%)           250        0        \n     [character]         2. H002                       1 ( 0.4%)           (100.0%)   (0.0%)   \n                         3. H003                       1 ( 0.4%)                               \n                         4. H004                       1 ( 0.4%)                               \n                         5. H005                       1 ( 0.4%)                               \n                         6. H006                       1 ( 0.4%)                               \n                         7. H007                       1 ( 0.4%)                               \n                         8. H008                       1 ( 0.4%)                               \n                         9. H009                       1 ( 0.4%)                               \n                         10. H010                      1 ( 0.4%)                               \n                         [ 240 others ]              240 (96.0%)                               \n\n2    ageyrs              Mean (sd) : 51.4 (18.7)     61 distinct values    250        0        \n     [numeric]           min &lt; med &lt; max:                                  (100.0%)   (0.0%)   \n                         18 &lt; 51 &lt; 94                                                          \n                         IQR (CV) : 28 (0.4)                                                   \n\n3    sex                 1. Female                   170 (68.8%)           247        3        \n     [factor]            2. Male                      77 (31.2%)           (98.8%)    (1.2%)   \n\n4    educ                1. None                     112 (45.0%)           249        1        \n     [factor]            2. Primary                   34 (13.7%)           (99.6%)    (0.4%)   \n                         3. JHS/Form 4                84 (33.7%)                               \n                         4. SHS/Secondary             15 ( 6.0%)                               \n                         5. Tertiary                   4 ( 1.6%)                               \n\n5    wgt                 Mean (sd) : 59.8 (12.8)     182 distinct values   246        4        \n     [numeric]           min &lt; med &lt; max:                                  (98.4%)    (1.6%)   \n                         35.5 &lt; 57.6 &lt; 105.2                                                   \n                         IQR (CV) : 17.3 (0.2)                                                 \n\n6    waist               Mean (sd) : 83 (11)         49 distinct values    249        1        \n     [numeric]           min &lt; med &lt; max:                                  (99.6%)    (0.4%)   \n                         64 &lt; 81 &lt; 114                                                         \n                         IQR (CV) : 15 (0.1)                                                   \n\n7    hgt                 Mean (sd) : 160.7 (12)      47 distinct values    248        2        \n     [numeric]           min &lt; med &lt; max:                                  (99.2%)    (0.8%)   \n                         67 &lt; 161 &lt; 184                                                        \n                         IQR (CV) : 10.5 (0.1)                                                 \n\n8    syst1               Mean (sd) : 132.3 (27.8)    98 distinct values    250        0        \n     [numeric]           min &lt; med &lt; max:                                  (100.0%)   (0.0%)   \n                         74 &lt; 128 &lt; 225                                                        \n                         IQR (CV) : 35.8 (0.2)                                                 \n\n9    diast1              Mean (sd) : 78.2 (16.4)     64 distinct values    247        3        \n     [numeric]           min &lt; med &lt; max:                                  (98.8%)    (1.2%)   \n                         49 &lt; 76 &lt; 160                                                         \n                         IQR (CV) : 20 (0.2)                                                   \n\n10   syst2               Mean (sd) : 131.6 (27.2)    94 distinct values    250        0        \n     [numeric]           min &lt; med &lt; max:                                  (100.0%)   (0.0%)   \n                         84 &lt; 127 &lt; 232                                                        \n                         IQR (CV) : 36 (0.2)                                                   \n\n11   diast2              Mean (sd) : 77.9 (15.8)     63 distinct values    247        3        \n     [numeric]           min &lt; med &lt; max:                                  (98.8%)    (1.2%)   \n                         50 &lt; 76 &lt; 150                                                         \n                         IQR (CV) : 18.5 (0.2)                                                 \n\n12   recdate             min : 2012-02-12            250 distinct values   250        0        \n     [POSIXct, POSIXt]   med : 2012-06-15 12:00:00                         (100.0%)   (0.0%)   \n                         max : 2012-10-18                                                      \n                         range : 8m 6d                                                         \n\n13   hpt                 1. No                       146 (58.6%)           249        1        \n     [factor]            2. Yes                      103 (41.4%)           (99.6%)    (0.4%)   \n-----------------------------------------------------------------------------------------------",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Missiing Data</span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "missing-data.html#viewing-missing-data-pattern",
    "href": "missing-data.html#viewing-missing-data-pattern",
    "title": "2  Visualization",
    "section": "2.4 Viewing missing data pattern",
    "text": "2.4 Viewing missing data pattern\n\n\nCode\ndf_hpt %&gt;% mice::md.pattern(rotate.names = T)\n\n\n    sid ageyrs syst1 syst2 recdate educ waist hpt hgt sex diast1 diast2 wgt   \n237   1      1     1     1       1    1     1   1   1   1      1      1   1  0\n1     1      1     1     1       1    1     1   1   1   1      1      1   0  1\n2     1      1     1     1       1    1     1   1   1   1      1      0   1  1\n1     1      1     1     1       1    1     1   1   1   1      1      0   0  2\n2     1      1     1     1       1    1     1   1   1   1      0      1   0  2\n2     1      1     1     1       1    1     1   1   1   0      1      1   1  1\n1     1      1     1     1       1    1     1   1   0   1      1      1   1  1\n1     1      1     1     1       1    1     1   1   0   0      1      1   1  2\n1     1      1     1     1       1    1     1   0   1   1      0      1   1  2\n1     1      1     1     1       1    1     0   1   1   1      1      1   1  1\n1     1      1     1     1       1    0     1   1   1   1      1      1   1  1\n      0      0     0     0       0    1     1   1   2   3      3      3   4 18\n\n\n\n\n\n\n\n\nFigure 2.1: Missing data pattern\n\n\n\n\n\n\n\nCode\ndf_hpt %&gt;% \n    visdat::vis_miss()\n\n\n\n\n\n\n\n\nFigure 2.2: Missing data pattern 2",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Missiing Data</span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "missing-data.html#regression-with-mice-imputation",
    "href": "missing-data.html#regression-with-mice-imputation",
    "title": "2  Visualization",
    "section": "2.5 Regression with mice imputation",
    "text": "2.5 Regression with mice imputation\n\n\nCode\ngtsummary::theme_gtsummary_compact()\n\n# Input the data\nimputed_data &lt;- \n    df_hpt %&gt;% \n    select(hpt, ageyrs, sex, waist, educ, wgt, hgt) %&gt;% \n    mice::mice(maxit = 20, m = 5,printFlag = F)\n\n# Visualize the 3rd og the 5 data sets created\nmice::complete(imputed_data, 4) %&gt;% \n    head() %&gt;% \n    gt::gt() %&gt;% \n    gt::opt_stylize(style = 3, color = \"blue\", add_row_striping = TRUE)\n\n\n\n\n\n\n\n\nhpt\nageyrs\nsex\nwaist\neduc\nwgt\nhgt\n\n\n\n\nYes\n84\nFemale\n83\nNone\n53.7\n153\n\n\nYes\n70\nFemale\n80\nNone\n55.3\n149\n\n\nYes\n55\nFemale\n113\nNone\n97.6\n162\n\n\nNo\n57\nMale\n76\nJHS/Form 4\n59.2\n172\n\n\nNo\n54\nMale\n78\nJHS/Form 4\n58.2\n168\n\n\nNo\n19\nFemale\n71\nSHS/Secondary\n54.9\n162\n\n\n\n\n\n\n\nCode\n# Create univariate table for original data set\ntbl1 &lt;- \n    df_hpt %&gt;% \n    gtsummary::tbl_uvregression(\n        include = c(ageyrs, sex, waist, educ, wgt, hgt),\n        y = hpt,\n        method = glm,\n        method.args = family(binomial),\n        exponentiate=TRUE,\n        pvalue_fun = function(x) gtsummary::style_pvalue(x, digits = 3)\n        ) %&gt;% \n    gtsummary::bold_labels() %&gt;% \n    gtsummary::bold_p()\ntbl1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOR\n1\n95% CI\n1\np-value\n\n\n\n\nAge (years)\n249\n1.06\n1.04, 1.08\n&lt;0.001\n\n\nSex\n246\n\n\n\n\n\n\n\n\n    Female\n\n\n—\n—\n\n\n\n\n    Male\n\n\n1.09\n0.63, 1.87\n0.765\n\n\nWaist circumference (cm)\n248\n1.02\n1.00, 1.04\n0.099\n\n\nEducational level\n248\n\n\n\n\n\n\n\n\n    None\n\n\n—\n—\n\n\n\n\n    Primary\n\n\n0.23\n0.09, 0.56\n0.002\n\n\n    JHS/Form 4\n\n\n0.43\n0.24, 0.77\n0.005\n\n\n    SHS/Secondary\n\n\n0.32\n0.08, 0.98\n0.060\n\n\n    Tertiary\n\n\n2.60\n0.32, 53.4\n0.414\n\n\nBody Weight\n245\n0.98\n0.96, 1.00\n0.120\n\n\nHeight (cm)\n247\n0.98\n0.96, 1.00\n0.103\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nCode\n# Build the model\nimputed_model &lt;- \n    with(imputed_data, \n         glm(hpt ~ ageyrs + sex + waist + educ + wgt + hgt, \n             family = \"binomial\")\n         )\n\n# present beautiful table with gtsummary\ntbl2 &lt;- \n    imputed_model %&gt;% \n    gtsummary::tbl_regression(\n        exponentiate=TRUE,\n        pvalue_fun = function(x) gtsummary::style_pvalue(x, digits = 3)\n        ) %&gt;% \n    gtsummary::bold_labels() %&gt;% \n    gtsummary::bold_p()\ntbl2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n1\n95% CI\n1\np-value\n\n\n\n\nAge (years)\n1.06\n1.04, 1.09\n&lt;0.001\n\n\nSex\n\n\n\n\n\n\n\n\n    Female\n—\n—\n\n\n\n\n    Male\n1.33\n0.62, 2.85\n0.461\n\n\nWaist circumference (cm)\n1.03\n0.98, 1.09\n0.198\n\n\nEducational level\n\n\n\n\n\n\n\n\n    None\n—\n—\n\n\n\n\n    Primary\n0.50\n0.18, 1.39\n0.181\n\n\n    JHS/Form 4\n0.85\n0.41, 1.78\n0.671\n\n\n    SHS/Secondary\n0.85\n0.21, 3.47\n0.817\n\n\n    Tertiary\n11.1\n0.89, 140\n0.062\n\n\nBody Weight\n0.99\n0.95, 1.04\n0.787\n\n\nHeight (cm)\n0.99\n0.96, 1.02\n0.455\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nCode\n# Combine tables\ngtsummary::tbl_merge(\n    tbls = list(tbl1, tbl2), \n    tab_spanner = c(\"**Univariate**\", \"**Multivariate**\")\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nUnivariate\n\n\nMultivariate\n\n\n\nN\nOR\n1\n95% CI\n1\np-value\nOR\n1\n95% CI\n1\np-value\n\n\n\n\nAge (years)\n249\n1.06\n1.04, 1.08\n&lt;0.001\n1.06\n1.04, 1.09\n&lt;0.001\n\n\nSex\n246\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Female\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    Male\n\n\n1.09\n0.63, 1.87\n0.765\n1.33\n0.62, 2.85\n0.461\n\n\nWaist circumference (cm)\n248\n1.02\n1.00, 1.04\n0.099\n1.03\n0.98, 1.09\n0.198\n\n\nEducational level\n248\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    None\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    Primary\n\n\n0.23\n0.09, 0.56\n0.002\n0.50\n0.18, 1.39\n0.181\n\n\n    JHS/Form 4\n\n\n0.43\n0.24, 0.77\n0.005\n0.85\n0.41, 1.78\n0.671\n\n\n    SHS/Secondary\n\n\n0.32\n0.08, 0.98\n0.060\n0.85\n0.21, 3.47\n0.817\n\n\n    Tertiary\n\n\n2.60\n0.32, 53.4\n0.414\n11.1\n0.89, 140\n0.062\n\n\nBody Weight\n245\n0.98\n0.96, 1.00\n0.120\n0.99\n0.95, 1.04\n0.787\n\n\nHeight (cm)\n247\n0.98\n0.96, 1.00\n0.103\n0.99\n0.96, 1.02\n0.455\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Missiing Data</span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "missing-data.html#inputation-with-variable-selection-using-missranger-package",
    "href": "missing-data.html#inputation-with-variable-selection-using-missranger-package",
    "title": "2  Visualization",
    "section": "2.6 Inputation with variable selection using missRanger package",
    "text": "2.6 Inputation with variable selection using missRanger package\nTable 2.1 is the first table we are drawing\n\n\nCode\n# Create an empty list\nkk &lt;- list()\n\n\n# Create a loop for running multiple (10) imputations  and selecting the best variables\nfor(i in 1:10){\n    df_temp &lt;- \n        df_hpt %&gt;% \n        select(hpt, ageyrs, sex, waist, educ, wgt, hgt)\n\n    df_imp &lt;-  \n        df_temp %&gt;% \n        missRanger::missRanger(\n            formula = . ~ ., seed = i, num.trees = 1000,verbose = F) \n\n    model.x &lt;- \n        glm(hpt ~ ageyrs + sex + waist + educ + wgt + hgt, \n            family = \"binomial\", data = df_imp)\n\n    kk[[i]]&lt;-\n        MASS::stepAIC(model.x, direction = \"both\", trace = FALSE,) %&gt;% \n        broom::tidy(exponentiate = T) %&gt;% \n        pull(term)\n}\n\n# Tabulate selected variables. Chosen : ageyrs and waist\nunlist(kk) %&gt;% table()\n\n\n.\n(Intercept)      ageyrs       waist \n         10          10          10 \n\n\nCode\ndf_for_reg &lt;-\n    df_hpt %&gt;% \n    select(ageyrs, waist, hpt)\n\n# Univariate regression\ntbl1 &lt;-\n    df_temp %&gt;% \n    gtsummary::tbl_uvregression(\n        method = glm,\n        y = hpt,\n        method.args = family(binomial),\n        exponentiate = TRUE,\n        pvalue_fun = function(x) gtsummary::style_pvalue(x, digits = 3)\n        ) %&gt;% \n    gtsummary::bold_p()\n\n# Multivariate regression \ntbl2 &lt;-\n    df_for_reg %&gt;%\n    mice::mice(m = 10, seed = 200, printFlag = F)%&gt;%\n    with(glm(hpt ~ ageyrs + waist, family = \"binomial\")\n        ) %&gt;%\n    gtsummary::tbl_regression(\n        exponentiate = T,\n        pvalue_fun = function(x) gtsummary::style_pvalue(x, digits = 3)\n        ) %&gt;%\n    gtsummary::bold_labels() %&gt;%\n    gtsummary::bold_p()\n\n# Merge tables into one\ntbl_all &lt;-\n    gtsummary::tbl_merge(\n    tbls = list(tbl1, tbl2),\n    tab_spanner = c(\"**Univariate**\", \"**Multivariate**\")\n    )\n\ntbl_all\n\n\n\n\nTable 2.1: The first table is here\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nUnivariate\n\n\nMultivariate\n\n\n\nN\nOR\n1\n95% CI\n1\np-value\nOR\n1\n95% CI\n1\np-value\n\n\n\n\nAge (years)\n249\n1.06\n1.04, 1.08\n&lt;0.001\n1.06\n1.04, 1.08\n&lt;0.001\n\n\nSex\n246\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Female\n\n\n—\n—\n\n\n\n\n\n\n\n\n\n\n    Male\n\n\n1.09\n0.63, 1.87\n0.765\n\n\n\n\n\n\n\n\nWaist circumference (cm)\n248\n1.02\n1.00, 1.04\n0.099\n1.02\n1.00, 1.05\n0.098\n\n\nEducational level\n248\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    None\n\n\n—\n—\n\n\n\n\n\n\n\n\n\n\n    Primary\n\n\n0.23\n0.09, 0.56\n0.002\n\n\n\n\n\n\n\n\n    JHS/Form 4\n\n\n0.43\n0.24, 0.77\n0.005\n\n\n\n\n\n\n\n\n    SHS/Secondary\n\n\n0.32\n0.08, 0.98\n0.060\n\n\n\n\n\n\n\n\n    Tertiary\n\n\n2.60\n0.32, 53.4\n0.414\n\n\n\n\n\n\n\n\nBody Weight\n245\n0.98\n0.96, 1.00\n0.120\n\n\n\n\n\n\n\n\nHeight (cm)\n247\n0.98\n0.96, 1.00\n0.103\n\n\n\n\n\n\n\n\n\n1\nOR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.3 is a depiction of the figures that may show on the table every time there is an indication for such\n\n\nCode\ndf_hpt %&gt;% \n    select(syst1, ageyrs, sex) %&gt;% \n    drop_na(syst1, ageyrs, sex) %&gt;% \n    ggplot(aes(x = ageyrs, y = syst1, color = sex)) + \n    geom_point()+\n    geom_smooth(formula = y~x, method = \"loess\", se = F)+\n    labs(\n        x = \"Age (years)\",\n        y = \"Systolic Blood Pressure (mmHg)\"\n        ) +\n    ggthemes::theme_clean()+\n    scale_color_manual(\n        name = \"Sex\", \n        labels = c(\"Female\",\"Male\"), \n        values = c(\"red\", \"#0043E0\")\n        )\n\n\n\n\n\n\n\n\nFigure 2.3: Relationship between systolic blood pressure and age\n\n\n\n\n\n\n\nCode\nlm1 &lt;- \n    glm(syst1 ~ sex+ ageyrs + waist + hgt, data = df_hpt, family = \"gaussian\")\nlm1 %&gt;% performance::check_heteroscedasticity()\n\n\nOK: Error variance appears to be homoscedastic (p = 0.136).\n\n\nCode\nlm1 %&gt;% performance::check_normality() %&gt;% plot()\n\n\nThere's no formal statistical test for normality for generalized linear\n  model.\n  Instead, please use `simulate_residuals()` and `check_residuals()` to\n  check for uniformity of residuals.\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% performance::check_posterior_predictions()\n\n\nWarning: 'performance::check_posterior_predictions' is deprecated.\nUse 'check_predictions()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% performance::check_outliers() %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% performance::check_collinearity() %&gt;% plot() \n\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n    sjPlot::plot_model(type = \"eff\", term = c(\"ageyrs[all]\", \"sex\"))+ \n    theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n    sjPlot::tab_model(\n        p.style = \"numeric_stars\", \n        show.reflvl = T, \n        show.intercept = F\n        )\n\n\n\n\n\n \nSystolic BP 1st\n\n\nPredictors\nEstimates\nCI\np\n\n\nAge (years)\n0.78 ***\n0.62 – 0.94\n&lt;0.001\n\n\nWaist circumference (cm)\n0.06 \n-0.21 – 0.34\n0.649\n\n\nHeight (cm)\n0.05 \n-0.22 – 0.31\n0.731\n\n\nFemale\nReference\n\n\n\n\nMale\n8.29 *\n1.52 – 15.05\n0.016\n\n\nObservations\n245\n\n\nR2\n0.298\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\n\n\nCode\nlm2 &lt;- \n    glm(waist ~ sex* ageyrs, data = df_hpt, family = \"gaussian\")\nlm2 %&gt;% performance::check_heteroscedasticity()\n\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.002).\n\n\nCode\nlm2 %&gt;% performance::check_normality() %&gt;% plot()\n\n\nThere's no formal statistical test for normality for generalized linear\n  model.\n  Instead, please use `simulate_residuals()` and `check_residuals()` to\n  check for uniformity of residuals.\n\n\n\n\n\n\n\n\n\nCode\nlm2 %&gt;% performance::check_posterior_predictions()\n\n\nWarning: 'performance::check_posterior_predictions' is deprecated.\nUse 'check_predictions()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n\n\nCode\nlm2 %&gt;% performance::check_outliers() %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\nlm2 %&gt;% performance::check_collinearity() %&gt;% plot() \n\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\nCode\nlm2 %&gt;% \n    sjPlot::plot_model(type = \"eff\", term = c(\"sex\", \"ageyrs[20, 50, 80]\"))+ \n    theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nlm2 %&gt;% \n    sjPlot::tab_model(\n        p.style = \"numeric_stars\", \n        show.reflvl = T, \n        show.intercept = F\n        )\n\n\n\n\n\n \nWaist circumference (cm)\n\n\nPredictors\nEstimates\nCI\np\n\n\nAge (years)\n-0.00 \n-0.09 – 0.09\n0.945\n\n\nFemale\nReference\n\n\n\n\nMale\n-8.26 \n-16.69 – 0.16\n0.055\n\n\nsexMale:ageyrs\n0.09 \n-0.06 – 0.25\n0.243\n\n\nObservations\n246\n\n\nR2\n0.030\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Missiing Data</span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "risk-and-odds.html",
    "href": "risk-and-odds.html",
    "title": "3  Risk and Odds",
    "section": "",
    "text": "3.1 Risk\nRisk is defined as the probability of having an outcome. Therefore, if in a the population of 100, 35 develop diabetes mellitus after a specified period of follow-up, the risk of developing diabetes in the population is\n\\[\\frac{35}{100} = 0.35\\] Tabulation of the ANC method and the occurrence of death below, we can conclude that the risk of perinatal mortality when one uses the old method is 0.11 (11.0%) and that for the new method is 0.06 (5.9%).\nCode\ndf_anc %&gt;% \n    tbl_cross(\n        percent = \"column\",\n        row = death, \n        col = anc, \n        label = list(death ~ \"Death\", anc = \"ANC\"),\n        digits = c(0,2)) %&gt;% \n    bold_labels()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANC\n\nTotal\n\n\nOld\nNew\n\n\n\n\nDeath\n\n\n\n\n\n\n\n\n    No\n373 (89.02%)\n316 (94.05%)\n689 (91.26%)\n\n\n    Yes\n46 (10.98%)\n20 (5.95%)\n66 (8.74%)\n\n\nTotal\n419 (100.00%)\n336 (100.00%)\n755 (100.00%)\nThis can be written as \\[Re = 0:06 \\text{ and } Rne = 0:11\\]\nWhere \\(Re\\) is the risk in the exposed group (new anc method) and \\(Rne\\) is the risk in the non-exposed (old anc method).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Risk and Odds</span>"
    ]
  },
  {
    "objectID": "risk-and-odds.html#risk-ratio",
    "href": "risk-and-odds.html#risk-ratio",
    "title": "3  Risk and Odds",
    "section": "3.2 Risk Ratio",
    "text": "3.2 Risk Ratio\nA comparative way of expressing the risks in the two groups is by the use of the Risk Ratio or Relative Risk (RR). Where \\[RR = \\frac{Re}{Rne}\\]\nNote that by inference if the \\(Re\\) is the same as \\(Rne\\) then \\(RR = 1\\). The \\(RR\\) of perinatal mortality of the new compared to the old method is\n\\[RR = \\frac{5.952381}{10.978520} = 0.5421843 \\approx 0.54\\]\nThe epiDisplay package has a function cs() which automatically calculates the RR and other relevant stats with their confidence intervals. This is applied to the ANCdata as below.\n\n\nCode\ndf_anc %$% epiDisplay::cs(outcome = death, exposure = anc, )\n\n\n\n          Exposure\nOutcome    Non-exposed Exposed Total\n  Negative 373         316     689  \n  Positive 46          20      66   \n  Total    419         336     755  \n                                    \n           Rne         Re      Rt   \n  Risk     0.11        0.06    0.09 \n                                         Estimate Lower95ci Upper95ci\n Risk difference (Re - Rne)              -0.05    -0.09     -0.01    \n Risk ratio                              0.54     0.32      0.91     \n Protective efficacy =(Rne-Re)/Rne*100   45.8     8.71      68.06    \n   or percent of risk reduced                                        \n Number needed to treat (NNT)            19.9     10.79     94.2     \n   or -1/(risk difference)                                           \n\n\nThe output above first tabulates the two variables producing a contingency table with the marginal totals. It then shows our previously calculated parameters, Re and Rne. Rt (Risk total) is the risk if both the exposed and unexposed are put together, here.\n\\[Rt =\\frac{20 + 46}{419 + 336} = \\frac{66}{755} \\approx 0.09\\]\nThe next section of the output shows the risk difference (difference between the risks of the two groups), the risk ratio, the protective efficacy and the number needed to treat (NNT) together with their confidence intervals.\nInterpreting the analysis so far, we conclude that the risk of perinatal death when using the new anc method is significantly less than using the old method. It significantly reduces the risk of death (Risk difference) by 0.05 (5%) and halves the chances of death (RR = 0.54, 95%CI: 0.32 to 0.91). About 20 (95%CI: 11 to 95) pregnant women need to be treated with the new anc method to prevent one perinatal death (NNT).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Risk and Odds</span>"
    ]
  },
  {
    "objectID": "risk-and-odds.html#odds",
    "href": "risk-and-odds.html#odds",
    "title": "3  Risk and Odds",
    "section": "3.3 Odds",
    "text": "3.3 Odds\nAnother way of expressing the risk of an outcome is using the Odds. Statistically the odds is defined as\n\\[Odds = \\frac{p}{1-p}\\]\nWhere p is the probability of the outcome occurring. Using the ANCdata the probability of death in the exposed is.\n\\[pe = \\frac{20}{336} = 0.05952381\\]\nThe odds of death in the exposed can then be determined as\n\\[Oddse = \\frac{0.05952381}{1-0.05952381} = 0.06329114\\]\nSimilarly, the probability of death in the non-exposed (old anc type) is\n\\[pne = \\frac{46}{419} = 0.1097852\\]\nAnd the odds of death in the non-exposed is\n\\[Oddsne = \\frac{0.1097852}{1-0.1097852} = 0.1233244\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Risk and Odds</span>"
    ]
  },
  {
    "objectID": "risk-and-odds.html#odds-ratio",
    "href": "risk-and-odds.html#odds-ratio",
    "title": "3  Risk and Odds",
    "section": "3.4 Odds ratio",
    "text": "3.4 Odds ratio\nThe comparative way of comparing the two odds is the Odds Ratio (OR). This is determined as\n\\[OR = \\frac{Oddse}{Oddsne} = 0.5132086 \\approx 0.51\\]\nOnce again fortunately we do not have to go through this tedious procedure each time we need to calculate the OR. The cc() function in the epiDisplay package does this very well. Below we apply it to the analysis just done.\n\n\nCode\ndf_anc %$% epiDisplay::cc(outcome=death, exposure=anc, graph = FALSE)\n\n\n\n       anc\ndeath   Old New Total\n  No    373 316   689\n  Yes    46  20    66\n  Total 419 336   755\n\nOR =  0.51 \n95% CI =  0.3, 0.89  \nChi-squared = 5.9, 1 d.f., P value = 0.015\nFisher's exact test (2-sided) P value = 0.019 \n\n\nThe output shows a table of the variables in question, the OR with its 95% confidence interval and both p-values determine by the chi-squared test and the Fisher’s test. With a confidence interval of the odds ratio not containing the null value 1, and small p-values from both methods it can be concluded that the odds of death in mothers who used the new ANC method is about half (0.5) of those who used the old method and the probability of obtaining an OR this values if the null was true, is low (p-value = 0.019). Therefore, the use of the new anc method is associated with significantly better perinatal outcomes compared to the old.\nOdds ratios are very important in regression analysis and will be dealt with in more detail in subsequent chapters.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Risk and Odds</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "4  Correlation",
    "section": "",
    "text": "We begin by reading in the data and selecting our desired variables\n\n\nCode\nmatDF &lt;- \n    readstata13::read.dta13(\"C:/Dataset/olivia_data_wide.dta\") %&gt;% \n    select(hct1, hct2, hct3, hct4, hct5)\n\n\nNext we summarize the data\n\n\nCode\nsummarytools::dfSummary(matDF, graph.col = F)\n\n\nData Frame Summary  \nmatDF  \nDimensions: 350 x 5  \nDuplicates: 3  \n\n------------------------------------------------------------------------------------\nNo   Variable    Stats / Values           Freqs (% of Valid)    Valid      Missing  \n---- ----------- ------------------------ --------------------- ---------- ---------\n1    hct1        Mean (sd) : 34.2 (5.6)   133 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                               (100.0%)   (0.0%)   \n                 10.5 &lt; 33.7 &lt; 49.9                                                 \n                 IQR (CV) : 7.6 (0.2)                                               \n\n2    hct2        Mean (sd) : 34.2 (5.6)   119 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                               (100.0%)   (0.0%)   \n                 10.2 &lt; 33.2 &lt; 54.9                                                 \n                 IQR (CV) : 7.9 (0.2)                                               \n\n3    hct3        Mean (sd) : 34.8 (6.3)   128 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                               (100.0%)   (0.0%)   \n                 4.3 &lt; 33.2 &lt; 75.5                                                  \n                 IQR (CV) : 8.6 (0.2)                                               \n\n4    hct4        Mean (sd) : 36.8 (7.6)   164 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                               (100.0%)   (0.0%)   \n                 10.4 &lt; 36 &lt; 76.5                                                   \n                 IQR (CV) : 6.4 (0.2)                                               \n\n5    hct5        Mean (sd) : 45.9 (9.5)   186 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                               (100.0%)   (0.0%)   \n                 6.2 &lt; 45.7 &lt; 92.3                                                  \n                 IQR (CV) : 8.6 (0.2)                                               \n------------------------------------------------------------------------------------\n\n\nWe begin by running a correlation coefficient matrix with lower segment shown\n\n\nCode\npsych::lowerCor(matDF, method = \"pearson\")\n\n\n     hct1  hct2  hct3  hct4  hct5 \nhct1  1.00                        \nhct2  0.36  1.00                  \nhct3  0.37  0.30  1.00            \nhct4  0.01 -0.14 -0.04  1.00      \nhct5  0.05  0.06 -0.01 -0.01  1.00\n\n\nAnd then a lot more detail with p-values and confidence interval (Normal)\n\n\nCode\npsych::corr.test(matDF, method = \"pearson\") %&gt;% \n    print(short=F)\n\n\nCall:psych::corr.test(x = matDF, method = \"pearson\")\nCorrelation matrix \n     hct1  hct2  hct3  hct4  hct5\nhct1 1.00  0.36  0.37  0.01  0.05\nhct2 0.36  1.00  0.30 -0.14  0.06\nhct3 0.37  0.30  1.00 -0.04 -0.01\nhct4 0.01 -0.14 -0.04  1.00 -0.01\nhct5 0.05  0.06 -0.01 -0.01  1.00\nSample Size \n[1] 350\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n     hct1 hct2 hct3 hct4 hct5\nhct1 0.00 0.00 0.00 1.00    1\nhct2 0.00 0.00 0.00 0.07    1\nhct3 0.00 0.00 0.00 1.00    1\nhct4 0.86 0.01 0.51 0.00    1\nhct5 0.35 0.25 0.82 0.84    0\n\n Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n          raw.lower raw.r raw.upper raw.p lower.adj upper.adj\nhct1-hct2      0.26  0.36      0.45  0.00      0.22      0.48\nhct1-hct3      0.28  0.37      0.46  0.00      0.24      0.50\nhct1-hct4     -0.10  0.01      0.11  0.86     -0.10      0.11\nhct1-hct5     -0.05  0.05      0.15  0.35     -0.09      0.19\nhct2-hct3      0.20  0.30      0.39  0.00      0.16      0.43\nhct2-hct4     -0.24 -0.14     -0.03  0.01     -0.28      0.00\nhct2-hct5     -0.04  0.06      0.17  0.25     -0.08      0.20\nhct3-hct4     -0.14 -0.04      0.07  0.51     -0.17      0.10\nhct3-hct5     -0.12 -0.01      0.09  0.82     -0.14      0.12\nhct4-hct5     -0.12 -0.01      0.09  0.84     -0.13      0.11\n\n\nBootstrapped coefficients and confidence interval can be obtained as below\n\n\nCode\npsych::cor.ci(matDF, cex.axis = 2, cex.lab = 3)\n\n\n\n\n\n\n\n\n\nCall:corCi(x = x, keys = keys, n.iter = n.iter, p = p, overlap = overlap, \n    poly = poly, method = method, plot = plot, minlength = minlength, \n    n = n, cex.axis = 2, cex.lab = 3)\n\n Coefficients and bootstrapped confidence intervals \n     hct1  hct2  hct3  hct4  hct5 \nhct1  1.00                        \nhct2  0.36  1.00                  \nhct3  0.37  0.30  1.00            \nhct4  0.01 -0.14 -0.04  1.00      \nhct5  0.05  0.06 -0.01 -0.01  1.00\n\n scale correlations and bootstrapped confidence intervals \n          lower.emp lower.norm estimate upper.norm upper.emp    p\nhct1-hct2      0.21       0.20     0.36       0.49      0.47 0.00\nhct1-hct3      0.26       0.25     0.37       0.49      0.47 0.00\nhct1-hct4     -0.09      -0.10     0.01       0.12      0.11 0.81\nhct1-hct5     -0.06      -0.07     0.05       0.17      0.16 0.41\nhct2-hct3      0.15       0.14     0.30       0.46      0.45 0.00\nhct2-hct4     -0.21      -0.21    -0.14      -0.05     -0.05 0.00\nhct2-hct5     -0.06      -0.04     0.06       0.16      0.15 0.23\nhct3-hct4     -0.17      -0.15    -0.04       0.08      0.07 0.57\nhct3-hct5     -0.10      -0.10    -0.01       0.09      0.08 0.92\nhct4-hct5     -0.16      -0.15    -0.01       0.12      0.12 0.84\n\n\n\n\nCode\nmatDF %&gt;% \n    cor() %&gt;% \n    ggcorrplot::ggcorrplot(hc.order = FALSE, \n           type = \"lower\", \n           lab = TRUE, \n           lab_size = 3, \n           method=\"square\", \n           colors = c(\"tomato2\", \"white\", \"springgreen3\"), \n           title=\"Correlogram of blood indices\", \n           ggtheme=theme_bw)\n\n\n\n\n\n\n\n\n\nGraphically we can use this\n\n\nCode\nmatDF %&gt;% \n    cor() %&gt;% \n    corrplot::corrplot(type = \"lower\", tl.pos = \"ld\",\n                       title = \"Out correlation matrix\", addCoef.col = \"black\",\n                       outline = \"black\", number.cex = .8)\n\n\n\n\n\n\n\n\n\n\n\nCode\n#|mmessage: false\n#|warning: false\nGGally::ggpairs(data = matDF, ggplot2::aes(color = hct1&gt;30))\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Correlation</span>",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "linear-regression.html",
    "href": "linear-regression.html",
    "title": "5  Linear Regression",
    "section": "",
    "text": "5.1 Acquiring the data\nWe begin by reading the data. Here we use the data from the Carotid Intima dataset\nCode\ndat &lt;- \n  dget(\"C:/Dataset/cint_data_clean\")%&gt;%\n  select(cca_0, sex, ageyrs, resid, hba1c, tobacco, alcohol, bmi, \n         whratio, totchol, ldl, hdl, trig, sbp, dbp)  %&gt;%\n  filter(!is.na(totchol), !is.na(ldl)) %&gt;% \n  mutate(trig = if_else(trig &gt; 40, trig/10, trig, missing = NULL))\nNext, we summarize the data\nCode\ndat %&gt;% \n    summarytools::dfSummary(graph.col = F)\n\n\nData Frame Summary  \ndat  \nDimensions: 702 x 15  \nDuplicates: 4  \n\n-------------------------------------------------------------------------------------\nNo   Variable    Stats / Values            Freqs (% of Valid)    Valid      Missing  \n---- ----------- ------------------------- --------------------- ---------- ---------\n1    cca_0       Mean (sd) : 0.9 (0.2)     40 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 0.5 &lt; 0.8 &lt; 1.6                                                     \n                 IQR (CV) : 0.2 (0.2)                                                \n\n2    sex         1. Female                 545 (77.6%)           702        0        \n     [factor]    2. Male                   157 (22.4%)           (100.0%)   (0.0%)   \n\n3    ageyrs      Mean (sd) : 44.3 (9)      46 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 26 &lt; 43 &lt; 75                                                        \n                 IQR (CV) : 12 (0.2)                                                 \n\n4    resid       1. Rural                   24 ( 3.4%)           702        0        \n     [factor]    2. Periurban              174 (24.8%)           (100.0%)   (0.0%)   \n                 3. Urban                  504 (71.8%)                               \n\n5    hba1c       Mean (sd) : 5.4 (1)       56 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 3.1 &lt; 5.3 &lt; 15.5                                                    \n                 IQR (CV) : 0.8 (0.2)                                                \n\n6    tobacco     1. No                     657 (93.6%)           702        0        \n     [factor]    2. Yes                     45 ( 6.4%)           (100.0%)   (0.0%)   \n\n7    alcohol     1. No                     458 (65.2%)           702        0        \n     [factor]    2. Yes                    244 (34.8%)           (100.0%)   (0.0%)   \n\n8    bmi         Mean (sd) : 26.6 (5.6)    582 distinct values   702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 13.3 &lt; 26.1 &lt; 45.3                                                  \n                 IQR (CV) : 7.7 (0.2)                                                \n\n9    whratio     Mean (sd) : 0.9 (0.1)     456 distinct values   702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 0.6 &lt; 0.9 &lt; 1.2                                                     \n                 IQR (CV) : 0.1 (0.1)                                                \n\n10   totchol     Mean (sd) : 5.1 (1.3)     73 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 1.1 &lt; 5 &lt; 11.1                                                      \n                 IQR (CV) : 1.7 (0.3)                                                \n\n11   ldl         Mean (sd) : 3.2 (1.1)     59 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 0 &lt; 3.1 &lt; 8.1                                                       \n                 IQR (CV) : 1.4 (0.3)                                                \n\n12   hdl         Mean (sd) : 1.4 (0.5)     31 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 0.3 &lt; 1.3 &lt; 4.4                                                     \n                 IQR (CV) : 0.6 (0.4)                                                \n\n13   trig        Mean (sd) : 1.4 (0.9)     227 distinct values   702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 0.3 &lt; 1.2 &lt; 10.7                                                    \n                 IQR (CV) : 0.8 (0.7)                                                \n\n14   sbp         Mean (sd) : 125 (23.9)    118 distinct values   702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 66 &lt; 121 &lt; 231                                                      \n                 IQR (CV) : 28 (0.2)                                                 \n\n15   dbp         Mean (sd) : 79.5 (14.1)   71 distinct values    702        0        \n     [numeric]   min &lt; med &lt; max:                                (100.0%)   (0.0%)   \n                 43 &lt; 79 &lt; 135                                                       \n                 IQR (CV) : 19 (0.2)                                                 \n-------------------------------------------------------------------------------------",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Linear Regression</span>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear-regression.html#linear-regression-with-a-single-continuous-variable",
    "href": "linear-regression.html#linear-regression-with-a-single-continuous-variable",
    "title": "5  Linear Regression",
    "section": "5.2 Linear regression with a single continuous variable",
    "text": "5.2 Linear regression with a single continuous variable\nWe begin by looking at the relationship between the dependent and independent variables\n\n\nCode\ndat %&gt;% \n  ggplot(aes(x = ageyrs, y = cca_0)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y~x) +\n  labs(\n      x = \"Age in years\", \n      y = \"Common Carotid Intima thickness\",\n      title = \"Relationship between CCA and Age of patient\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nSince the relationship between the two looks linear we will go on to fit the model\n\n\nCode\nlm.1 &lt;- \n    lm(cca_0 ~ ageyrs, data = dat)\n\n\nNext w,e summarise the model, extract the coefficients and confidence intervals with the help of the flextable package.\n\n\nCode\nlm.1 %&gt;% flextable::as_flextable()\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)0.6280.02921.9880.0000***ageyrs0.0050.0018.3810.0000***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.1511 on 700 degrees of freedomMultiple R-squared: 0.0912, Adjusted R-squared: 0.0899F-statistic: 70.25 on 700 and 1 DF, p-value: 0.0000\n\n\nNext, we extract some regression analysis stats required for the regression diagnostics\n\n\nCode\ntibble(\n    resid = residuals(lm.1), \n    fits = fitted(lm.1), \n    st.resid = rstandard(lm.1),\n    cookd = cooks.distance(lm.1),\n    covr = covratio(lm.1),\n    hatv = hatvalues(lm.1),\n    dfit = dffits(lm.1),\n    dfbeta1 = dfbeta(lm.1)[,2]) %&gt;% \n  arrange(desc(cookd)) %&gt;% \n  round(5) %&gt;% \n  slice(1:10) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresid\nfits\nst.resid\ncookd\ncovr\nhatv\ndfit\ndfbeta1\n\n\n\n\n0.40242\n0.97258\n2.67540\n0.03210\n0.99127\n0.00889\n0.25449\n0.00015\n\n\n0.52507\n0.92493\n3.48188\n0.02314\n0.97212\n0.00380\n0.21685\n0.00011\n\n\n-0.25435\n1.00435\n-1.69521\n0.02018\n1.00862\n0.01385\n-0.20119\n-0.00012\n\n\n0.71213\n0.88787\n4.71760\n0.02012\n0.94181\n0.00180\n0.20372\n0.00006\n\n\n0.53625\n0.81375\n3.55451\n0.01868\n0.96985\n0.00295\n0.19491\n-0.00009\n\n\n0.34330\n0.95670\n2.28006\n0.01800\n0.99487\n0.00688\n0.19033\n0.00011\n\n\n0.19948\n1.02552\n1.33222\n0.01614\n1.01593\n0.01786\n0.17975\n0.00011\n\n\n-0.24376\n0.99376\n-1.62316\n0.01608\n1.00748\n0.01206\n-0.17953\n-0.00011\n\n\n0.35389\n0.94611\n2.34901\n0.01585\n0.99279\n0.00571\n0.17864\n0.00010\n\n\n-0.25287\n0.97787\n-1.68180\n0.01375\n1.00445\n0.00963\n-0.16604\n-0.00010\n\n\n\n\n\nAnd then plot the regression diagnostic graphs\n\n\nCode\nopar &lt;- par(mfrow = c(2,2))\nplot(lm.1, pch = 18, cex=.5)\n\n\n\n\n\n\n\n\n\nCode\npar(opar)\n\n\nBelow we formally check the model assumption with the performance package. First the normality of the residuals\n\n\nCode\nperformance::check_predictions(lm.1)\n\n\nWarning: Maximum value of original data is not included in the\n  replicated data.\n  Model may not capture the variation of the data.\n\n\n\n\n\n\n\n\n\n\n\nCode\nperformance::check_normality(lm.1)\n\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nCode\nperformance::check_normality(lm.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nNext heteroscedasticity\n\n\nCode\nperformance::check_heteroscedasticity(lm.1)\n\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.018).\n\n\nCode\nperformance::check_heteroscedasticity(lm.1) %&gt;% \n    plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nperformance::check_distribution(lm.1)\n\n\n# Distribution of Model Family\n\nPredicted Distribution of Residuals\n\n Distribution Probability\n       normal         34%\n         beta         19%\n       cauchy         16%\n\nPredicted Distribution of Response\n\n  Distribution Probability\n inverse-gamma         28%\n         gamma         22%\n          beta         16%\n\n\nCode\nperformance::check_distribution(lm.1) %&gt;% \n    plot()\n\n\n\n\n\n\n\n\n\n\n5.2.1 Linear regression with one continuous and one categorical predictor\n\n\nCode\nlm.2 &lt;- \n    lm(cca_0 ~ ageyrs + sex, data = dat)\n\nlm.2 %&gt;% \n    summary() \n\n\n\nCall:\nlm(formula = cca_0 ~ ageyrs + sex, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35690 -0.11033 -0.01512  0.08711  0.71810 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.6301958  0.0285622  22.064  &lt; 2e-16 ***\nageyrs      0.0051368  0.0006377   8.056 3.42e-15 ***\nsexMale     0.0234025  0.0138148   1.694   0.0907 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1509 on 699 degrees of freedom\nMultiple R-squared:  0.09491,   Adjusted R-squared:  0.09233 \nF-statistic: 36.65 on 2 and 699 DF,  p-value: 7.294e-16\n\n\nAnd then plot the diagnostics\n\n\nCode\nopar &lt;- par(mfrow = c(2,2))\nlm.2 %&gt;% \n    plot(pch = 18, cex=.5)\n\n\n\n\n\n\n\n\n\nCode\npar(opar)\n\n\nFurther, we plot the marginal plot for the various sexes\n\n\nCode\ndat %&gt;% \n  ggplot(aes(x = ageyrs, y = cca_0, col = sex)) +\n  geom_smooth(formula = y~x, method = \"lm\") +\n  geom_point() +\n  labs(\n      x = \"Age in years\", \n      y = \"CCA\", \n      title = \"CCA vrs Age for each sex\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nLinear regression with one continuous and one categorical predictor with interaction\n\n\nCode\nlm.3 &lt;- \n    lm(cca_0 ~ ageyrs*sex, data = dat)\n\nlm.3 %&gt;% \n    summary()\n\n\n\nCall:\nlm(formula = cca_0 ~ ageyrs * sex, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35711 -0.10997 -0.01482  0.08664  0.71789 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.6284770  0.0330494  19.016  &lt; 2e-16 ***\nageyrs          0.0051762  0.0007429   6.968 7.45e-12 ***\nsexMale         0.0303114  0.0681101   0.445    0.656    \nageyrs:sexMale -0.0001503  0.0014510  -0.104    0.918    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.151 on 698 degrees of freedom\nMultiple R-squared:  0.09493,   Adjusted R-squared:  0.09104 \nF-statistic:  24.4 on 3 and 698 DF,  p-value: 5.025e-15\n\n\nAnd then plot the diagnostics\n\n\nCode\nopar &lt;- par(mfrow = c(2,2))\nlm.3 %&gt;% \n    plot(pch = 18, cex=.5)\n\n\n\n\n\n\n\n\n\nCode\npar(opar)\n\n\nNext, we make a plot of the marginal effects after\n\n\nCode\npr.3 &lt;- \n    ggeffects::ggpredict(lm.3, terms = c(\"ageyrs\", \"sex\"))\n\npr.3 %&gt;% \n  plot(ci = TRUE, add.data = TRUE) +\n  labs(\n      x = \"Age in years\", \n      y = \"CCA thickness\", \n      title = \"Marginal relationship\")\n\n\nWarning: Argument `add.data` is deprecated and will be removed in the future.\n  Please use `show_data` instead.\n\n\nWarning: Argument `ci` is deprecated and will be removed in the future. Please\n  use `show_ci` instead.\n\n\nData points may overlap. Use the `jitter` argument to add some amount of\n  random variation to the location of data points and avoid overplotting.\n\n\n\n\n\n\n\n\n\nLinear regression with one continuous and two categorical predictors with interaction\n\n\nCode\nlm.4 &lt;- \n    lm(cca_0 ~ ageyrs*sex*resid, data = dat)\n\nlm.4 %&gt;% \n    summary()\n\n\n\nCall:\nlm(formula = cca_0 ~ ageyrs * sex * resid, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.36621 -0.10171 -0.01644  0.08202  0.70879 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)                    0.434224   0.155773   2.788  0.00546 **\nageyrs                         0.010017   0.003277   3.057  0.00232 **\nsexMale                       -1.476681   1.361101  -1.085  0.27834   \nresidPeriurban                 0.171485   0.167778   1.022  0.30710   \nresidUrban                     0.213439   0.160840   1.327  0.18494   \nageyrs:sexMale                 0.034164   0.031289   1.092  0.27527   \nageyrs:residPeriurban         -0.005066   0.003557  -1.424  0.15476   \nageyrs:residUrban             -0.005046   0.003400  -1.484  0.13821   \nsexMale:residPeriurban         1.661961   1.367568   1.215  0.22468   \nsexMale:residUrban             1.452145   1.363439   1.065  0.28722   \nageyrs:sexMale:residPeriurban -0.035862   0.031413  -1.142  0.25401   \nageyrs:sexMale:residUrban     -0.033653   0.031336  -1.074  0.28322   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1499 on 690 degrees of freedom\nMultiple R-squared:  0.1184,    Adjusted R-squared:  0.1044 \nF-statistic: 8.427 on 11 and 690 DF,  p-value: 5.047e-14\n\n\nAnd then plot the diagnostics\n\n\nCode\nopar &lt;- par(mfrow = c(2,2))\nlm.4 %&gt;% \n    plot(pch = 18, cex=.5)\n\n\n\n\n\n\n\n\n\nCode\npar(opar)\n\n\nNext, we make a plot of the marginal effects after\n\n\nCode\npr.4 &lt;- ggeffects::ggpredict(lm.4, terms = c(\"ageyrs\", \"sex\", \"resid\"))\npr.4 %&gt;% \n  plot(ci = TRUE, add.data = TRUE, dot.size = .5, dot.alpha = .5) +\n  labs(x = \"Age in years\", y = \"CCA thickness\", title = \"Marginal relationship\")\n\n\nWarning: Argument `add.data` is deprecated and will be removed in the future.\n  Please use `show_data` instead.\n\n\nWarning: Argument `ci` is deprecated and will be removed in the future. Please\n  use `show_ci` instead.\n\n\nWarning: Argument `dot.alpha` is deprecated and will be removed in the future.\n  Please use `dot_alpha` instead.\n\n\nWarning: Argument `dot.size` is deprecated and will be removed in the future.\n  Please use `dot_size` instead.\n\n\nData points may overlap. Use the `jitter` argument to add some amount of\n  random variation to the location of data points and avoid overplotting.\n\n\n\n\n\n\n\n\n\nThere is a set of criteria for evaluating linear regression equations. These are:\n\nThere must be a linear relationship between the predictor and dependent variables\nThe residuals must be independent\nHomoscedaticity: The variance of the residuals must be uniform at every level of x\nThe residual must be normally distributed\n\n\n\nCode\ncorr.mat &lt;- \n  dat %&gt;% \n  select(cca_0, ageyrs, whratio, totchol, ldl, sbp, dbp) %&gt;% \n  cor() %&gt;% \n  round(4)\n\ncorr.mat %&gt;% \n  kableExtra::kbl(align = c(rep(\"l\", 7)), caption = \"Correlation matrix\") %&gt;% \n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"bordered\", \"condensed\", \"hover\", \"responsive\"), \n                            full_width= FALSE, html_font = \"san_serif\", font_size = 16)\n\n\n\n\nCorrelation matrix\n\n\n\ncca_0\nageyrs\nwhratio\ntotchol\nldl\nsbp\ndbp\n\n\n\n\ncca_0\n1.0000\n0.3020\n0.1398\n0.1387\n0.1131\n0.1963\n0.1538\n\n\nageyrs\n0.3020\n1.0000\n0.2962\n0.2196\n0.1563\n0.2755\n0.1782\n\n\nwhratio\n0.1398\n0.2962\n1.0000\n0.1521\n0.1247\n0.1681\n0.1509\n\n\ntotchol\n0.1387\n0.2196\n0.1521\n1.0000\n0.9086\n0.3198\n0.2647\n\n\nldl\n0.1131\n0.1563\n0.1247\n0.9086\n1.0000\n0.2553\n0.2069\n\n\nsbp\n0.1963\n0.2755\n0.1681\n0.3198\n0.2553\n1.0000\n0.7936\n\n\ndbp\n0.1538\n0.1782\n0.1509\n0.2647\n0.2069\n0.7936\n1.0000\n\n\n\n\n\n\n\n\nAnd then graphically present the correlation matrix\n\n\nCode\ndat %&gt;% \n  select(cca_0, ageyrs, whratio, totchol, ldl, sbp, dbp) %&gt;% \n  pairs(pch=\".\")\n\n\n\n\n\n\n\n\n\nCode\ncorrplot::corrplot(corr.mat)\n\n\n\n\n\n\n\n\n\nBoth the correlation matrix and the diagram indicate a high correlation between\n\nsbp and dbp\ntotchol, ldl and hdl\n\nThese could potentially be indicative of multicollinearity",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Linear Regression</span>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear-regression.html#fitting-the-model",
    "href": "linear-regression.html#fitting-the-model",
    "title": "5  Linear Regression",
    "section": "5.3 Fitting the model",
    "text": "5.3 Fitting the model\nWe then fit the linear model and summarize it\n\n\nCode\nlm1 &lt;- lm(cca_0 ~ sbp + dbp + ldl + ageyrs + totchol + whratio, data = dat)\nsummary(lm1)\n\n\n\nCall:\nlm(formula = cca_0 ~ sbp + dbp + ldl + ageyrs + totchol + whratio, \n    data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.33971 -0.10555 -0.01751  0.08800  0.68657 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.4697581  0.0744135   6.313 4.88e-10 ***\nsbp         0.0006056  0.0004044   1.498    0.135    \ndbp         0.0002161  0.0006659   0.325    0.746    \nldl         0.0021276  0.0129757   0.164    0.870    \nageyrs      0.0044292  0.0006872   6.446 2.15e-10 ***\ntotchol     0.0035070  0.0104519   0.336    0.737    \nwhratio     0.0895525  0.0839122   1.067    0.286    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1502 on 695 degrees of freedom\nMultiple R-squared:  0.1086,    Adjusted R-squared:  0.1009 \nF-statistic: 14.11 on 6 and 695 DF,  p-value: 3.37e-15\n\n\nThe broom package gives us the opportunity of extracting the coefficient, residual, etc into a dataframe. We next do this below\n\n\nCode\nlm1 %&gt;% broom::tidy()\n\n\n# A tibble: 7 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept) 0.470     0.0744       6.31  4.88e-10\n2 sbp         0.000606  0.000404     1.50  1.35e- 1\n3 dbp         0.000216  0.000666     0.325 7.46e- 1\n4 ldl         0.00213   0.0130       0.164 8.70e- 1\n5 ageyrs      0.00443   0.000687     6.45  2.15e-10\n6 totchol     0.00351   0.0105       0.336 7.37e- 1\n7 whratio     0.0896    0.0839       1.07  2.86e- 1\n\n\nCode\nlm1 %&gt;% broom::augment()\n\n\n# A tibble: 702 × 13\n   cca_0   sbp   dbp   ldl ageyrs totchol whratio .fitted  .resid    .hat .sigma\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 0.925   130    80   4.5     58     6.7   0.9     0.936 -0.0113 0.00677  0.150\n 2 0.975   120    80   2.3     48     4.4   0.924   0.875  0.0996 0.00359  0.150\n 3 0.85    110    80   1.3     40     2.7   0.877   0.822  0.0284 0.00730  0.150\n 4 0.875   120    80   3.5     38     5.1   0.869   0.831  0.0438 0.00301  0.150\n 5 1.6     150   100   3.1     49     4.9   1.01    0.913  0.687  0.00863  0.148\n 6 1.02    130    70   4.2     60     6.3   0.970   0.947  0.0777 0.00986  0.150\n 7 1       106    71   2.1     42     3.8   0.949   0.838  0.162  0.00503  0.150\n 8 1.32    130   100   3.2     55     4.9   0.843   0.913  0.412  0.0130   0.149\n 9 1.1     110    80   3.3     36     5.1   0.814   0.811  0.289  0.00503  0.150\n10 1       110    70   0.7     55     3.3   0.912   0.890  0.110  0.0172   0.150\n# ℹ 692 more rows\n# ℹ 2 more variables: .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;\n\n\nCode\nlm1 %&gt;% broom::glance()\n\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.109         0.101 0.150      14.1 3.37e-15     6   338. -661. -624.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nlm1 %&gt;% \n  broom::augment() %&gt;% \n  ggplot(aes(x=.resid)) + \n  geom_histogram(fill = \"blue\", col = \"black\", alpha = .4) +\n  theme_classic()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n  broom::augment() %&gt;%\n  ggpubr::ggqqplot(x = \".resid\", col = \"red\", \n                   title = \"QQ plot of the residuals of  the model\") \n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n  plot(1, pch = 16, col = \"skyblue\")\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n  plot(2, pch = 16, col = \"skyblue\")\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n  plot(3, pch = 16, col = \"skyblue\")\n\n\n\n\n\n\n\n\n\nCode\nlm1 %&gt;% \n  plot(4, pch = 16, col = \"skyblue\")",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Linear Regression</span>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear-regression.html#checking-multi-colinearity",
    "href": "linear-regression.html#checking-multi-colinearity",
    "title": "5  Linear Regression",
    "section": "5.4 Checking multi-colinearity",
    "text": "5.4 Checking multi-colinearity\n\n\nCode\ncar::vif(lm1) %&gt;% round(3)\n\n\n    sbp     dbp     ldl  ageyrs totchol whratio \n  2.914   2.725   5.829   1.198   6.155   1.114",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Linear Regression</span>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear-regression.html#variable-selection-in-multiple-linear-regression",
    "href": "linear-regression.html#variable-selection-in-multiple-linear-regression",
    "title": "5  Linear Regression",
    "section": "5.5 Variable selection in multiple linear regression",
    "text": "5.5 Variable selection in multiple linear regression\nHere we go through the drill of selecting the best model from a set of predictor variables. We do this with the help of the olsrr package.\n\n5.5.1 Forward regression using the p-values for the selection of the best model\nWe begin by running the model as before\n\n\nCode\nlm1 &lt;- lm(cca_0 ~ sbp + dbp + ldl + ageyrs + totchol + whratio, data = dat)\nsummary(lm1)\n\n\n\nCall:\nlm(formula = cca_0 ~ sbp + dbp + ldl + ageyrs + totchol + whratio, \n    data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.33971 -0.10555 -0.01751  0.08800  0.68657 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.4697581  0.0744135   6.313 4.88e-10 ***\nsbp         0.0006056  0.0004044   1.498    0.135    \ndbp         0.0002161  0.0006659   0.325    0.746    \nldl         0.0021276  0.0129757   0.164    0.870    \nageyrs      0.0044292  0.0006872   6.446 2.15e-10 ***\ntotchol     0.0035070  0.0104519   0.336    0.737    \nwhratio     0.0895525  0.0839122   1.067    0.286    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1502 on 695 degrees of freedom\nMultiple R-squared:  0.1086,    Adjusted R-squared:  0.1009 \nF-statistic: 14.11 on 6 and 695 DF,  p-value: 3.37e-15\n\n\nNext, we perform the forward stepwise selection using a cut-off p.value of 0.1. The table below gives a summary of the selection criteria\n\n\nCode\nfwd.fit.pval &lt;- olsrr::ols_step_forward_p(lm1, penter=0.1)\nfwd.fit.pval\n\n\n\n                               Stepwise Summary                                \n-----------------------------------------------------------------------------\nStep    Variable        AIC         SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------\n 0      Base Model    -592.088    -582.980    -2584.497    0.00000    0.00000 \n 1      ageyrs        -657.220    -643.558    -2649.447    0.09120    0.08990 \n 2      sbp           -665.999    -647.783    -2658.153    0.10505    0.10249 \n 3      totchol       -665.472    -642.703    -2657.597    0.10692    0.10308 \n 4      whratio       -664.658    -637.334    -2656.749    0.10843    0.10331 \n-----------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                         Model Summary                           \n----------------------------------------------------------------\nR                       0.329       RMSE                  0.149 \nR-Squared               0.108       MSE                   0.022 \nAdj. R-Squared          0.103       Coef. Var            17.374 \nPred R-Squared          0.095       AIC                -664.658 \nMAE                     0.117       SBC                -637.334 \n----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n               Sum of                                               \n              Squares         DF    Mean Square      F         Sig. \n--------------------------------------------------------------------\nRegression      1.907          4          0.477    21.192    0.0000 \nResidual       15.676        697          0.022                     \nTotal          17.583        701                                    \n--------------------------------------------------------------------\n\n                                 Parameter Estimates                                  \n-------------------------------------------------------------------------------------\n      model     Beta    Std. Error    Std. Beta      t       Sig      lower    upper \n-------------------------------------------------------------------------------------\n(Intercept)    0.473         0.073                 6.461    0.000     0.330    0.617 \n     ageyrs    0.004         0.001        0.251    6.461    0.000     0.003    0.006 \n        sbp    0.001         0.000        0.106    2.742    0.006     0.000    0.001 \n    totchol    0.005         0.004        0.043    1.132    0.258    -0.004    0.014 \n    whratio    0.091         0.084        0.041    1.085    0.278    -0.073    0.255 \n-------------------------------------------------------------------------------------\n\n\nThe final best-fitting selected model is as below. However, I will run it on the standardized version of our variables as the coefficients are too small\n\n\nCode\ndat2 &lt;-  \n  dat %&gt;% \n  mutate_at(c(\"ageyrs\", \"sbp\"), ~(scale(.) %&gt;% as.vector))\n\nlm.pval &lt;- lm(cca_0 ~ sbp + ageyrs, data = dat2)\ncoefficients(lm.pval)\n\n\n(Intercept)         sbp      ageyrs \n 0.86317664  0.01938752  0.04248649 \n\n\nCode\nlm.pval %&gt;% flextable::as_flextable()\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)0.8630.006152.4270.0000***sbp0.0190.0063.2890.0011 **ageyrs0.0420.0067.2070.0000***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.15 on 699 degrees of freedomMultiple R-squared: 0.105, Adjusted R-squared: 0.1025F-statistic: 41.02 on 699 and 2 DF, p-value: 0.0000\n\n\nCode\nlm.pval %&gt;%\n    broom::tidy(conf.int=T) %&gt;% \n    mutate(across(estimate:conf.high,~round(.x, 3))) %&gt;% \n    flextable::flextable() %&gt;% \n    flextable::font(i=1:3, fontname = \"Times New Roman\") %&gt;% \n    flextable::bold(i=1, j=1:7,part = \"header\") %&gt;% \n    flextable::theme_zebra()\n\n\ntermestimatestd.errorstatisticp.valueconf.lowconf.high(Intercept)0.8630.006152.4270.0000.8520.874sbp0.0190.0063.2890.0010.0080.031ageyrs0.0420.0067.2070.0000.0310.054\n\n\nCode\nlm.pval %&gt;% performance::check_collinearity()\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n    sbp 1.08 [1.03, 1.23]         1.04      0.92     [0.81, 0.97]\n ageyrs 1.08 [1.03, 1.23]         1.04      0.92     [0.81, 0.97]\n\n\nCode\nlm.pval %&gt;% performance::check_collinearity() %&gt;% plot()\n\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\nCode\nlm.pval %&gt;% performance::check_heteroscedasticity()\n\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.011).\n\n\nCode\nlm.pval %&gt;% performance::check_heteroscedasticity() %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\nlm.pval %&gt;% performance::check_normality()\n\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nCode\nlm.pval %&gt;% performance::check_normality() %&gt;% plot() \n\n\n\n\n\n\n\n\n\nCode\nlm.pval %&gt;% performance::check_predictions()\n\n\nWarning: Maximum value of original data is not included in the\n  replicated data.\n  Model may not capture the variation of the data.\n\n\n\n\n\n\n\n\n\nCode\nlm.pval %&gt;% performance::check_predictions() %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\nlm.pval %&gt;% performance::check_outliers()\n\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n\n\nCode\nlm.pval %&gt;% performance::check_outliers() %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\nplot(lm.pval)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.2 Forward regression using the AIC for the selection of the best model\nWe change next to perform the forward stepwise selection using the AIC. The table below gives a summary of the selection criteria\n\n\nCode\nfwd.fit.aic &lt;- \n    olsrr::ols_step_forward_aic(lm1)\nfwd.fit.aic\n\n\n\n                               Stepwise Summary                                \n-----------------------------------------------------------------------------\nStep    Variable        AIC         SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------\n 0      Base Model    -592.088    -582.980    -2584.497    0.00000    0.00000 \n 1      ageyrs        -657.220    -643.558    -2649.447    0.09120    0.08990 \n 2      sbp           -665.999    -647.783    -2658.153    0.10505    0.10249 \n-----------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                         Model Summary                           \n----------------------------------------------------------------\nR                       0.324       RMSE                  0.150 \nR-Squared               0.105       MSE                   0.023 \nAdj. R-Squared          0.102       Coef. Var            17.382 \nPred R-Squared          0.097       AIC                -665.999 \nMAE                     0.117       SBC                -647.783 \n----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n               Sum of                                               \n              Squares         DF    Mean Square      F         Sig. \n--------------------------------------------------------------------\nRegression      1.847          2          0.924    41.023    0.0000 \nResidual       15.736        699          0.023                     \nTotal          17.583        701                                    \n--------------------------------------------------------------------\n\n                                 Parameter Estimates                                  \n-------------------------------------------------------------------------------------\n      model     Beta    Std. Error    Std. Beta      t        Sig     lower    upper \n-------------------------------------------------------------------------------------\n(Intercept)    0.553         0.036                 15.199    0.000    0.482    0.625 \n     ageyrs    0.005         0.001        0.268     7.207    0.000    0.003    0.006 \n        sbp    0.001         0.000        0.122     3.289    0.001    0.000    0.001 \n-------------------------------------------------------------------------------------\n\n\nCode\nplot(fwd.fit.aic)\n\n\n\n\n\n\n\n\n\n\n\n5.5.3 Backward regression using the p.values for the selection of the best model\nWe change next to perform the backward stepwise removal using the p-value. The table below gives a summary of the selection criteria\n\n\nCode\nbwd.fit.pval &lt;- \n    olsrr::ols_step_backward_p(lm1, prem=0.1)\nbwd.fit.pval\n\n\n\n                               Stepwise Summary                                \n-----------------------------------------------------------------------------\nStep    Variable        AIC         SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------\n 0      Full Model    -660.788    -624.357    -2652.837    0.10860    0.10090 \n 1      ldl           -662.761    -630.883    -2654.831    0.10856    0.10216 \n 2      dbp           -664.658    -637.334    -2656.749    0.10843    0.10331 \n-----------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                         Model Summary                           \n----------------------------------------------------------------\nR                       0.329       RMSE                  0.149 \nR-Squared               0.108       MSE                   0.022 \nAdj. R-Squared          0.103       Coef. Var            17.374 \nPred R-Squared          0.095       AIC                -664.658 \nMAE                     0.117       SBC                -637.334 \n----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n               Sum of                                               \n              Squares         DF    Mean Square      F         Sig. \n--------------------------------------------------------------------\nRegression      1.907          4          0.477    21.192    0.0000 \nResidual       15.676        697          0.022                     \nTotal          17.583        701                                    \n--------------------------------------------------------------------\n\n                                 Parameter Estimates                                  \n-------------------------------------------------------------------------------------\n      model     Beta    Std. Error    Std. Beta      t       Sig      lower    upper \n-------------------------------------------------------------------------------------\n(Intercept)    0.473         0.073                 6.461    0.000     0.330    0.617 \n        sbp    0.001         0.000        0.106    2.742    0.006     0.000    0.001 \n     ageyrs    0.004         0.001        0.251    6.461    0.000     0.003    0.006 \n    totchol    0.005         0.004        0.043    1.132    0.258    -0.004    0.014 \n    whratio    0.091         0.084        0.041    1.085    0.278    -0.073    0.255 \n-------------------------------------------------------------------------------------\n\n\n\n\n5.5.4 Backward regression using the aic for the selection of the best model\n\n\nCode\nbwd.fit.aic &lt;- \n    olsrr::ols_step_backward_aic(lm1)\nbwd.fit.aic\n\n\n\n                               Stepwise Summary                                \n-----------------------------------------------------------------------------\nStep    Variable        AIC         SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------\n 0      Full Model    -660.788    -624.357    -2652.837    0.10860    0.10090 \n 1      ldl           -662.761    -630.883    -2654.847    0.10856    0.10216 \n 2      dbp           -664.658    -637.334    -2656.776    0.10843    0.10331 \n 3      whratio       -665.472    -642.703    -2657.616    0.10692    0.10308 \n 4      totchol       -665.999    -647.783    -2658.163    0.10505    0.10249 \n-----------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                         Model Summary                           \n----------------------------------------------------------------\nR                       0.324       RMSE                  0.150 \nR-Squared               0.105       MSE                   0.023 \nAdj. R-Squared          0.102       Coef. Var            17.382 \nPred R-Squared          0.097       AIC                -665.999 \nMAE                     0.117       SBC                -647.783 \n----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n               Sum of                                               \n              Squares         DF    Mean Square      F         Sig. \n--------------------------------------------------------------------\nRegression      1.847          2          0.924    41.023    0.0000 \nResidual       15.736        699          0.023                     \nTotal          17.583        701                                    \n--------------------------------------------------------------------\n\n                                 Parameter Estimates                                  \n-------------------------------------------------------------------------------------\n      model     Beta    Std. Error    Std. Beta      t        Sig     lower    upper \n-------------------------------------------------------------------------------------\n(Intercept)    0.553         0.036                 15.199    0.000    0.482    0.625 \n        sbp    0.001         0.000        0.122     3.289    0.001    0.000    0.001 \n     ageyrs    0.005         0.001        0.268     7.207    0.000    0.003    0.006 \n-------------------------------------------------------------------------------------\n\n\nCode\nplot(bwd.fit.aic)\n\n\n\n\n\n\n\n\n\n\n\n5.5.5 Both direction regression using the p.values for the selection of the best model\nWe change next to perform the backward stepwise removal using the p-value. The table below gives a summary of the selection criteria\n\n\nCode\nboth.fit.pval &lt;- \n    olsrr::ols_step_both_p(\n        lm1, \n        prem = 0.1, \n        penter = 0.1,  \n        progress = TRUE)\n\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1. sbp \n2. dbp \n3. ldl \n4. ageyrs \n5. totchol \n6. whratio \n\n\nVariables Added/Removed: \n\n=&gt; ageyrs added \n=&gt; sbp added \n\nNo more variables to be added or removed.\n\n\nCode\nboth.fit.pval\n\n\n\n                               Stepwise Summary                                \n-----------------------------------------------------------------------------\nStep    Variable        AIC         SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------\n 0      Base Model    -592.088    -582.980    -2584.497    0.00000    0.00000 \n 1      ageyrs (+)    -657.220    -643.558    -2649.447    0.09120    0.08990 \n 2      sbp (+)       -665.999    -647.783    -2658.153    0.10505    0.10249 \n-----------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                         Model Summary                           \n----------------------------------------------------------------\nR                       0.324       RMSE                  0.150 \nR-Squared               0.105       MSE                   0.023 \nAdj. R-Squared          0.102       Coef. Var            17.382 \nPred R-Squared          0.097       AIC                -665.999 \nMAE                     0.117       SBC                -647.783 \n----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n               Sum of                                               \n              Squares         DF    Mean Square      F         Sig. \n--------------------------------------------------------------------\nRegression      1.847          2          0.924    41.023    0.0000 \nResidual       15.736        699          0.023                     \nTotal          17.583        701                                    \n--------------------------------------------------------------------\n\n                                 Parameter Estimates                                  \n-------------------------------------------------------------------------------------\n      model     Beta    Std. Error    Std. Beta      t        Sig     lower    upper \n-------------------------------------------------------------------------------------\n(Intercept)    0.553         0.036                 15.199    0.000    0.482    0.625 \n     ageyrs    0.005         0.001        0.268     7.207    0.000    0.003    0.006 \n        sbp    0.001         0.000        0.122     3.289    0.001    0.000    0.001 \n-------------------------------------------------------------------------------------\n\n\n\n\n5.5.6 Both direction regression using the aic for the selection of the best model\n\n\nCode\nboth.fit.aic &lt;- \n    olsrr::ols_step_both_aic(lm1, progress = TRUE)\n\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1. sbp \n2. dbp \n3. ldl \n4. ageyrs \n5. totchol \n6. whratio \n\n\nVariables Added/Removed: \n\n=&gt; ageyrs added \n=&gt; sbp added \n\nNo more variables to be added or removed.\n\n\nCode\nboth.fit.aic\n\n\n\n                               Stepwise Summary                                \n-----------------------------------------------------------------------------\nStep    Variable        AIC         SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------\n 0      Base Model    -592.088    -582.980    -2584.497    0.00000    0.00000 \n 1      ageyrs (+)    -657.220    -643.558    -2649.447    0.09120    0.08990 \n 2      sbp (+)       -665.999    -647.783    -2658.153    0.10505    0.10249 \n-----------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                         Model Summary                           \n----------------------------------------------------------------\nR                       0.324       RMSE                  0.150 \nR-Squared               0.105       MSE                   0.023 \nAdj. R-Squared          0.102       Coef. Var            17.382 \nPred R-Squared          0.097       AIC                -665.999 \nMAE                     0.117       SBC                -647.783 \n----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n               Sum of                                               \n              Squares         DF    Mean Square      F         Sig. \n--------------------------------------------------------------------\nRegression      1.847          2          0.924    41.023    0.0000 \nResidual       15.736        699          0.023                     \nTotal          17.583        701                                    \n--------------------------------------------------------------------\n\n                                 Parameter Estimates                                  \n-------------------------------------------------------------------------------------\n      model     Beta    Std. Error    Std. Beta      t        Sig     lower    upper \n-------------------------------------------------------------------------------------\n(Intercept)    0.553         0.036                 15.199    0.000    0.482    0.625 \n     ageyrs    0.005         0.001        0.268     7.207    0.000    0.003    0.006 \n        sbp    0.001         0.000        0.122     3.289    0.001    0.000    0.001 \n-------------------------------------------------------------------------------------\n\n\nCode\nplot(both.fit.aic)\n\n\n\n\n\n\n\n\n\n\n\n5.5.7 Pick the best predicting model.\nThe output below is divided into two tables. The first picks out the best 1, 2, 3, etc predictir model. Hence the best 3 predictor model for our linear regression is sbp ageyrs totchol. However, to pick the best model out of the lot, in case 6, we look at the second table. The best will have a high R-Square Adj.R-Square and Pred R-Square. Also, the best model will give the lower C(p), AIC, SBIC, SBC, MSEP, FPE, HSP, and APC. Looking at our output it appears the best will be the 2 predictor mode of lm(cca_0 ~ ageyrs + sbp).\n\n\nCode\nmodcompare &lt;- \n    olsrr::ols_step_best_subset(lm1)\n\nmodcompare\n\n\n             Best Subsets Regression             \n-------------------------------------------------\nModel Index    Predictors\n-------------------------------------------------\n     1         ageyrs                             \n     2         sbp ageyrs                         \n     3         sbp ageyrs totchol                 \n     4         sbp ageyrs totchol whratio         \n     5         sbp dbp ageyrs totchol whratio     \n     6         sbp dbp ldl ageyrs totchol whratio \n-------------------------------------------------\n\n                                                     Subsets Regression Summary                                                      \n-------------------------------------------------------------------------------------------------------------------------------------\n                       Adj.        Pred                                                                                               \nModel    R-Square    R-Square    R-Square     C(p)         AIC          SBIC          SBC        MSEP       FPE       HSP       APC  \n-------------------------------------------------------------------------------------------------------------------------------------\n  1        0.0912      0.0899      0.0858    10.5636    -657.2199    -2649.4469    -643.5581    16.0250    0.0229    0.0000    0.9140 \n  2        0.1050      0.1025      0.0968     1.7667    -665.9991    -2658.1525    -647.7834    15.8035    0.0226    0.0000    0.9026 \n  3        0.1069      0.1031      0.0961     2.3041    -665.4722    -2657.5966    -642.7025    15.7930    0.0226    0.0000    0.9033 \n  4        0.1084      0.1033      0.0952     3.1292    -664.6577    -2656.7487    -637.3341    15.7890    0.0227    0.0000    0.9044 \n  5        0.1086      0.1022      0.0929     5.0269    -662.7610    -2654.8305    -630.8835    15.8093    0.0227    0.0000    0.9068 \n  6        0.1086      0.1009      0.0912     7.0000    -660.7882    -2652.8371    -624.3567    15.8315    0.0228    0.0000    0.9094 \n-------------------------------------------------------------------------------------------------------------------------------------\nAIC: Akaike Information Criteria \n SBIC: Sawa's Bayesian Information Criteria \n SBC: Schwarz Bayesian Criteria \n MSEP: Estimated error of prediction, assuming multivariate normality \n FPE: Final Prediction Error \n HSP: Hocking's Sp \n APC: Amemiya Prediction Criteria",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Linear Regression</span>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html",
    "href": "anova-oneway.html",
    "title": "6  Oneway ANOVA",
    "section": "",
    "text": "6.1 Background\nOneway analysis of variance is used when there are more than two levels of a predictor variable and one dependent variable.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html#hypothesis",
    "href": "anova-oneway.html#hypothesis",
    "title": "6  Oneway ANOVA",
    "section": "6.2 Hypothesis",
    "text": "6.2 Hypothesis\nH0 - There is no difference in the means for each group\nHa - At least one of the means is significantly different from the others",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html#assumptions",
    "href": "anova-oneway.html#assumptions",
    "title": "6  Oneway ANOVA",
    "section": "6.3 Assumptions",
    "text": "6.3 Assumptions\n\nNormality – Each sample should be drawn from a normally distributed population. It is not required for large sample sizes. If normality is violated use Kruskal-Wallis test\nEqual Variance - The variance of all the groups must be similar. If variances are equal, use ANOVA. If variances are not equal, use the Welch ANOVA\nIndependence - The observation in each group must be independent from each other. They must also come from a random process.\nOutlier - Data should be devoid of significant outliers",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html#data",
    "href": "anova-oneway.html#data",
    "title": "6  Oneway ANOVA",
    "section": "6.4 Data",
    "text": "6.4 Data\nWe look at data from a nursery of newborns, comparing their weights after grouping their 5-minute APGAR scores into Low (0-3), Medium(4-7), and High (8-10).\n\n\nCode\ndf_babies &lt;- \n    readxl::read_xlsx(\"C:/Dataset/mbu2.xlsx\") %&gt;% \n    filter(age == 0 & apgar2 &lt;= 10 & sex != \"Missing\" & wt &lt; 7.5) %&gt;% \n    select(apgar5 = apgar2, bwt = wt, sex) %&gt;% \n    drop_na() %&gt;% \n    mutate(\n        sex = factor(sex),\n        apgar5 = case_when(\n            apgar5 &lt; 4 ~ \"0-3\",\n            apgar5 &lt; 8 ~ \"4-7\",\n            apgar5 &lt;= 10 ~ \"8-10\") %&gt;% \n            factor(levels = c(\"0-3\", \"4-7\", \"8-10\"), ordered = TRUE))\n\ndf_babies %&gt;% \n    summarytools::dfSummary(graph.col = F)\n\n\nData Frame Summary  \ndf_babies  \nDimensions: 3356 x 3  \nDuplicates: 3113  \n\n-----------------------------------------------------------------------------------------\nNo   Variable            Stats / Values         Freqs (% of Valid)   Valid      Missing  \n---- ------------------- ---------------------- -------------------- ---------- ---------\n1    apgar5              1. 0-3                  157 ( 4.7%)         3356       0        \n     [ordered, factor]   2. 4-7                 1438 (42.8%)         (100.0%)   (0.0%)   \n                         3. 8-10                1761 (52.5%)                             \n\n2    bwt                 Mean (sd) : 2.6 (1)    50 distinct values   3356       0        \n     [numeric]           min &lt; med &lt; max:                            (100.0%)   (0.0%)   \n                         0.4 &lt; 2.7 &lt; 5.5                                                 \n                         IQR (CV) : 1.5 (0.4)                                            \n\n3    sex                 1. Female              1510 (45.0%)         3356       0        \n     [factor]            2. Male                1846 (55.0%)         (100.0%)   (0.0%)   \n-----------------------------------------------------------------------------------------\n\n\nData summary and visualization\n\n\nCode\ndf_babies %&gt;% \n    group_by(apgar5) %&gt;% \n    summarise(across(\n        .cols = c(bwt), \n        .fns = list(\n            \"Mean\" = ~mean(.x), \n            \"SD\" = ~sd(.x),\n            \"Variance\" = ~var(.x),\n            \"N\" = ~n()))) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\napgar5\nbwt_Mean\nbwt_SD\nbwt_Variance\nbwt_N\n\n\n\n\n0-3\n2.095541\n1.1222313\n1.2594031\n157\n\n\n4-7\n2.435814\n0.9477166\n0.8981667\n1438\n\n\n8-10\n2.742476\n0.9409445\n0.8853766\n1761\n\n\n\n\n\n\n\nCode\ndf_babies %&gt;% \n    ggplot(aes(y = bwt, x = apgar5)) + \n    geom_boxplot(alpha = .3) +\n    labs(\n        y = \"Birth Weight (kgs)\", \n        x = \"APGAR\",\n        fill = \"APGAR Category\") +\n    theme_light()\n\n\n\n\n\n\n\n\nFigure 6.1: Distriubution of birth weight for various APGAR categories\n\n\n\n\n\n\n\nCode\ndf_babies %&gt;% \n    ggplot(aes(y = bwt, x = apgar5)) + \n    geom_boxplot(alpha = .3) +\n    labs(\n        y = \"Birth Weight (kgs)\", \n        x = \"APGAR\") +\n    theme_light()+\n    theme(\n        strip.text = element_text(face = \"bold\", size = 12),\n        strip.background = element_rect(fill = \"black\"))+\n    facet_wrap(. ~ sex)\n\n\n\n\n\n\n\n\nFigure 6.2: Distriubution of birth weight for various APGAR categories",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html#fit-model",
    "href": "anova-oneway.html#fit-model",
    "title": "6  Oneway ANOVA",
    "section": "6.5 Fit model",
    "text": "6.5 Fit model\nAll data together\n\n\nCode\ndf_babies %&gt;% \n    rstatix::anova_test(bwt ~ apgar5) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\n\napgar5\n2\n3353\n62.333\n0\n*\n0.036\n\n\n\n\n\nData grouped by sex\n\n\nCode\ndf_babies %&gt;% \n    group_by(sex) %&gt;% \n    rstatix::anova_test(bwt ~ apgar5) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\nsex\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\n\nFemale\napgar5\n2\n1507\n35.698\n0\n*\n0.045\n\n\nMale\napgar5\n2\n1843\n32.912\n0\n*\n0.034",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html#mutltiple-comparison",
    "href": "anova-oneway.html#mutltiple-comparison",
    "title": "6  Oneway ANOVA",
    "section": "6.6 Mutltiple comparison",
    "text": "6.6 Mutltiple comparison\nAll data together\n\n\nCode\ndf_babies %&gt;% \n    rstatix::tukey_hsd(bwt ~ apgar5) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ngroup1\ngroup2\nnull.value\nestimate\nconf.low\nconf.high\np.adj\np.adj.signif\n\n\n\n\napgar5\n0-3\n4-7\n0\n0.3402722\n0.1524480\n0.5280964\n6.58e-05\n****\n\n\napgar5\n0-3\n8-10\n0\n0.6469345\n0.4608135\n0.8330554\n0.00e+00\n****\n\n\napgar5\n4-7\n8-10\n0\n0.3066622\n0.2272388\n0.3860856\n0.00e+00\n****\n\n\n\n\n\nData grouped by sex\n\n\nCode\ndf_babies %&gt;% \n    group_by(sex) %&gt;% \n    rstatix::tukey_hsd(bwt ~ apgar5) %&gt;%  \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex\nterm\ngroup1\ngroup2\nnull.value\nestimate\nconf.low\nconf.high\np.adj\np.adj.signif\n\n\n\n\nFemale\napgar5\n0-3\n4-7\n0\n0.1355326\n-0.1319827\n0.4030478\n4.60e-01\nns\n\n\nFemale\napgar5\n0-3\n8-10\n0\n0.5217204\n0.2573289\n0.7861119\n1.19e-05\n****\n\n\nFemale\napgar5\n4-7\n8-10\n0\n0.3861878\n0.2704095\n0.5019661\n0.00e+00\n****\n\n\nMale\napgar5\n0-3\n4-7\n0\n0.5004289\n0.2419560\n0.7589019\n1.77e-05\n****\n\n\nMale\napgar5\n0-3\n8-10\n0\n0.7532432\n0.4966045\n1.0098818\n0.00e+00\n****\n\n\nMale\napgar5\n4-7\n8-10\n0\n0.2528142\n0.1456318\n0.3599967\n1.00e-07\n****",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "anova-oneway.html#checking-assumptions",
    "href": "anova-oneway.html#checking-assumptions",
    "title": "6  Oneway ANOVA",
    "section": "6.7 Checking assumptions",
    "text": "6.7 Checking assumptions\n\n6.7.1 Plotting\nThis is a large sample size but it will be performed for practice\n\n\nCode\ndf_babies %&gt;% \n    aov(bwt ~ apgar5, data = .) %&gt;% \n    performance::check_model()\n\n\n\n\n\n\n\n\n\nThere appear to be significant violations of the assumptions of the model\n\n\n6.7.2 Testing\n\n6.7.2.1 Normality\n\n\nCode\ndf_babies %&gt;% \n    aov(bwt ~ apgar5, data = .) %&gt;% \n    broom::augment() %&gt;% \n    rstatix::shapiro_test(.resid) %&gt;%\n    mystyle()\n\n\nWarning: The `augment()` method for objects of class `aov` is not maintained by the broom team, and is only supported through the `lm` tidier method. Please be cautious in interpreting and reporting broom output.\n\nThis warning is displayed once per session.\n\n\n\n\n\n\n\n\nvariable\nstatistic\np\n\n\n\n\n.resid\n0.9784008\n3.43482e-22\n\n\n\n\n\n\n\n\n\n6.7.2.2 Equality of variance\n\n\nCode\ndf_babies %&gt;% \n    rstatix::levene_test(bwt ~ apgar5)%&gt;%\n    mystyle()\n\n\n\n\n\n\n\n\ndf1\ndf2\nstatistic\np\n\n\n\n\n2\n3353\n11.77934\n7.983371e-06",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Analysis of Variance</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Oneway ANOVA</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html",
    "href": "logistic-regression.html",
    "title": "7  Logistic Regression",
    "section": "",
    "text": "7.1 Reading and visualizing data\nFirst, we read the data and visualize it\nCode\nlibrary(tidyverse)\nadm &lt;- \n    read.table(\"C:/Dataset/Admissions.txt\", header = TRUE) %&gt;% \n    select(-x) %&gt;% \n    tibble()\n\nadm %&gt;% \n    summarytools::dfSummary(graph.col = F)\n\n\nData Frame Summary  \nadm  \nDimensions: 400 x 4  \nDuplicates: 5  \n\n---------------------------------------------------------------------------------------\nNo   Variable    Stats / Values              Freqs (% of Valid)    Valid      Missing  \n---- ----------- --------------------------- --------------------- ---------- ---------\n1    admit       Min  : 0                    0 : 273 (68.2%)       400        0        \n     [integer]   Mean : 0.3                  1 : 127 (31.8%)       (100.0%)   (0.0%)   \n                 Max  : 1                                                              \n\n2    gmat        Mean (sd) : 587.7 (115.5)   26 distinct values    400        0        \n     [integer]   min &lt; med &lt; max:                                  (100.0%)   (0.0%)   \n                 220 &lt; 580 &lt; 800                                                       \n                 IQR (CV) : 140 (0.2)                                                  \n\n3    gpa         Mean (sd) : 3.4 (0.4)       132 distinct values   400        0        \n     [numeric]   min &lt; med &lt; max:                                  (100.0%)   (0.0%)   \n                 2.3 &lt; 3.4 &lt; 4                                                         \n                 IQR (CV) : 0.5 (0.1)                                                  \n\n4    rank        Mean (sd) : 2.5 (0.9)       1 :  61 (15.2%)       400        0        \n     [integer]   min &lt; med &lt; max:            2 : 151 (37.8%)       (100.0%)   (0.0%)   \n                 1 &lt; 2 &lt; 4                   3 : 121 (30.2%)                           \n                 IQR (CV) : 1 (0.4)          4 :  67 (16.8%)                           \n---------------------------------------------------------------------------------------",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#assumptions-for-a-logistic-regression",
    "href": "logistic-regression.html#assumptions-for-a-logistic-regression",
    "title": "7  Logistic Regression",
    "section": "7.2 Assumptions for a logistic regression",
    "text": "7.2 Assumptions for a logistic regression\n\nCases are randomly sampled\nData free of bivariate or multivariate outliers\nThe outcome variable is dichotomous\nThe association between the continuous predictor and logit transformation is linear\nModel-free of collinearity",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#building-the-model",
    "href": "logistic-regression.html#building-the-model",
    "title": "7  Logistic Regression",
    "section": "7.3 Building the model",
    "text": "7.3 Building the model\nThen we build a logistic regression model using the rank variable as a numeric variable\n\n\nCode\nmod.1 &lt;- \n    glm(admit ~ .,  data = adm, family = \"binomial\")",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#visualizing-the-model-and-its-properties",
    "href": "logistic-regression.html#visualizing-the-model-and-its-properties",
    "title": "7  Logistic Regression",
    "section": "7.4 Visualizing the model and its properties",
    "text": "7.4 Visualizing the model and its properties\nA summary of the model can be visualized from the summary() function. Next, we use the broom package to display various properties of the model in a tabular form. These can then be used for further analysis.\n\n\nCode\nmod.1 %&gt;% summary()\n\n\n\nCall:\nglm(formula = admit ~ ., family = \"binomial\", data = adm)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.449548   1.132846  -3.045  0.00233 ** \ngmat         0.002294   0.001092   2.101  0.03564 *  \ngpa          0.777014   0.327484   2.373  0.01766 *  \nrank        -0.560031   0.127137  -4.405 1.06e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 499.98  on 399  degrees of freedom\nResidual deviance: 459.44  on 396  degrees of freedom\nAIC: 467.44\n\nNumber of Fisher Scoring iterations: 4\n\n\nCode\nbroom::glance(mod.1)\n\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1          500.     399  -230.  467.  483.     459.         396   400\n\n\nCode\nbroom::augment(mod.1) %&gt;% \n    arrange(desc(.cooksd)) %&gt;% \n    head(10) %&gt;% \n    gt::gt()\n\n\n\n\n\n\n\n\nadmit\ngmat\ngpa\nrank\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n1\n300\n2.84\n2\n-1.6747048\n1.921687\n0.015824364\n1.074078\n0.02179898\n1.937074\n\n\n1\n400\n3.23\n4\n-2.2623363\n2.173188\n0.008445841\n1.072887\n0.02062862\n2.182424\n\n\n1\n580\n2.86\n4\n-2.1369186\n2.120602\n0.009038879\n1.073152\n0.01949815\n2.130251\n\n\n1\n680\n2.42\n1\n-0.5693145\n1.426733\n0.039553560\n1.076001\n0.01894216\n1.455815\n\n\n1\n680\n3.00\n4\n-1.7987408\n1.975802\n0.012174862\n1.073843\n0.01884634\n1.987941\n\n\n1\n480\n3.71\n4\n-1.7058530\n1.935323\n0.011479446\n1.074035\n0.01617082\n1.946528\n\n\n1\n560\n2.65\n3\n-1.7859393\n1.970240\n0.010212491\n1.073878\n0.01554574\n1.980379\n\n\n1\n340\n3.00\n2\n-1.4586242\n1.826316\n0.013837152\n1.074514\n0.01529544\n1.839084\n\n\n1\n520\n2.68\n3\n-1.8543872\n1.999914\n0.008953886\n1.073744\n0.01455841\n2.008928\n\n\n1\n520\n3.74\n4\n-1.5907842\n1.884802\n0.011106681\n1.074267\n0.01393459\n1.895357\n\n\n\n\n\n\n\nThe maximum Cook’s Distance of 0.02 (&lt;0.04) is not very different from the rest and can therefore be said not to have outliers.\nNext, we check for linear association by applying the Box Tidwell test\n\n\nCode\nglm(admit ~ gmat + gmat:log(gmat) + gpa  + gpa:log(gpa) + rank + \n        rank:log(rank), data = adm, family = \"binomial\") %&gt;% \n    broom::tidy()\n\n\n# A tibble: 7 × 5\n  term           estimate std.error statistic p.value\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)     0.913    16.0        0.0572   0.954\n2 gmat            0.0265    0.0626     0.423    0.672\n3 gpa            -2.71     10.3       -0.264    0.792\n4 rank           -1.39      1.04      -1.34     0.180\n5 gmat:log(gmat) -0.00328   0.00848   -0.387    0.699\n6 gpa:log(gpa)    1.57      4.64       0.339    0.734\n7 rank:log(rank)  0.456     0.562      0.811    0.417\n\n\nNone of the variables has a significant interaction and hence the linearity between the variable and the logit of the outcome can be assumed.\nResiduals are referred to as deviant residuals. Also, we have out beta estimates and significance (p-values). Null deviance is a measure of error if you estimate only the model with the intercept term and not the x variable at all at the right. So we compare the value of the Residual deviance to the Null deviance. Also, we can use the AIC, smaller is better here.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#plotting-coefficients",
    "href": "logistic-regression.html#plotting-coefficients",
    "title": "7  Logistic Regression",
    "section": "7.5 Plotting coefficients",
    "text": "7.5 Plotting coefficients\nThe coefficient of the regression can be plotted using the coefplotpackage. This is illustrated below\n\n\nCode\ncoefplot::coefplot(\n    mod.1, \n    predictors=c(\"gpa\", \"rank\", \"gmat\"), \n    guide = \"none\", innerCI = 2, \n    outerCI=0, \n    title = \"Coefficient Plot of Model 1\", \n    ylab = \"Predictors\",\n    decreasing = FALSE,  \n    newNames = c(\n        gpa = \"Grade Point Avg.\", \n        rank = \"Rank of School\",\n        gmat = \"GMAT Score\")) + \n  theme_light()",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#predictions-for-the-model---extracting-and-plotting",
    "href": "logistic-regression.html#predictions-for-the-model---extracting-and-plotting",
    "title": "7  Logistic Regression",
    "section": "7.6 Predictions for the model - Extracting and plotting",
    "text": "7.6 Predictions for the model - Extracting and plotting\nPredictions from the model can be obtained with the effects package. This is illustrated below. First, we predict the model using the gpa, convert it to a tibble, plot the predicted probabilities and finally compare the plotted probabilities for the persons ranked as 1 to 5.\n\n\nCode\nggeffects::ggpredict(model = mod.1, terms = c(\"gpa[all]\"))\n\n\n# Predicted probabilities of admit\n\n gpa | Predicted |     95% CI\n-----------------------------\n2.26 |      0.18 | 0.09, 0.33\n2.78 |      0.25 | 0.18, 0.35\n2.97 |      0.28 | 0.21, 0.36\n3.14 |      0.31 | 0.25, 0.38\n3.31 |      0.34 | 0.29, 0.40\n3.48 |      0.37 | 0.31, 0.43\n3.64 |      0.40 | 0.33, 0.47\n4.00 |      0.47 | 0.36, 0.58\n\nAdjusted for:\n* gmat = 580.00\n* rank =   2.00\n\n\n\nNot all rows are shown in the output. Use `print(..., n = Inf)` to show\n  all rows.\n\n\nCode\nggeffects::ggpredict(model = mod.1, terms = c(\"gpa[all]\")) %&gt;% \n    tibble()\n\n\n# A tibble: 132 × 6\n       x predicted std.error conf.low conf.high group\n   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;\n 1  2.26     0.185     0.395   0.0947     0.330 1    \n 2  2.42     0.204     0.346   0.115      0.336 1    \n 3  2.48     0.212     0.328   0.124      0.338 1    \n 4  2.52     0.217     0.315   0.130      0.340 1    \n 5  2.55     0.221     0.306   0.135      0.341 1    \n 6  2.56     0.223     0.303   0.136      0.342 1    \n 7  2.62     0.231     0.286   0.146      0.344 1    \n 8  2.63     0.232     0.283   0.148      0.345 1    \n 9  2.65     0.235     0.277   0.152      0.346 1    \n10  2.67     0.238     0.271   0.155      0.347 1    \n# ℹ 122 more rows\n\n\nCode\nggeffects::ggpredict(model = mod.1, terms = c(\"gpa[all]\")) %&gt;% \n    plot()\n\n\n\n\n\n\n\n\n\nCode\nglm(admit ~ gpa*rank + gmat,  data = adm, family = \"binomial\") %&gt;% \n    ggeffects::ggpredict(terms = c(\"gpa[all]\", \"rank[2,4]\")) %&gt;% \n    plot()",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#comparing-two-nested-models",
    "href": "logistic-regression.html#comparing-two-nested-models",
    "title": "7  Logistic Regression",
    "section": "7.7 Comparing two nested models",
    "text": "7.7 Comparing two nested models\nWe can compare the two models using the anova function in R. The first one is the Null Mode and the other includes the gpa variable. This we do with the analysis of the deviance table as below. Remember these must be nested in each other.\n\n\nCode\nfirst_model &lt;- \n    glm(admit ~ 1,  data = adm, family = \"binomial\")\nsecond_model &lt;- \n    glm(admit ~ gpa,  data = adm, family = \"binomial\")\nanova(first_model, second_model, test = \"Chisq\") %&gt;% \n    broom::tidy() %&gt;% \n    gt::gt() %&gt;% \n    gt::opt_stylize(style = 6, color = \"gray\")\n\n\n\n\n\n\n\n\nterm\ndf.residual\nresidual.deviance\ndf\ndeviance\np.value\n\n\n\n\nadmit ~ 1\n399\n499.9765\nNA\nNA\nNA\n\n\nadmit ~ gpa\n398\n486.9676\n1\n13.0089\n0.0003100148\n\n\n\n\n\n\n\nCode\nrm(first_model, second_model)\n\n\nResults indicate a significant improvement between the Null model and the one with the gpa as a predictor\n\n7.7.1 ROC curves for model\nNext, we compute the predicted probabilities of being admitted for each individual. And then generate ROC curves after we re-categorize standard error of the Rank variable into High and Low.\n\n\nCode\ndata.frame(\n    adm = adm$admit, \n    pred = mod.1$fitted.values, \n    rank2 = ifelse(adm$rank &gt; 2, \"High\", \"Low\") %&gt;% \n        as.factor()) %&gt;% \n    arrange(adm) %&gt;% \n    ggplot(aes(d=adm, m=pred, col=rank2))+ \n    plotROC::geom_roc(n.cuts = 5) + \n    geom_segment(\n        x=0, y=0, xend=1, yend=1, col=\"black\", lty = \"solid\", \n        linewidth = 0.7) +\n    labs(\n        title = \"ROC for the various groups of Ranks\",\n        x = \"1 - Sepcificity\",\n        y = \"Sensitivity\",\n        col = \"Rank\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\nRank is considered as a numeric variable but it is a categorical one so we convert it to one below\n\n\nCode\nadm &lt;- \n    adm %&gt;% \n    mutate(catrank = factor(rank))\nadm\n\n\n# A tibble: 400 × 5\n   admit  gmat   gpa  rank catrank\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;  \n 1     0   380  3.61     3 3      \n 2     1   660  3.67     3 3      \n 3     1   800  4        1 1      \n 4     1   640  3.19     4 4      \n 5     0   520  2.93     4 4      \n 6     1   760  3        2 2      \n 7     1   560  2.98     1 1      \n 8     0   400  3.08     2 2      \n 9     1   540  3.39     3 3      \n10     0   700  3.92     2 2      \n# ℹ 390 more rows\n\n\nAnd then create a second model\n\n\nCode\nmod.2 &lt;- \n    glm(admit ~ gmat + gpa + catrank,  data = adm, family = \"binomial\")\n\nmod.2 %&gt;% \n    summary()\n\n\n\nCall:\nglm(formula = admit ~ gmat + gpa + catrank, family = \"binomial\", \n    data = adm)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.989979   1.139951  -3.500 0.000465 ***\ngmat         0.002264   0.001094   2.070 0.038465 *  \ngpa          0.804038   0.331819   2.423 0.015388 *  \ncatrank2    -0.675443   0.316490  -2.134 0.032829 *  \ncatrank3    -1.340204   0.345306  -3.881 0.000104 ***\ncatrank4    -1.551464   0.417832  -3.713 0.000205 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 499.98  on 399  degrees of freedom\nResidual deviance: 458.52  on 394  degrees of freedom\nAIC: 470.52\n\nNumber of Fisher Scoring iterations: 4\n\n\nWe note a significant change in our Null Deviance and the residual deviance as well as a small AIC.\nNext, we build some confidence intervals using the profile log-likelihood.\n\n\nCode\nmod.2 %&gt;% confint()\n\n\nWaiting for profiling to be done...\n\n\n                    2.5 %       97.5 %\n(Intercept) -6.2716202334 -1.792547080\ngmat         0.0001375921  0.004435874\ngpa          0.1602959439  1.464142727\ncatrank2    -1.3008888002 -0.056745722\ncatrank3    -2.0276713127 -0.670372346\ncatrank4    -2.4000265384 -0.753542605\n\n\nAnd then using the standard errors\n\n\nCode\nmod.2 %&gt;% \n    confint.default()\n\n\n                    2.5 %       97.5 %\n(Intercept) -6.2242418514 -1.755716295\ngmat         0.0001202298  0.004408622\ngpa          0.1536836760  1.454391423\ncatrank2    -1.2957512650 -0.055134591\ncatrank3    -2.0169920597 -0.663415773\ncatrank4    -2.3703986294 -0.732528724\n\n\nNext, we can create a coefficients confidence interval table as below\n\n\nCode\nconf_table &lt;- \n    cbind(mod.2$coefficient, confint(mod.2))\n\n\nWaiting for profiling to be done...\n\n\nCode\nconf_table\n\n\n                                 2.5 %       97.5 %\n(Intercept) -3.989979073 -6.2716202334 -1.792547080\ngmat         0.002264426  0.0001375921  0.004435874\ngpa          0.804037549  0.1602959439  1.464142727\ncatrank2    -0.675442928 -1.3008888002 -0.056745722\ncatrank3    -1.340203916 -2.0276713127 -0.670372346\ncatrank4    -1.551463677 -2.4000265384 -0.753542605\n\n\nWe convert to odd ratios with\n\n\nCode\nexp(conf_table)\n\n\n                            2.5 %    97.5 %\n(Intercept) 0.0185001 0.001889165 0.1665354\ngmat        1.0022670 1.000137602 1.0044457\ngpa         2.2345448 1.173858216 4.3238349\ncatrank2    0.5089310 0.272289674 0.9448343\ncatrank3    0.2617923 0.131641717 0.5115181\ncatrank4    0.2119375 0.090715546 0.4706961\n\n\nWe can also use the epiDisplay package to display this\n\n\nCode\noptions(width = 100)\nepiDisplay::logistic.display(mod.2)\n\n\n\nLogistic regression predicting admit \n \n                  crude OR(95%CI)         adj. OR(95%CI)          P(Wald's test) P(LR-test)\ngmat (cont. var.) 1.0036 (1.0017,1.0055)  1.0023 (1.0001,1.0044)  0.038          0.037     \n                                                                                           \ngpa (cont. var.)  2.86 (1.59,5.14)        2.23 (1.17,4.28)        0.015          0.014     \n                                                                                           \ncatrank: ref.=1                                                                  &lt; 0.001   \n   2              0.47 (0.26,0.86)        0.51 (0.27,0.95)        0.033                    \n   3              0.26 (0.13,0.49)        0.26 (0.13,0.52)        &lt; 0.001                  \n   4              0.19 (0.08,0.41)        0.21 (0.09,0.48)        &lt; 0.001                  \n                                                                                           \nLog-likelihood = -229.2587\nNo. of observations = 400\nAIC value = 470.5175",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#the-lessr-logit-function",
    "href": "logistic-regression.html#the-lessr-logit-function",
    "title": "7  Logistic Regression",
    "section": "7.8 The lessR Logit function",
    "text": "7.8 The lessR Logit function\nThe lessR package gives a detailed output for logistic regression. This is shown below.\n\n\nCode\nlessR::Logit(admit ~ gpa + rank + gmat,  data = adm, brief = F)\n\n\n\nResponse Variable:   admit\nPredictor Variable 1:  gpa\nPredictor Variable 2:  rank\nPredictor Variable 3:  gmat\n\nNumber of cases (rows) of data:  400 \nNumber of cases retained for analysis:  400 \n\n\n   BASIC ANALYSIS \n\n-- Estimated Model of admit for the Logit of Reference Group Membership\n\n             Estimate    Std Err  z-value  p-value   Lower 95%   Upper 95%\n(Intercept)   -3.4495     1.1328   -3.045    0.002     -5.6699     -1.2292 \n        gpa    0.7770     0.3275    2.373    0.018      0.1352      1.4189 \n       rank   -0.5600     0.1271   -4.405    0.000     -0.8092     -0.3108 \n       gmat    0.0023     0.0011    2.101    0.036      0.0002      0.0044 \n\n\n-- Odds Ratios and Confidence Intervals\n\n             Odds Ratio   Lower 95%   Upper 95%\n(Intercept)      0.0318      0.0034      0.2925 \n        gpa      2.1750      1.1447      4.1324 \n       rank      0.5712      0.4452      0.7328 \n       gmat      1.0023      1.0002      1.0044 \n\n\n-- Model Fit\n\n    Null deviance: 499.977 on 399 degrees of freedom\nResidual deviance: 459.442 on 396 degrees of freedom\n\nAIC: 467.4418 \n\nNumber of iterations to convergence: 4 \n\n\nCollinearity\n\n     Tolerance       VIF\ngpa      0.852     1.173\nrank     0.985     1.016\ngmat     0.842     1.188\n\n   ANALYSIS OF RESIDUALS AND INFLUENCE \nData, Fitted, Residual, Studentized Residual, Dffits, Cook's Distance\n   [sorted by Cook's Distance]\n   [res_rows = 20 out of 400 cases (rows) of data]\n--------------------------------------------------------------------\n     gpa rank gmat admit  P(Y=1) residual rstudent  dffits   cooks\n316 2.84    2  300     1 0.15780   0.8422    1.944  0.2287 0.02180\n198 3.23    4  400     1 0.09429   0.9057    2.192  0.1877 0.02063\n156 2.86    4  580     1 0.10556   0.8944    2.139  0.1896 0.01950\n373 2.42    1  680     1 0.36140   0.6386    1.452  0.2746 0.01894\n279 3.00    4  680     1 0.14200   0.8580    1.995  0.2055 0.01885\n319 3.71    4  480     1 0.15370   0.8463    1.952  0.1953 0.01617\n342 2.65    3  560     1 0.14357   0.8564    1.986  0.1873 0.01555\n317 3.00    2  340     1 0.18868   0.8113    1.843  0.2027 0.01530\n40  2.68    3  520     1 0.13536   0.8646    2.014  0.1778 0.01456\n28  3.74    4  520     1 0.16927   0.8307    1.899  0.1870 0.01393\n318 3.63    4  780     1 0.25354   0.7465    1.673  0.2103 0.01372\n4   3.19    4  640     1 0.14895   0.8511    1.965  0.1754 0.01331\n385 2.62    2  480     1 0.19267   0.8073    1.829  0.1902 0.01328\n314 3.65    4  520     1 0.15967   0.8403    1.929  0.1780 0.01311\n395 3.99    3  460     1 0.27406   0.7259    1.625  0.2084 0.01285\n255 3.52    4  740     1 0.22148   0.7785    1.751  0.1950 0.01280\n122 2.67    2  480     1 0.19879   0.8012    1.811  0.1819 0.01192\n294 3.97    1  800     0 0.71307  -0.7131   -1.595 -0.2027 0.01183\n254 3.55    4  540     1 0.15544   0.8446    1.941  0.1667 0.01170\n142 3.52    4  700     1 0.20606   0.7939    1.790  0.1801 0.01142\n\n\n   PREDICTION \n\nProbability threshold for classification : 0.5\n\n\nData, Fitted Values, Standard Errors\n   [sorted by fitted value]\n   [pred_all=TRUE to see all intervals displayed]\n--------------------------------------------------------------------\n     gpa rank gmat admit label  fitted std.err\n290 2.26    4  420     0     0 0.04879 0.02069\n49  2.48    4  440     0     0 0.05990 0.02207\n72  2.92    4  300     0     0 0.06108 0.02257\n84  2.91    4  380     0     0 0.07197 0.02290\n\n... for the rows of data where fitted is close to 0.5 ...\n\n     gpa rank gmat admit label fitted std.err\n271 3.95    2  640     1     0 0.4919 0.04976\n68  3.30    1  620     0     0 0.4942 0.05149\n281 3.94    2  660     0     1 0.5015 0.04891\n91  3.83    2  700     0     1 0.5030 0.04501\n105 3.95    2  660     1     1 0.5034 0.04952\n\n... for the last 4 rows of sorted data ...\n\n     gpa rank gmat admit label fitted std.err\n151 3.74    1  800     1     1 0.6752 0.06168\n13  4.00    1  760     1     1 0.6989 0.06003\n294 3.97    1  800     0     1 0.7131 0.06126\n3   4.00    1  800     1     1 0.7178 0.06139\n--------------------------------------------------------------------\n\n\n----------------------------\nSpecified confusion matrices\n----------------------------\n\nProbability threshold for predicting : 0.5\n\n              Baseline         Predicted \n---------------------------------------------------\n             Total  %Tot        0      1  %Correct \n---------------------------------------------------\n        1      127  31.8       98     29     22.8 \nadmit   0      273  68.2      253     20     92.7 \n---------------------------------------------------\n      Total    400                           70.5 \n\nAccuracy: 70.50 \nSensitivity: 22.83 \nPrecision: 59.18",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic-regression.html#selecting-the-best-model",
    "href": "logistic-regression.html#selecting-the-best-model",
    "title": "7  Logistic Regression",
    "section": "7.9 Selecting the best model",
    "text": "7.9 Selecting the best model\nTo select the best model we first run a stepwise backward regression\n\n\nCode\nmod.3 &lt;- \n    MASS::stepAIC(mod.2, direction = \"backward\", trace = FALSE)\n\nmod.3\n\n\n\nCall:  glm(formula = admit ~ gmat + gpa + catrank, family = \"binomial\", \n    data = adm)\n\nCoefficients:\n(Intercept)         gmat          gpa     catrank2     catrank3     catrank4  \n  -3.989979     0.002264     0.804038    -0.675443    -1.340204    -1.551464  \n\nDegrees of Freedom: 399 Total (i.e. Null);  394 Residual\nNull Deviance:      500 \nResidual Deviance: 458.5    AIC: 470.5\n\n\nAll factors are considered significant and retained in the model\nNext, we run a bootstrap diagnostic retention of variables to determine the best predictive variables\n\n\nCode\nbootStepAIC::boot.stepAIC(mod.2, data = adm, B = 100)\n\n\n\nSummary of Bootstrapping the 'stepAIC()' procedure for\n\nCall:\nglm(formula = admit ~ gmat + gpa + catrank, family = \"binomial\", \n    data = adm)\n\nBootstrap samples: 100 \nDirection: backward \nPenalty: 2 * df\n\nCovariates selected\n        (%)\ncatrank  96\ngmat     82\ngpa      82\n\nCoefficients Sign\n          + (%)  - (%)\ngmat     100.00   0.00\ngpa      100.00   0.00\ncatrank2   1.04  98.96\ncatrank3   0.00 100.00\ncatrank4   0.00 100.00\n\nStat Significance\n           (%)\ncatrank3 97.92\ncatrank4 96.88\ngpa      75.61\ngmat     69.51\ncatrank2 58.33\n\n\nThe stepAIC() for the original data-set gave\n\nCall:  glm(formula = admit ~ gmat + gpa + catrank, family = \"binomial\", \n    data = adm)\n\nCoefficients:\n(Intercept)         gmat          gpa     catrank2     catrank3     catrank4  \n  -3.989979     0.002264     0.804038    -0.675443    -1.340204    -1.551464  \n\nDegrees of Freedom: 399 Total (i.e. Null);  394 Residual\nNull Deviance:      500 \nResidual Deviance: 458.5    AIC: 470.5\n\nStepwise Model Path \nAnalysis of Deviance Table\n\nInitial Model:\nadmit ~ gmat + gpa + catrank\n\nFinal Model:\nadmit ~ gmat + gpa + catrank\n\n\n  Step Df Deviance Resid. Df Resid. Dev      AIC\n1                        394   458.5175 470.5175\n\n\nThe suggested final predictive model therefore is\n\n\nCode\nmod.4 &lt;- \n    glm(admit ~ gmat + gpa + catrank,  data = adm, family = \"binomial\")\n\nepiDisplay::logistic.display(mod.4)\n\n\n\nLogistic regression predicting admit \n \n                  crude OR(95%CI)         adj. OR(95%CI)          P(Wald's test) P(LR-test)\ngmat (cont. var.) 1.0036 (1.0017,1.0055)  1.0023 (1.0001,1.0044)  0.038          0.037     \n                                                                                           \ngpa (cont. var.)  2.86 (1.59,5.14)        2.23 (1.17,4.28)        0.015          0.014     \n                                                                                           \ncatrank: ref.=1                                                                  &lt; 0.001   \n   2              0.47 (0.26,0.86)        0.51 (0.27,0.95)        0.033                    \n   3              0.26 (0.13,0.49)        0.26 (0.13,0.52)        &lt; 0.001                  \n   4              0.19 (0.08,0.41)        0.21 (0.09,0.48)        &lt; 0.001                  \n                                                                                           \nLog-likelihood = -229.2587\nNo. of observations = 400\nAIC value = 470.5175",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Logistic Regression</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html",
    "href": "survival-analysis.html",
    "title": "8  Survival Analysis",
    "section": "",
    "text": "9 Reading and cleaning data\nCode\ndf_mbu &lt;-\n    readxl::read_xlsx(\"C:/Dataset/mbu.xlsx\") %&gt;% \n    janitor::clean_names() %&gt;% \n    select(\n        -c(pt_name, ip, diag1, diag2, diag3, address, \n              disweight, field1, del_date_time)) %&gt;% \n    filter(\n        (outcome %in% c(\"Died\", \"Discharged\")) & \n        (wt &lt; 8 & wt &gt;= 1) & \n        (age &lt; 29) & \n        (sex != \"Missing\") & \n        (place != \"Missing\") &\n        (apgar1 &lt; 11) &\n        (apgar2 &lt; 11) & \n        (!is.na(adm_date_time)) & \n        (!is.na(dis_date_time)) &\n        (del != \"Missing\")) %&gt;% \n    rename(apgar5 = apgar2,\n           del_mode = del) %&gt;% \n    mutate(gestage = ifelse(gestage &gt; 50 | gestage &lt; 26, NA, gestage),\n           place = ifelse(place == \"Self\", \"Home\", place),\n           place = ifelse(\n               place == \"Maternity Home\", \"Clinic/Hospital\", place),\n           across(c(sex, place), ~as.factor(.)),\n           place = fct_relevel(\n               place, c(\"KATH\", \"Clinic/Hospital\", \"Home\")),\n           died = outcome == \"Died\",\n           adm_dura_hrs = difftime(\n               dis_date_time, adm_date_time, units = \"hours\") %&gt;% \n               as.numeric(),\n           adm_dura_hrs = ifelse(\n               adm_dura_hrs &lt; 0 | adm_dura_hrs &gt; 1040, NA, adm_dura_hrs),\n           adm_year = format(adm_date_time, \"%Y\"),\n           outcome = factor(outcome, levels = c(\"Discharged\",\"Died\")),\n           del_mode = ifelse(\n               del_mode %in% c(\"Forceps\", \"Vacuum\"), \n               \"Assisted VD\", del_mode) %&gt;% \n               factor(levels = c(\"SVD\", \"C/S\", \"Assisted VD\"))) %&gt;% \n    select(-c(adm_date_time, dis_date_time)) %&gt;% \n    filter(adm_year != \"2012\" & !is.na(adm_dura_hrs))",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#weekly-survival",
    "href": "survival-analysis.html#weekly-survival",
    "title": "8  Survival Analysis",
    "section": "14.1 Weekly survival",
    "text": "14.1 Weekly survival\n\n\nCode\nsummary(km_by_sex, times = seq(0, 1040, by = 24*7))\n\n\nCall: survfit(formula = survival::Surv(event = died, time = adm_dura_hrs) ~ \n    sex, data = .)\n\n                sex=Female \n time n.risk n.event survival  std.err lower 95% CI upper 95% CI\n    0   3292       3    0.999 0.000526        0.998        1.000\n  168   1087     423    0.851 0.006897        0.838        0.865\n  336    348      33    0.803 0.010707        0.782        0.824\n  504    175      12    0.770 0.013998        0.743        0.797\n  672     83       9    0.709 0.023494        0.665        0.757\n  840     24      14    0.557 0.041019        0.483        0.644\n 1008      1       0    0.557 0.041019        0.483        0.644\n\n                sex=Male \n time n.risk n.event survival  std.err lower 95% CI upper 95% CI\n    0   4210       5    0.999 0.000531        0.998        1.000\n  168   1186     585    0.839 0.006366        0.827        0.851\n  336    296      49    0.777 0.010880        0.756        0.799\n  504    140      17    0.717 0.017530        0.683        0.752\n  672     79       6    0.672 0.024214        0.626        0.721\n  840     31       8    0.580 0.036905        0.512        0.657\n 1008      4       2    0.520 0.054000        0.425        0.638\n\n\n\n\nCode\nkm_by_sex %&gt;% \n    survminer::ggsurvplot(\n        data = df_mbu,\n        pval = T,\n        risk.table = T, \n        censor = F,\n        font.x = c(10, \"bold.italic\", \"red\"),\n        font.y = c(10, \"bold.italic\", \"darkred\"),\n        font.tickslab = c(10, \"plain\", \"darkgreen\"),\n        tables.theme = survminer::theme_cleantable(),\n        conf.int=T,\n        tables.height = 0.2,\n        break.x.by = 24*7,\n        legend.title = \"\",\n        surv.scale = \"percent\")",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#checking-the-model",
    "href": "survival-analysis.html#checking-the-model",
    "title": "8  Survival Analysis",
    "section": "18.1 Checking the model",
    "text": "18.1 Checking the model\n\n\nCode\nperformance::performance(cox_1)\n\n\nResponse residuals not available to calculate mean square error. (R)MSE\n  is probably not reliable.\n\n\nWarning: Can't calculate weighted residuals from model.\n\n\n# Indices of model performance\n\nAIC       |      AICc |       BIC | Nagelkerke's R2 |  RMSE | Sigma\n-------------------------------------------------------------------\n18651.333 | 18651.375 | 18734.408 |           0.139 | 0.413 | 0.000\n\n\nCode\nperformance::performance(cox_2)\n\n\nResponse residuals not available to calculate mean square error. (R)MSE\n  is probably not reliable.\n\n\nWarning: Can't calculate weighted residuals from model.\n\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | Nagelkerke's R2 |  RMSE | Sigma\n----------------------------------------------------------------\n9244.289 | 9244.365 | 9328.463 |           0.135 | 0.377 | 0.000",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#compare-two-multivariate-models-obviously-second-is-better-than-first",
    "href": "survival-analysis.html#compare-two-multivariate-models-obviously-second-is-better-than-first",
    "title": "8  Survival Analysis",
    "section": "18.2 Compare two multivariate models: Obviously second is better than first",
    "text": "18.2 Compare two multivariate models: Obviously second is better than first\n\n\nCode\nperformance::compare_performance(cox_1, cox_2)\n\n\nWhen comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName  | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) | Nagelkerke's R2 |  RMSE | Sigma\n-----------------------------------------------------------------------------------------------------\ncox_1 | coxph | 18651.3 (&lt;.001) | 18651.4 (&lt;.001) | 18734.4 (&lt;.001) |           0.139 | 0.413 | 0.000\ncox_2 | coxph |  9244.3 (&gt;.999) |  9244.4 (&gt;.999) |  9328.5 (&gt;.999) |           0.135 | 0.377 | 0.000",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#checking-for-proportional-hazard-assumption",
    "href": "survival-analysis.html#checking-for-proportional-hazard-assumption",
    "title": "8  Survival Analysis",
    "section": "18.3 Checking for proportional hazard assumption",
    "text": "18.3 Checking for proportional hazard assumption\nSignificant p-values indicates Proportional Hazard assumption violated\n\n\nCode\ncox_1 %&gt;% survival::cox.zph()\n\n\n            chisq df       p\nwt        0.00917  1  0.9237\nage       8.38652  1  0.0038\nsex       2.54003  1  0.1110\nplace     6.94463  2  0.0310\napgar1   30.05277  1 4.2e-08\napgar5   38.45559  1 5.6e-10\ndel_mode  2.09712  2  0.3504\nadm_year 10.39820  3  0.0155\nGLOBAL   72.90917 12 9.1e-11\n\n\nResiduals falling outside the standard error margins indicates Proportional Hazard assumption violated. These violations will have to be dealt with.\n\n\nCode\ncox_1 %&gt;% survival::cox.zph() %&gt;% survminer::ggcoxzph()\n\n\nWarning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):\ncollapsing to unique 'x' values",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#without-gestational-age",
    "href": "survival-analysis.html#without-gestational-age",
    "title": "8  Survival Analysis",
    "section": "19.1 Without gestational age",
    "text": "19.1 Without gestational age\n\n\nCode\ncox_1A &lt;-\n    df_mbu %&gt;% \n    select(-c(outcome, gestage)) %&gt;%\n    gtsummary::tbl_uvregression(\n        method = survival::coxph, \n        y = survival::Surv(event = died, time = adm_dura_hrs),\n        exponentiate = TRUE, \n        pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3)) %&gt;% \n    gtsummary::bold_labels() %&gt;% \n    gtsummary::bold_p()\n\ncox_1B &lt;- \n    df_mbu %&gt;% \n    select(-c(outcome, gestage)) %&gt;% \n    survival::coxph(\n        survival::Surv(\n            event = died, time = adm_dura_hrs) ~ ., data = .) %&gt;% \n    gtsummary::tbl_regression(\n        exponentiate = TRUE,\n        pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3)) %&gt;% \n    gtsummary::bold_labels() %&gt;% \n    gtsummary::bold_p()\n\ngtsummary::tbl_merge(\n    tbls = list(cox_1A, cox_1B),\n    tab_spanner = c(\"Univariate\", \"Multivariate\")) %&gt;% \n    gtsummary::modify_caption(\n        \"Combined Univariate and Multivariate Cox regression with sex\")\n\n\n\n\n\n\nCombined Univariate and Multivariate Cox regression with sex\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nUnivariate\n\n\nMultivariate\n\n\n\nN\nHR\n1\n95% CI\n1\np-value\nHR\n1\n95% CI\n1\np-value\n\n\n\n\nWeight in kgs\n7,502\n0.66\n0.61, 0.70\n&lt;0.001\n0.70\n0.66, 0.75\n&lt;0.001\n\n\nAge in days\n7,502\n1.00\n0.96, 1.05\n0.839\n1.01\n0.97, 1.06\n0.558\n\n\nSex\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Female\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    Male\n\n\n1.13\n1.01, 1.27\n0.034\n1.17\n1.04, 1.31\n0.010\n\n\nPlace of delivery\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    KATH\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    Clinic/Hospital\n\n\n2.29\n2.03, 2.57\n&lt;0.001\n1.85\n1.64, 2.09\n&lt;0.001\n\n\n    Home\n\n\n1.57\n0.89, 2.78\n0.122\n1.39\n0.78, 2.47\n0.261\n\n\nFirst minute APGAR\n7,502\n0.72\n0.70, 0.74\n&lt;0.001\n0.96\n0.90, 1.01\n0.113\n\n\nFifth minute APGAR\n7,502\n0.66\n0.64, 0.68\n&lt;0.001\n0.69\n0.66, 0.74\n&lt;0.001\n\n\nMode of delivery\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    SVD\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    C/S\n\n\n0.64\n0.57, 0.72\n&lt;0.001\n1.20\n1.06, 1.36\n0.005\n\n\n    Assisted VD\n\n\n0.53\n0.33, 0.88\n0.013\n0.92\n0.56, 1.51\n0.738\n\n\nYear of admission\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    2013\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    2014\n\n\n0.77\n0.67, 0.89\n&lt;0.001\n0.74\n0.64, 0.85\n&lt;0.001\n\n\n    2015\n\n\n0.72\n0.61, 0.84\n&lt;0.001\n0.82\n0.69, 0.96\n0.017\n\n\n    2016\n\n\n0.84\n0.70, 1.01\n0.063\n0.93\n0.77, 1.12\n0.464\n\n\n\n1\nHR = Hazard Ratio, CI = Confidence Interval",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#with-gestational-age",
    "href": "survival-analysis.html#with-gestational-age",
    "title": "8  Survival Analysis",
    "section": "19.2 With gestational age",
    "text": "19.2 With gestational age\n\n\nCode\ncox_2A &lt;-\n    df_mbu %&gt;% \n    select(-c(outcome)) %&gt;%\n    gtsummary::tbl_uvregression(\n        method = survival::coxph, \n        y = survival::Surv(event = died, time = adm_dura_hrs),\n        exponentiate = TRUE, \n        pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3)) %&gt;% \n    gtsummary::bold_labels() %&gt;% \n    gtsummary::bold_p()\n\ncox_2B &lt;- \n    df_mbu %&gt;% \n    select(-c(outcome)) %&gt;% \n    survival::coxph(\n        survival::Surv(\n            event = died, time = adm_dura_hrs) ~ ., data = .) %&gt;% \n    gtsummary::tbl_regression(\n        pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3),\n        exponentiate = TRUE) %&gt;% \n    gtsummary::bold_labels() %&gt;% \n    gtsummary::bold_p()\n\ngtsummary::tbl_merge(\n    tbls = list(cox_2A, cox_2B),\n    tab_spanner = c(\"Univariate\", \"Multivariate\")) %&gt;% \n    gtsummary::modify_caption(\n        \"Combined Univariate and Multivariate Cox regression with sex\")\n\n\n\n\n\n\nCombined Univariate and Multivariate Cox regression with sex\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nUnivariate\n\n\nMultivariate\n\n\n\nN\nHR\n1\n95% CI\n1\np-value\nHR\n1\n95% CI\n1\np-value\n\n\n\n\nWeight in kgs\n7,502\n0.66\n0.61, 0.70\n&lt;0.001\n0.69\n0.59, 0.81\n&lt;0.001\n\n\nAge in days\n7,502\n1.00\n0.96, 1.05\n0.839\n1.03\n0.99, 1.08\n0.163\n\n\nSex\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Female\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    Male\n\n\n1.13\n1.01, 1.27\n0.034\n1.09\n0.93, 1.28\n0.299\n\n\nPlace of delivery\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    KATH\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    Clinic/Hospital\n\n\n2.29\n2.03, 2.57\n&lt;0.001\n1.60\n1.34, 1.93\n&lt;0.001\n\n\n    Home\n\n\n1.57\n0.89, 2.78\n0.122\n1.29\n0.64, 2.61\n0.475\n\n\nFirst minute APGAR\n7,502\n0.72\n0.70, 0.74\n&lt;0.001\n0.97\n0.90, 1.05\n0.457\n\n\nFifth minute APGAR\n7,502\n0.66\n0.64, 0.68\n&lt;0.001\n0.67\n0.62, 0.73\n&lt;0.001\n\n\nMode of delivery\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    SVD\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    C/S\n\n\n0.64\n0.57, 0.72\n&lt;0.001\n1.22\n1.03, 1.45\n0.025\n\n\n    Assisted VD\n\n\n0.53\n0.33, 0.88\n0.013\n1.36\n0.74, 2.51\n0.324\n\n\nGestational age\n4,793\n0.90\n0.88, 0.91\n&lt;0.001\n0.97\n0.94, 1.00\n0.048\n\n\nYear of admission\n7,502\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    2013\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    2014\n\n\n0.77\n0.67, 0.89\n&lt;0.001\n0.74\n0.59, 0.92\n0.007\n\n\n    2015\n\n\n0.72\n0.61, 0.84\n&lt;0.001\n0.90\n0.71, 1.14\n0.376\n\n\n    2016\n\n\n0.84\n0.70, 1.01\n0.063\n1.04\n0.80, 1.34\n0.787\n\n\n\n1\nHR = Hazard Ratio, CI = Confidence Interval",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "survival-analysis.html#plotting-coefficients",
    "href": "survival-analysis.html#plotting-coefficients",
    "title": "8  Survival Analysis",
    "section": "19.3 Plotting coefficients",
    "text": "19.3 Plotting coefficients\n\n\nCode\ndf_mbu %&gt;% \n    select(-c(outcome)) %&gt;% \n    survival::coxph(\n        survival::Surv(event = died, time = adm_dura_hrs) ~ ., \n        data = .) %&gt;% \n    sjPlot::plot_model(\n        value.offset = 0.4,show.values = T, show.p = T) +\n    geom_hline(yintercept = 1, alpha =.5, color = 'grey45') +\n    labs(\n        title = \"Coefficients Plot of Hazard Ratios\", \n        y = \"Hazard ratio (95%CI)\") +\n    theme_minimal() +\n    scale_y_log10(limits = c(0.4, 5))\n\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Survival Analysis</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "pkg-dplyr.html",
    "href": "pkg-dplyr.html",
    "title": "9  dplyr Package",
    "section": "",
    "text": "10 Creating function to configrure tables\nCode\ntbl_style &lt;- function(df){\n    df %&gt;% \n        gt::gt() %&gt;% \n        gt::tab_options(\n            table.font.size = 14, \n            table.font.names = \"serif\", \n            data_row.padding = gt::px(2)\n        ) %&gt;% \n        gt::opt_stylize(style = 5)\n}",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>`dplyr` Package</span>"
    ]
  },
  {
    "objectID": "pkg-dplyr.html#arrange",
    "href": "pkg-dplyr.html#arrange",
    "title": "9  dplyr Package",
    "section": "13.1 arrange",
    "text": "13.1 arrange\n\n\nCode\ndat %&gt;% \n    arrange(name, desc(day))\n\n\n# A tibble: 5 × 5\n  name     day month  year bp    \n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n1 Akosua    21    12  2010 110/76\n2 Ama       12     5  2020 120/80\n3 Kwame     14     2  2019 132/66\n4 Yaa       19     8  2000 117/77\n5 Yaw       13     3  1982 144/98",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>`dplyr` Package</span>"
    ]
  },
  {
    "objectID": "pkg-dplyr.html#unite",
    "href": "pkg-dplyr.html#unite",
    "title": "9  dplyr Package",
    "section": "13.2 unite()",
    "text": "13.2 unite()\n\n\nCode\ndat %&gt;% \n    unite(col = \"dob\", c(day, month, year), sep=\"/\") %&gt;% \n    tbl_style()\n\n\n\n\n\n\n\n\nname\ndob\nbp\n\n\n\n\nAma\n12/5/2020\n120/80\n\n\nKwame\n14/2/2019\n132/66\n\n\nAkosua\n21/12/2010\n110/76\n\n\nYaw\n13/3/1982\n144/98\n\n\nYaa\n19/8/2000\n117/77",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>`dplyr` Package</span>"
    ]
  },
  {
    "objectID": "pkg-dplyr.html#seperate",
    "href": "pkg-dplyr.html#seperate",
    "title": "9  dplyr Package",
    "section": "13.3 seperate()",
    "text": "13.3 seperate()\n\n\nCode\ndat %&gt;% \n    separate(col = bp, into = c(\"sbp\", \"dbp\"), sep = \"/\") %&gt;% \n    tbl_style()\n\n\n\n\n\n\n\n\nname\nday\nmonth\nyear\nsbp\ndbp\n\n\n\n\nAma\n12\n5\n2020\n120\n80\n\n\nKwame\n14\n2\n2019\n132\n66\n\n\nAkosua\n21\n12\n2010\n110\n76\n\n\nYaw\n13\n3\n1982\n144\n98\n\n\nYaa\n19\n8\n2000\n117\n77\n\n\n\n\n\n\n\n\n\nCode\ndat %&gt;% \n    separate(col = bp, into = c(\"sbp\", \"dbp\"), sep = \"/\") %&gt;% \n    unite(col = \"dob\", c(day, month, year), sep=\"/\") %&gt;% \n    mutate(dob_new = lubridate::dmy(dob)) %&gt;% \n    tbl_style()\n\n\n\n\n\n\n\n\nname\ndob\nsbp\ndbp\ndob_new\n\n\n\n\nAma\n12/5/2020\n120\n80\n2020-05-12\n\n\nKwame\n14/2/2019\n132\n66\n2019-02-14\n\n\nAkosua\n21/12/2010\n110\n76\n2010-12-21\n\n\nYaw\n13/3/1982\n144\n98\n1982-03-13\n\n\nYaa\n19/8/2000\n117\n77\n2000-08-19",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>`dplyr` Package</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html",
    "href": "pkg-gtsummary.html",
    "title": "10  gtsummary",
    "section": "",
    "text": "11 Reading in the data\nCode\ndf_cint_all &lt;- dget(\"C:/Dataset/cint_data_clean\")\ndf_mbu &lt;- readxl::read_xlsx(\"C:/Dataset/mbu.xlsx\")",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#table-1",
    "href": "pkg-gtsummary.html#table-1",
    "title": "10  gtsummary",
    "section": "15.1 Table 1",
    "text": "15.1 Table 1\n\n\nCode\ndf_cint %&gt;% \n    tbl_summary(\n        by = sex,                    # aggregate table by sex\n        missing_text = \"(Missing)\",  # Label missing data as such\n        type = sbp ~ \"continuous2\",  # Report sbp with 2 or more statistics\n        statistic = list(sbp ~ c(\"{mean},({sd})\",\n                                 \"({min},{max})\"),\n                         bmicat ~ \"{n}/{N} ({p}%)\",\n                         bulb_0 ~ c(\"{mean} ({sd})\")),\n        label = bmi ~ \"BMI (Kg/m sq.)\",   # To modify labels\n        digits = dbp ~ 1) %&gt;%         # Force dbp to have one decimal\n    add_overall(last = T) %&gt;%           # Add overall column\n    modify_spanning_header(all_stat_cols() ~ \"**Sex of Participants**\") %&gt;% \n    add_p(pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3)) %&gt;%    # Adds p-value column\n    add_q(method = \"fdr\",                   #Add p-value for multiple comparison\n          pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3)) %&gt;% \n    add_stat_label() %&gt;%        # Add specific stats to each variable\n    add_n() %&gt;%                     # Add valid observation to each variable\n    bold_p() %&gt;%       # Bold significant p-values\n    add_significance_stars()   # add significance stars\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\n\nSex of Participants\n\np-value\n1\nq-value\n2\n\n\nFemale\nN = 554\nMale\nN = 158\nOverall\nN = 712\n\n\n\n\nBulb diameter at time 0, Mean (SD)\n712\n0.90 (0.22)\n0.93 (0.20)\n0.91 (0.22)\n0.035*\n0.082\n\n\nBulb diameter at 12 months, Median (Q1, Q3)\n363\n0.83 (0.70, 0.95)\n0.85 (0.68, 0.98)\n0.83 (0.70, 0.95)\n0.683\n0.683\n\n\n    (Missing)\n\n\n262\n87\n349\n\n\n\n\n\n\nBMI (Kg/m sq.), Median (Q1, Q3)\n712\n27.1 (23.2, 31.2)\n23.0 (21.0, 25.6)\n26.1 (22.4, 30.1)\n&lt;0.001***\n&lt;0.001\n\n\nSystolic Blood Pressure\n712\n\n\n\n\n\n\n0.242\n0.423\n\n\n    Mean,(SD)\n\n\n125,(24)\n127,(24)\n125,(24)\n\n\n\n\n\n\n    (Min,Max)\n\n\n(66,231)\n(82,199)\n(66,231)\n\n\n\n\n\n\nDiastolic Blood Pressure, Median (Q1, Q3)\n712\n79.0 (70.0, 88.0)\n78.0 (69.0, 90.0)\n79.0 (70.0, 89.0)\n0.563\n0.657\n\n\nCategorized BMI, n/N (%)\n711\n\n\n\n\n\n\n&lt;0.001***\n&lt;0.001\n\n\n    Normal\n\n\n208/553 (38%)\n110/158 (70%)\n318/711 (45%)\n\n\n\n\n\n\n    High\n\n\n345/553 (62%)\n48/158 (30%)\n393/711 (55%)\n\n\n\n\n\n\n    (Missing)\n\n\n1\n0\n1\n\n\n\n\n\n\nHypertension present, n (%)\n712\n314 (57%)\n95 (60%)\n409 (57%)\n0.439\n0.615\n\n\n\n1\np&lt;0.05; p&lt;0.01; p&lt;0.001\n\n\n2\nFalse discovery rate correction for multiple testing",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#table-2",
    "href": "pkg-gtsummary.html#table-2",
    "title": "10  gtsummary",
    "section": "15.2 Table 2",
    "text": "15.2 Table 2\n\n\nCode\ndf_mbu_clean %&gt;% \n    tbl_summary(by = died) %&gt;% \n    add_overall(last = T) %&gt;%\n    add_p() %&gt;% \n    modify_spanning_header(all_stat_cols() ~ \"**Mortality**\") %&gt;% \n    modify_caption(caption = \"**Table 2**: MBU data by outcome\") %&gt;% \n    bold_labels()\n\n\n\n\n\n\nTable 2: MBU data by outcome\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nMortality\n\np-value\n2\n\n\nNo\nN = 4,257\n1\nYes\nN = 727\n1\nOverall\nN = 4,984\n1\n\n\n\n\nWeight (kgs)\n2.80 (2.00, 3.30)\n1.60 (1.10, 2.70)\n2.70 (1.90, 3.30)\n&lt;0.001\n\n\nAge (days)\n0.00 (0.00, 1.00)\n0.00 (0.00, 1.00)\n0.00 (0.00, 1.00)\n0.008\n\n\nSex\n\n\n\n\n\n\n0.6\n\n\n    Female\n1,887 (44%)\n329 (45%)\n2,216 (44%)\n\n\n\n\n    Male\n2,370 (56%)\n398 (55%)\n2,768 (56%)\n\n\n\n\nPlace of birth\n\n\n\n\n\n\n&lt;0.001\n\n\n    Clinic/Hospital\n601 (14%)\n195 (27%)\n796 (16%)\n\n\n\n\n    Home\n55 (1.3%)\n9 (1.2%)\n64 (1.3%)\n\n\n\n\n    KATH\n3,594 (84%)\n520 (72%)\n4,114 (83%)\n\n\n\n\n    Maternity Home\n7 (0.2%)\n3 (0.4%)\n10 (0.2%)\n\n\n\n\nAPGAR (min 1)\n6.00 (4.00, 7.00)\n4.00 (2.00, 6.00)\n6.00 (4.00, 7.00)\n&lt;0.001\n\n\nMode of delivery\n\n\n\n\n\n\n&lt;0.001\n\n\n    C/S\n2,344 (55%)\n318 (44%)\n2,662 (53%)\n\n\n\n\n    SVD\n1,790 (42%)\n398 (55%)\n2,188 (44%)\n\n\n\n\n    Vacuum\n123 (2.9%)\n11 (1.5%)\n134 (2.7%)\n\n\n\n\nGestational Age\n38.0 (35.0, 40.0)\n34.0 (29.0, 39.0)\n38.0 (34.0, 40.0)\n&lt;0.001\n\n\nAPGAR (min 5)\n8.00 (7.00, 9.00)\n6.00 (5.00, 7.00)\n8.00 (7.00, 9.00)\n&lt;0.001\n\n\nAdmission duration\n5 (3, 8)\n1 (0, 4)\n5 (2, 8)\n&lt;0.001\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n2\nWilcoxon rank sum test; Pearson’s Chi-squared test; Fisher’s exact test",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#table-3",
    "href": "pkg-gtsummary.html#table-3",
    "title": "10  gtsummary",
    "section": "15.3 Table 3",
    "text": "15.3 Table 3\nThis is table 3 of many😉\n1\n\n\nCode\ndf_cint %&gt;% \n    tbl_summary(\n        by = sex,                    # aggregate table by sex\n        statistic = all_continuous() ~ \"{mean} ({sd})\") %&gt;% # Stats touse for all continuous variables\n    add_stat_label(label = all_continuous()~ \"Mean(StD)\") %&gt;% # Label to give statistics\n    add_difference() %&gt;%    # Add a difeference, ci and p-value column\n    modify_spanning_header(all_stat_cols()~ \"**Sex**\") %&gt;%  # Add spanning header\n    modify_caption(\"**Table 1. Patient Characteristics**\") %&gt;% # Add table title\n    italicize_levels() %&gt;%  # Italics for the levels\n    bold_labels()   # Bold fo rhe labels\n\n\nThe following errors were returned during `modify_caption()`:\n✖ For variable `hpt` (`sex`) and \"estimate\", \"statistic\", \"p.value\",\n  \"parameter\", \"conf.low\", and \"conf.high\" statistics: Expecting `variable` to\n  be either &lt;logical&gt; or &lt;numeric/integer&gt; coded as 0 and 1.\n\n\n\n\n\n\nTable 1. Patient Characteristics\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nSex\n\nDifference\n1\n95% CI\n1,2\np-value\n1\n\n\nFemale\nN = 554\nMale\nN = 158\n\n\n\n\nBulb diameter at time 0, Mean(StD)\n0.90 (0.22)\n0.93 (0.20)\n-0.03\n-0.07, 0.01\n0.095\n\n\nBulb diameter at 12 months, Mean(StD)\n0.85 (0.23)\n0.87 (0.29)\n-0.02\n-0.10, 0.05\n0.5\n\n\n    Unknown\n262\n87\n\n\n\n\n\n\n\n\nBody Mass Index, Mean(StD)\n27.4 (5.7)\n23.7 (4.0)\n3.7\n3.0, 4.5\n&lt;0.001\n\n\nSystolic Blood Pressure, Mean(StD)\n125 (24)\n127 (24)\n-2.5\n-6.8, 1.8\n0.3\n\n\nDiastolic Blood Pressure, Mean(StD)\n80 (14)\n79 (15)\n0.35\n-2.3, 3.0\n0.8\n\n\nCategorized BMI, n (%)\n\n\n\n\n0.68\n0.50, 0.86\n\n\n\n\n    Normal\n208 (38%)\n110 (70%)\n\n\n\n\n\n\n\n\n    High\n345 (62%)\n48 (30%)\n\n\n\n\n\n\n\n\n    Unknown\n1\n0\n\n\n\n\n\n\n\n\nHypertension present, n (%)\n314 (57%)\n95 (60%)\n\n\n\n\n\n\n\n\n\n1\nWelch Two Sample t-test; Standardized Mean Difference\n\n\n2\nCI = Confidence Interval",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#stratified-table",
    "href": "pkg-gtsummary.html#stratified-table",
    "title": "10  gtsummary",
    "section": "15.4 Stratified table",
    "text": "15.4 Stratified table\n\n\nCode\ndf_cint %&gt;% \n    drop_na(bmicat) %&gt;% \n    tbl_strata(\n        strata = bmicat, ~.x %&gt;%      # Add a strata to the table\n            tbl_summary(\n                by = sex\n            ) %&gt;% \n            add_p()      # P value for each strata\n    ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNormal\n\n\nHigh\n\n\n\nFemale\nN = 208\n1\nMale\nN = 110\n1\np-value\n2\nFemale\nN = 345\n1\nMale\nN = 48\n1\np-value\n2\n\n\n\n\nBulb diameter at time 0\n0.85 (0.75, 0.99)\n0.88 (0.78, 1.03)\n0.074\n0.85 (0.75, 1.03)\n0.91 (0.80, 1.05)\n0.13\n\n\nBulb diameter at 12 months\n0.80 (0.70, 0.90)\n0.84 (0.68, 0.98)\n0.2\n0.85 (0.70, 0.95)\n0.88 (0.68, 0.95)\n0.9\n\n\n    Unknown\n97\n60\n\n\n164\n27\n\n\n\n\nBody Mass Index\n22.22 (20.09, 23.51)\n21.85 (20.31, 23.11)\n0.4\n29.8 (27.5, 33.3)\n27.0 (25.9, 30.9)\n&lt;0.001\n\n\nSystolic Blood Pressure\n118 (100, 133)\n120 (107, 132)\n0.3\n123 (111, 140)\n136 (122, 158)\n&lt;0.001\n\n\nDiastolic Blood Pressure\n76 (67, 84)\n74 (66, 84)\n0.7\n80 (71, 90)\n85 (77, 95)\n0.035\n\n\nHypertension present\n97 (47%)\n57 (52%)\n0.4\n216 (63%)\n38 (79%)\n0.025\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n2\nWilcoxon rank sum test; Pearson’s Chi-squared test",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#specifying-tables-tests",
    "href": "pkg-gtsummary.html#specifying-tables-tests",
    "title": "10  gtsummary",
    "section": "15.5 Specifying tables tests",
    "text": "15.5 Specifying tables tests\n\n\nCode\ndf_cint %&gt;% \n    tbl_summary(by = sex,\n                statistic = list(all_continuous() ~ \"{mean} ({sd})\")\n    ) %&gt;% \n    add_p(\n        test = list(\n            all_continuous()~ \"t.test\",     # Specify T test for all continuous variables\n            all_categorical() ~ \"fisher.test\"     # Specify fisher's text for all categorical variables\n        )\n    ) %&gt;% \n    separate_p_footnotes()     # Specific p-value labelled\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nFemale\nN = 554\n1\nMale\nN = 158\n1\np-value\n\n\n\n\nBulb diameter at time 0\n0.90 (0.22)\n0.93 (0.20)\n0.0952\n\n\nBulb diameter at 12 months\n0.85 (0.23)\n0.87 (0.29)\n0.52\n\n\n    Unknown\n262\n87\n\n\n\n\nBody Mass Index\n27.4 (5.7)\n23.7 (4.0)\n&lt;0.0012\n\n\nSystolic Blood Pressure\n125 (24)\n127 (24)\n0.32\n\n\nDiastolic Blood Pressure\n80 (14)\n79 (15)\n0.82\n\n\nCategorized BMI\n\n\n\n\n&lt;0.0013\n\n\n    Normal\n208 (38%)\n110 (70%)\n\n\n\n\n    High\n345 (62%)\n48 (30%)\n\n\n\n\n    Unknown\n1\n0\n\n\n\n\nHypertension present\n314 (57%)\n95 (60%)\n0.53\n\n\n\n1\nMean (SD); n (%)\n\n\n2\nWelch Two Sample t-test\n\n\n3\nFisher’s exact test",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#customised-tables",
    "href": "pkg-gtsummary.html#customised-tables",
    "title": "10  gtsummary",
    "section": "15.6 Customised tables",
    "text": "15.6 Customised tables\n\n\nCode\ndf_cint %&gt;% \n    select(bmi, hpt, bulb_0, sbp, bmicat) %&gt;% \n    tbl_summary(\n        by = hpt,\n        statistic = list(\n            bmi ~ \"{mean} ({sd})\",\n            all_categorical() ~ \"{n} ({p})\",\n            sbp ~ \"{median} ({p25}, {p75})\",\n            bulb_0 ~ \"{mean} ({sd})\"),\n         missing_text = \"(Missing\",\n        digits = list(all_categorical() ~ c(0, 1))\n    ) %&gt;% \n    add_stat_label(label = list(\n        bmi = \"Mean(SD)\",\n        bulb_0 = \"Mean(SD)\",\n        all_categorical() ~ \"n(%)\",\n        sbp = \"Median(IQR)\"\n    )) %&gt;% \n    add_p(\n        test = list(\n            bmi ~ \"t.test\",\n            bulb_0 ~ \"t.test\",\n            all_categorical() ~ \"fisher.test\",\n            sbp ~ \"wilcox.test\"\n        )\n    ) %&gt;% \n    separate_p_footnotes()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nNo\nN = 303\nYes\nN = 409\np-value\n\n\n\n\nBody Mass Index, Mean(SD)\n25.3 (5.4)\n27.5 (5.5)\n&lt;0.0011\n\n\nBulb diameter at time 0, Mean(SD)\n0.88 (0.22)\n0.92 (0.22)\n0.0131\n\n\nSystolic Blood Pressure, Median(IQR)\n108 (98, 113)\n134 (125, 150)\n&lt;0.0012\n\n\nCategorized BMI, n(%)\n\n\n\n\n&lt;0.0013\n\n\n    Normal\n164 (54.1)\n154 (37.7)\n\n\n\n\n    High\n139 (45.9)\n254 (62.3)\n\n\n\n\n    (Missing\n0\n1\n\n\n\n\n\n1\nWelch Two Sample t-test\n\n\n2\nWilcoxon rank sum test\n\n\n3\nFisher’s exact test",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#creating-data-for-the-paired-table",
    "href": "pkg-gtsummary.html#creating-data-for-the-paired-table",
    "title": "10  gtsummary",
    "section": "15.7 Creating data for the paired table",
    "text": "15.7 Creating data for the paired table\n\n\nCode\ndf_paired_cint &lt;- \n    df_cint_all %&gt;% \n    select(sid, cart, cca_0, cca_12, ica_0, ica_12) %&gt;%\n    mutate(\n        ica_12 = case_when(ica_12 &gt; median(ica_12, na.rm=T) ~ \"High\",\n                               ica_12 &lt;= median(ica_12, na.rm=T) ~ \"Low\") %&gt;% \n            factor(),\n        ica_0 = case_when(ica_0 &gt; median(ica_0, na.rm=T) ~ \"High\",\n                               ica_0 &lt;= median(ica_0, na.rm=T) ~ \"Low\") %&gt;% \n            factor()\n    ) %&gt;% \n    select(sid, cart, cca_0, cca_12, ica_0, ica_12)\n\ndf_A &lt;-\n    df_paired_cint %&gt;% \n    pivot_longer(cols =  c(cca_0, cca_12), \n                 names_to = c(\"cca\", \"period\"), \n                 names_sep = \"_\", \n                 values_to  = \"cca_measure\") %&gt;% \n    select(sid, cart, period, cca_measure)\n\ndf_paired_long &lt;-\n    df_paired_cint %&gt;%\n    pivot_longer(cols =  c(ica_0, ica_12), \n                 names_to = c(\"ica\", \"period\"), \n                 names_sep = \"_\", \n                 values_to  = \"ica_measure\") %&gt;% \n    select(sid, cart, period, ica_measure) %&gt;% \n    full_join(df_A, by = c(\"sid\", \"period\", \"cart\"))",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#paired-table",
    "href": "pkg-gtsummary.html#paired-table",
    "title": "10  gtsummary",
    "section": "15.8 Paired table",
    "text": "15.8 Paired table\n\n\nCode\ndf_paired_long %&gt;% \n    mutate(period = case_when(period == \"0\" ~ \"Month 0\",\n                              period == \"12\" ~ \"Month 12\")) %&gt;% \n    filter(complete.cases(.)) %&gt;% \n    group_by(sid) %&gt;% \n    filter(n()==2) %&gt;% \n    ungroup() %&gt;%\n    tbl_strata(strata = cart, ~.x %&gt;%\n        tbl_summary(by = period, \n                    include = -sid,\n                    statistic = list(cca_measure ~ \"{mean} ({sd})\",\n                                     ica_measure ~ \"{n} ({p})\"),\n                    label = list(ica_measure = \"ICA\",\n                                 cca_measure = \"CCA(mm)\"),\n                    digits = list(all_categorical() ~ c(0, 1)))%&gt;% \n            add_p(test = list(ica_measure ~ \"mcnemar.test\",\n                              cca_measure ~ \"paired.t.test\"),\n                              group = sid,\n                  pvalue_fun = ~ gtsummary::style_pvalue(.x, digits = 3)) %&gt;% \n            separate_p_footnotes() %&gt;% \n            add_stat_label(label = list(ica_measure = \"n(%)\",\n                                        cca_measure = \"mean(SD)\"))\n    ) %&gt;% \n    modify_caption(\"**Table 2: Comparative month 0 and 12 measures**\")\n\n\n\n\n\n\nTable 2: Comparative month 0 and 12 measures\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNaive\n\n\ncART\n\n\nCONTROL\n\n\n\nMonth 0\nN = 86\nMonth 12\nN = 86\np-value\nMonth 0\nN = 237\nMonth 12\nN = 237\np-value\nMonth 0\nN = 40\nMonth 12\nN = 40\np-value\n\n\n\n\nICA, n(%)\n\n\n\n\n0.7281\n\n\n\n\n0.7591\n\n\n\n\n0.0021\n\n\n    High\n32 (37.2)\n29 (33.7)\n\n\n154 (65.0)\n150 (63.3)\n\n\n14 (35.0)\n1 (2.5)\n\n\n\n\n    Low\n54 (62.8)\n57 (66.3)\n\n\n83 (35.0)\n87 (36.7)\n\n\n26 (65.0)\n39 (97.5)\n\n\n\n\nCCA(mm), mean(SD)\n0.83 (0.13)\n0.77 (0.14)\n0.0022\n0.93 (0.17)\n0.88 (0.16)\n&lt;0.0012\n0.84 (0.13)\n0.70 (0.11)\n&lt;0.0012\n\n\n\n1\nMcNemar’s Chi-squared test with continuity correction\n\n\n2\nPaired t-test",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#multivariate-regression",
    "href": "pkg-gtsummary.html#multivariate-regression",
    "title": "10  gtsummary",
    "section": "17.1 Multivariate regression",
    "text": "17.1 Multivariate regression\n\n17.1.1 Multiple liner regreession\n\n\nCode\ndf_cint %&gt;% \n    lm(sbp ~ ., data = .) %&gt;% \n    tbl_regression(pvalue_fun = function(x) style_pvalue(x, digits = 3)) %&gt;% \n    modify_header(update = list(estimate ~ \"**Estimate**\",\n                                label ~ \"**Variable**\")) %&gt;% \n    modify_caption(caption = \"**Table XI:** Multivariate linear regression\") %&gt;%\n    bold_labels() %&gt;% \n    as_gt() %&gt;% \n    gt::tab_options(\n        table.font.size = 14,\n        table.font.names = \"Times New Roman\",\n        data_row.padding = 1\n    ) \n\n\n\n\n\n\nTable XI: Multivariate linear regression\n\n\n\n\n\n\n\n\nVariable\nEstimate\n95% CI\n1\np-value\n\n\n\n\nSex\n\n\n\n\n\n\n\n\n    Female\n—\n—\n\n\n\n\n    Male\n-0.25\n-3.6, 3.1\n0.883\n\n\nBulb diameter at time 0\n4.6\n-1.2, 10\n0.122\n\n\nBulb diameter at 12 months\n7.4\n1.7, 13\n0.011\n\n\nBody Mass Index\n0.05\n-0.32, 0.43\n0.781\n\n\nDiastolic Blood Pressure\n0.92\n0.79, 1.0\n&lt;0.001\n\n\nCategorized BMI\n\n\n\n\n\n\n\n\n    Normal\n—\n—\n\n\n\n\n    High\n0.19\n-4.0, 4.3\n0.930\n\n\nHypertension present\n\n\n\n\n\n\n\n\n    No\n—\n—\n\n\n\n\n    Yes\n17\n13, 20\n&lt;0.001\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n17.1.2 Multiple variable logistic regression\n\n\nCode\ndf_mbu_clean %&gt;% \n    select(-dura_adm) %&gt;% \n    glm(died ~ ., data = ., family = binomial) %&gt;% \n    tbl_regression(exponentiate = T) %&gt;% \n    add_n(location = \"level\") %&gt;% \n    add_nevent(location = \"level\") %&gt;% \n    add_global_p() %&gt;% \n    add_q() %&gt;% \n    add_significance_stars(\n        hide_p = FALSE,\n        hide_ci = FALSE,\n        hide_se = TRUE) %&gt;% \n    add_vif() %&gt;% \n    modify_header(label = \"**Predictor**\") %&gt;% \n    modify_caption(caption = \"**Table 5: Highly customised logistic regression**\") %&gt;% \n    modify_footnote(ci = \"CI = My 95%CI\", abbreviation = TRUE) %&gt;% \n    sort_p() %&gt;% \n    bold_p(t=0.1, q=TRUE) %&gt;% \n    bold_labels() %&gt;% \n    italicize_levels()\n\n\nWarning: Use of the \"ci\" column was deprecated in gtsummary v2.0, and the column will\neventually be removed from the tables.\n! Review `?deprecated_ci_column()` for details on how to update your code.\nℹ The \"ci\" column has been replaced by the merged \"conf.low\" and \"conf.high\"\n  columns (merged with `modify_column_merge()`).\nℹ In most cases, a simple update from `ci = 'a new label'` to `conf.low = 'a\n  new label'` is sufficient.\n\n\n\n\n\n\nTable 5: Highly customised logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredictor\nN\nEvent N\nOR\n1,2\n95% CI\n2\np-value\nq-value\n3\nGVIF\n2\nAdjusted GVIF\n4,2\n\n\n\n\nAPGAR (min 5)\n4,984\n727\n0.57***\n0.51, 0.63\n&lt;0.001\n&lt;0.001\n3.8\n2.0\n\n\nWeight (kgs)\n4,984\n727\n0.51***\n0.43, 0.62\n&lt;0.001\n&lt;0.001\n2.9\n1.7\n\n\nPlace of birth\n\n\n\n\n\n***\n\n\n&lt;0.001\n&lt;0.001\n1.1\n1.0\n\n\n    Clinic/Hospital\n796\n195\n—\n—\n\n\n\n\n\n\n\n\n\n\n    Home\n64\n9\n0.66\n0.27, 1.48\n\n\n\n\n\n\n\n\n\n\n    KATH\n4,114\n520\n0.56\n0.45, 0.70\n\n\n\n\n\n\n\n\n\n\n    Maternity Home\n10\n3\n1.68\n0.30, 8.14\n\n\n\n\n\n\n\n\n\n\nGestational Age\n4,984\n727\n0.94***\n0.91, 0.97\n&lt;0.001\n0.001\n2.9\n1.7\n\n\nAge (days)\n4,984\n727\n1.05*\n1.00, 1.09\n0.032\n0.052\n1.0\n1.0\n\n\nMode of delivery\n\n\n\n\n\n*\n\n\n0.045\n0.060\n1.2\n1.0\n\n\n    C/S\n2,662\n318\n—\n—\n\n\n\n\n\n\n\n\n\n\n    SVD\n2,188\n398\n0.78\n0.64, 0.95\n\n\n\n\n\n\n\n\n\n\n    Vacuum\n134\n11\n1.00\n0.48, 1.90\n\n\n\n\n\n\n\n\n\n\nSex\n\n\n\n\n\n\n\n\n0.095\n0.11\n1.0\n1.0\n\n\n    Female\n2,216\n329\n—\n—\n\n\n\n\n\n\n\n\n\n\n    Male\n2,768\n398\n1.17\n0.97, 1.41\n\n\n\n\n\n\n\n\n\n\nAPGAR (min 1)\n4,984\n727\n1.00\n0.92, 1.10\n&gt;0.9\n&gt;0.9\n3.9\n2.0\n\n\n\n1\np&lt;0.05; p&lt;0.01; p&lt;0.001\n\n\n2\nOR = Odds Ratio, CI = Confidence Interval, GVIF = Generalized Variance Inflation Factor\n\n\n3\nFalse discovery rate correction for multiple testing\n\n\n4\nGVIF2\n\n\n\n\n\n\n\n\n\n\n17.1.3 Cox proportional hazard regression\n\n\nCode\ndf_mbu_clean %&gt;% \n    coxph(Surv(dura_adm, died == \"Yes\")~., data = .) %&gt;% \n    tbl_regression(exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n1\n95% CI\n1\np-value\n\n\n\n\nWeight (kgs)\n0.63\n0.54, 0.74\n&lt;0.001\n\n\nAge (days)\n1.04\n1.01, 1.07\n0.021\n\n\nSex\n\n\n\n\n\n\n\n\n    Female\n—\n—\n\n\n\n\n    Male\n1.11\n0.95, 1.28\n0.2\n\n\nPlace of birth\n\n\n\n\n\n\n\n\n    Clinic/Hospital\n—\n—\n\n\n\n\n    Home\n0.55\n0.28, 1.08\n0.083\n\n\n    KATH\n0.66\n0.55, 0.78\n&lt;0.001\n\n\n    Maternity Home\n1.08\n0.34, 3.39\n0.9\n\n\nAPGAR (min 1)\n0.96\n0.90, 1.03\n0.3\n\n\nMode of delivery\n\n\n\n\n\n\n\n\n    C/S\n—\n—\n\n\n\n\n    SVD\n0.77\n0.66, 0.90\n0.001\n\n\n    Vacuum\n0.96\n0.52, 1.77\n&gt;0.9\n\n\nGestational Age\n0.97\n0.94, 1.00\n0.031\n\n\nAPGAR (min 5)\n0.68\n0.64, 0.74\n&lt;0.001\n\n\n\n1\nHR = Hazard Ratio, CI = Confidence Interval",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#merging",
    "href": "pkg-gtsummary.html#merging",
    "title": "10  gtsummary",
    "section": "18.1 Merging",
    "text": "18.1 Merging",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#stacking",
    "href": "pkg-gtsummary.html#stacking",
    "title": "10  gtsummary",
    "section": "18.2 Stacking",
    "text": "18.2 Stacking",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#multiple-comparison-table",
    "href": "pkg-gtsummary.html#multiple-comparison-table",
    "title": "10  gtsummary",
    "section": "18.3 Multiple comparison table",
    "text": "18.3 Multiple comparison table\n\n\nCode\nlibrary(titanic)\nlibrary(plotrix) #has a std.error function\n\n# create smaller version of the dataset\ndf &lt;- \n  titanic_train %&gt;%\n  select(Sex, Embarked, Age, Fare) %&gt;%\n  filter(Embarked != \"\") # deleting empty Embarked status\n\n# first, write a little function to get the 2-way ANOVA p-values in a table\n# function to get 2-way ANOVA p-values in tibble\ntwoway_p &lt;- function(variable) {\n  paste(variable, \"~ Sex * Embarked\") %&gt;%\n    as.formula() %&gt;%\n    aov(data = df) %&gt;% \n    broom::tidy() %&gt;%\n    select(term, p.value) %&gt;%\n    filter(complete.cases(.)) %&gt;%\n    pivot_wider(names_from = term, values_from = p.value) %&gt;%\n    mutate(\n      variable = .env$variable,\n      row_type = \"label\"\n    )\n}\n\n# add all results to a single table (will be merged with gtsummary table in next step)\ntwoway_results &lt;-\n  bind_rows(\n    twoway_p(\"Age\"),\n    twoway_p(\"Fare\")\n  )\ntwoway_results\n\n\n# A tibble: 2 × 5\n           Sex Embarked `Sex:Embarked` variable row_type\n         &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   \n1 0.00823      3.97e- 1         0.611  Age      label   \n2 0.0000000191 4.27e-16         0.0958 Fare     label   \n\n\nCode\ntbl &lt;-\n  # first build a stratified `tbl_summary()` table to get summary stats by two variables\n  df %&gt;%\n  tbl_strata(\n    strata =  Sex,\n    .tbl_fun =\n      ~.x %&gt;%\n      tbl_summary(\n        by = Embarked,\n        missing = \"no\",\n        statistic = all_continuous() ~ \"{mean} ({std.error})\",\n        digits = everything() ~ 1\n      ) %&gt;%\n      modify_header(all_stat_cols() ~ \"**{level}**\")\n  ) %&gt;%\n  # merge the 2way ANOVA results into tbl_summary table\n  modify_table_body(\n    ~.x %&gt;%\n      left_join(\n        twoway_results,\n        by = c(\"variable\", \"row_type\")\n      )\n  ) %&gt;%\n  # by default the new columns are hidden, add a header to unhide them\n  modify_header(list(\n    Sex ~ \"**Sex**\", \n    Embarked ~ \"**Embarked**\", \n    `Sex:Embarked` ~ \"**Sex * Embarked**\"\n  )) %&gt;%\n  # adding spanning header to analysis results\n  modify_spanning_header(c(Sex, Embarked, `Sex:Embarked`) ~ \"**Two-way ANOVA p-values**\") %&gt;%\n  # format the p-values with a pvalue formatting function\n  modify_fmt_fun(c(Sex, Embarked, `Sex:Embarked`) ~ style_pvalue) %&gt;%\n  # update the footnote to be nicer looking\n  modify_footnote(all_stat_cols() ~ \"Mean (SE)\")",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-gtsummary.html#footnotes",
    "href": "pkg-gtsummary.html#footnotes",
    "title": "10  gtsummary",
    "section": "",
    "text": "Need to insert this k3k3↩︎\n1/(2*df)↩︎",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>`gtsummary`</span>"
    ]
  },
  {
    "objectID": "pkg-nlme.html",
    "href": "pkg-nlme.html",
    "title": "11  nlme",
    "section": "",
    "text": "Code\ncint &lt;- dget(\"C:/Dataset/cint_data_11042021\")\n\n\nSince this is a large dataset we start off by selecting the variables we need, convert it to the long format, and generate the “Time” variable\n\n\nCode\ndf &lt;-\n    cint %&gt;% \n    select(\n        sid, cca_0, cca_12, sex, ageyrs, resid, physical, \n        hpt_old, cart) %&gt;% \n    gather(period, cca, cca_0:cca_12) %&gt;% \n    mutate(\n        Time = ifelse(\n            period == \"cca_0\", 0, \n            ifelse(period == \"cca_12\", 1, NA)))\n\n\nHere we begin to pick up abnormal or suspicious data escpecially in the cca. One way is to determine the changes with time\n\n\nCode\ndf2 &lt;- \n    df %&gt;% \n    arrange(sid, period) %&gt;%\n    group_by(sid) %&gt;% \n    mutate(\n        cca_prev = lag(cca, order_by = sid),\n        cca_diff = cca - cca_prev) \n\ndf2 %&gt;% \n    arrange(sid, period) %&gt;% \n    head(10) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsid\nsex\nageyrs\nresid\nphysical\nhpt_old\ncart\nperiod\ncca\nTime\ncca_prev\ncca_diff\n\n\n\n\n1\nFemale\n58\nUrban\nYes\nNo\nNaive\ncca_0\n0.925\n0\nNA\nNA\n\n\n1\nFemale\n58\nUrban\nYes\nNo\nNaive\ncca_12\n1.000\n1\n0.925\n0.075\n\n\n2\nFemale\n48\nUrban\nYes\nNo\nNaive\ncca_0\n0.975\n0\nNA\nNA\n\n\n2\nFemale\n48\nUrban\nYes\nNo\nNaive\ncca_12\n0.700\n1\n0.975\n-0.275\n\n\n3\nFemale\n40\nUrban\nYes\nNo\ncART\ncca_0\n0.850\n0\nNA\nNA\n\n\n3\nFemale\n40\nUrban\nYes\nNo\ncART\ncca_12\n0.925\n1\n0.850\n0.075\n\n\n4\nMale\n38\nUrban\nNo\nNo\nNaive\ncca_0\n0.875\n0\nNA\nNA\n\n\n4\nMale\n38\nUrban\nNo\nNo\nNaive\ncca_12\n0.750\n1\n0.875\n-0.125\n\n\n5\nFemale\n49\nUrban\nNo\nYes\ncART\ncca_0\n1.600\n0\nNA\nNA\n\n\n5\nFemale\n49\nUrban\nNo\nYes\ncART\ncca_12\n1.225\n1\n1.600\n-0.375\n\n\n\n\n\nAnd then plot the differences\n\n\nCode\ndf2 %&gt;% \n    na.omit() %&gt;% \n    ggplot(aes(x = cca_diff)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nComment: Generally there was decrease in the cca values over the two time periods. Next we summarise and visualise the data\n\n\nCode\ndf %&gt;% \n    na.omit() %&gt;% \n    ggplot(aes(x = Time, y = cca, group = sid))+\n    geom_jitter(show.legend = F, width = .01) +\n    stat_smooth(\n        formula = y ~x, \n        method = \"lm\", \n        se = FALSE, \n        col = \"grey\") +\n    theme_light()\n\n\n\n\n\n\n\n\n\nNext the UNCONDITIONAL NULL MODEL to evaluate clustering, thereby finding out if we need to even do multilevel analysis\n\n\nCode\nn0 &lt;- \n    nlme::gls(\n        cca ~ 1, data = df, na.action = na.omit, method = \"ML\")\n\nn0 %&gt;% \n    broom.mixed::tidy(conf.int=T) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.8520116\n0.004918\n173.2448\n0\n0.8423726\n0.8616507\n\n\n\n\n\n\n\nCode\nn1 &lt;- \n    nlme::lme(\n        cca ~ 1, random = ~ 1 | sid, \n        data = df, na.action = na.omit, method = \"ML\")\n\nn0 %&gt;% broom.mixed::tidy(conf.int=T) %&gt;% kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.8520116\n0.004918\n173.2448\n0\n0.8423726\n0.8616507\n\n\n\n\n\n\n\nCode\nn1 %&gt;% reghelper::ICC()\n\n\n[1] 0.3150857\n\n\nCode\nanova(n0, n1)\n\n\n   Model df       AIC       BIC   logLik   Test  L.Ratio p-value\nn0     1  2 -869.6521 -859.6919 436.8260                        \nn1     2  3 -909.9268 -894.9866 457.9634 1 vs 2 42.27476  &lt;.0001\n\n\nSince ICC &gt; 0.05 and also the random effects CI does not include 0 there exist significant clustering to suggest we do multilevel modeling. Next we test the UNCONDITIONAL SLOPE MODEL using the FIXED slope\n\n\nCode\nn2 &lt;- \n    nlme::lme(\n        cca ~ Time, random = ~ 1 | sid, \n        data = df, \n        na.action = na.omit, \n        method = \"ML\")\n\nn2 %&gt;% \n    broom.mixed::tidy(conf.int=T) %&gt;% \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\ndf\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\nfixed\nNA\n(Intercept)\n0.8629565\n0.0060113\n711\n143.554679\n0e+00\n0.8511653\n0.8747476\n\n\nfixed\nNA\nTime\n-0.0447315\n0.0086710\n362\n-5.158735\n4e-07\n-0.0617676\n-0.0276955\n\n\nran_pars\nsid\nsd_(Intercept)\n0.0979221\nNA\nNA\nNA\nNA\n0.0857260\n0.1118532\n\n\nran_pars\nResidual\nsd_Observation\n0.1268559\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\nCode\nn2 %&gt;% reghelper::ICC()\n\n\n[1] 0.3733763\n\n\nCode\nanova(n0, n1, n2)\n\n\n   Model df       AIC       BIC   logLik   Test  L.Ratio p-value\nn0     1  2 -869.6521 -859.6919 436.8260                        \nn1     2  3 -909.9268 -894.9866 457.9634 1 vs 2 42.27476  &lt;.0001\nn2     3  4 -932.4301 -912.5098 470.2150 2 vs 3 24.50329  &lt;.0001\n\n\nNext we test the UNCONDITIONAL SLOPE MODEL using the RANDOM slope\n\n\nCode\nn3 &lt;- \n    nlme::lme(\n        cca ~ Time, \n        random = ~ Time | sid, \n        data = df, \n        na.action = na.omit, \n        method = \"ML\")\n\n\nn3 %&gt;% summary()\n\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: df \n        AIC       BIC   logLik\n  -929.0894 -899.2089 470.5447\n\nRandom effects:\n Formula: ~Time | sid\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev     Corr  \n(Intercept) 0.14902004 (Intr)\nTime        0.16324990 -0.51 \nResidual    0.05371762       \n\nFixed effects:  cca ~ Time \n                 Value   Std.Error  DF   t-value p-value\n(Intercept)  0.8629565 0.005942057 711 145.22857       0\nTime        -0.0452827 0.008766665 362  -5.16533       0\n Correlation: \n     (Intr)\nTime -0.413\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-0.85549105 -0.24307511 -0.02773692  0.23248407  1.46909846 \n\nNumber of Observations: 1075\nNumber of Groups: 712 \n\n\nCode\nn3 %&gt;% nlme::intervals(which = \"fixed\")\n\n\nApproximate 95% confidence intervals\n\n Fixed effects:\n                  lower        est.       upper\n(Intercept)  0.85130124  0.86295646  0.87461168\nTime        -0.06250667 -0.04528273 -0.02805879\n\n\nCode\nn3 %&gt;% reghelper::ICC()\n\n\n[1] 0.9442325\n\n\nCode\nanova(n0, n1, n2, n3)\n\n\n   Model df       AIC       BIC   logLik   Test  L.Ratio p-value\nn0     1  2 -869.6521 -859.6919 436.8260                        \nn1     2  3 -909.9268 -894.9866 457.9634 1 vs 2 42.27476  &lt;.0001\nn2     3  4 -932.4301 -912.5098 470.2150 2 vs 3 24.50329  &lt;.0001\nn3     4  6 -929.0894 -899.2089 470.5447 3 vs 4  0.65926  0.7192\n\n\nNext we test the FULL MODEL using the RANDOM slope\n\n\nCode\nn4 &lt;- \n    nlme::lme(\n        cca ~ Time + hpt_old + sex + scale(ageyrs) + cart, \n        random = ~ 1 | sid, \n        data = df, \n        method = \"ML\", \n        na.action = na.omit)\n\nn4 %&gt;% \n    broom.mixed::tidy() %&gt;% \n    kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n0.8224719\n0.0101076\n706\n81.371922\n0.0000000\n\n\nfixed\nNA\nTime\n-0.0650204\n0.0087880\n362\n-7.398737\n0.0000000\n\n\nfixed\nNA\nhpt_oldYes\n0.0577155\n0.0145760\n706\n3.959637\n0.0000827\n\n\nfixed\nNA\nsexMale\n0.0290863\n0.0121127\n706\n2.401295\n0.0165947\n\n\nfixed\nNA\nscale(ageyrs)\n0.0280193\n0.0053049\n706\n5.281768\n0.0000002\n\n\nfixed\nNA\ncartcART\n0.0886504\n0.0119744\n706\n7.403327\n0.0000000\n\n\nfixed\nNA\ncartCONTROL\n-0.0159617\n0.0130719\n706\n-1.221074\n0.2224656\n\n\nran_pars\nsid\nsd_(Intercept)\n0.0745001\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd_Observation\n0.1259536\nNA\nNA\nNA\nNA\n\n\n\n\n\nCode\nn4 %&gt;% reghelper::ICC()\n\n\n[1] 0.2591817\n\n\nCode\nanova(n0, n1, n2, n3, n4) \n\n\n   Model df        AIC        BIC   logLik   Test   L.Ratio p-value\nn0     1  2  -869.6521  -859.6919 436.8260                         \nn1     2  3  -909.9268  -894.9866 457.9634 1 vs 2  42.27476  &lt;.0001\nn2     3  4  -932.4301  -912.5098 470.2150 2 vs 3  24.50329  &lt;.0001\nn3     4  6  -929.0894  -899.2089 470.5447 3 vs 4   0.65926  0.7192\nn4     5  9 -1088.4835 -1043.6628 553.2418 4 vs 5 165.39417  &lt;.0001",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Specific Packages</span>",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>`nlme`</span>"
    ]
  },
  {
    "objectID": "ss-matched-case-control.html",
    "href": "ss-matched-case-control.html",
    "title": "12  Matched Case-Control",
    "section": "",
    "text": "12.1 Objective\nTo determine if being HIV positive (exposure) is associated with malnutrition (outcome) in children on admission at a specialized nutritional rehabilitation center. A researcher intends to conduct a matched case-control study he selects children with malnutrition and matches them to controls of children without malnutrition at a ratio of 1:2.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Sample Size</span>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matched Case-Control</span>"
    ]
  },
  {
    "objectID": "ss-matched-case-control.html#hypothesis",
    "href": "ss-matched-case-control.html#hypothesis",
    "title": "12  Matched Case-Control",
    "section": "12.2 Hypothesis",
    "text": "12.2 Hypothesis\n\\(H_0\\): There is no association between being malnourished and being HIV positive",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Sample Size</span>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matched Case-Control</span>"
    ]
  },
  {
    "objectID": "ss-matched-case-control.html#formula",
    "href": "ss-matched-case-control.html#formula",
    "title": "12  Matched Case-Control",
    "section": "12.3 Formula",
    "text": "12.3 Formula\nWe use the formula below by Wang and Ji (2020).\n\\[\nn = (\\frac{Z_{\\alpha/2} + Z_\\beta}{P_1 - P_2})^2 \\times (1 + \\frac{1}{k})\n\\]\nWhere:\n\n\\(n\\) is the number of matched pairs needed\n\\(Z_{\\alpha/2}\\) is the critical value of the standard normal distribution at the desired significance level such that a 95% confidence level will correspond to 1.96\n\\(Z_{\\beta}\\) is the critical value of the standard normal distribution at the desired power such that an 80% power will correspond to a value of 0.84.\n\\(P_1\\) is the proportion of exposure in cases. This can be obtained from similar prior studies\n\\(P_0\\) is the proportion of exposure in controls, This can be obtained from similar prior studies\n\\(k\\) is the number of controls per case such that for a 1:1 match \\(k\\) =1",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Sample Size</span>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matched Case-Control</span>"
    ]
  },
  {
    "objectID": "ss-matched-case-control.html#determination",
    "href": "ss-matched-case-control.html#determination",
    "title": "12  Matched Case-Control",
    "section": "12.4 Determination",
    "text": "12.4 Determination\nAssuming in the literature the proportion of HIV positive in non-malnourished children ( \\(P_0\\)) was 0.25 and that for malnourished children (\\(P_1\\)) was 0.3. Also, the investigator decides the use a 95% confidence interval and a power of 80%. The sample size is determined as below\n\\[\nn = (\\frac{1.96 + 0.84}{0.3 - 0.25})^2 \\times (1 + \\frac{1}{2})\n\\]\nThus a minimum total of 4710 study subjects will be included. This will consist of 3140 controls and 1570 cases.\n\n\n\n\nWang, Xiaofeng, and Xinge Ji. 2020. “Sample Size Estimation in Clinical Research.” Chest 158 (1): S12–20. https://doi.org/10.1016/j.chest.2020.03.010.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Sample Size</span>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matched Case-Control</span>"
    ]
  },
  {
    "objectID": "gr-histogram.html",
    "href": "gr-histogram.html",
    "title": "13  Histogram",
    "section": "",
    "text": "13.0.1 Read in Data\nWe begin by importing the data into R Studio and then summarizing it.\n\n\nCode\ndf_histo &lt;- \n    readstata13::read.dta13(\"C:/Dataset/olivia_data_wide.dta\") %&gt;% \n    select(hb1, hb2, hb3, hb4)\n\ndf_histo %&gt;% \n    summarytools::dfSummary(labels.col = F, graph.col = F) \n\n\nData Frame Summary  \ndf_histo  \nDimensions: 350 x 4  \nDuplicates: 3  \n\n-----------------------------------------------------------------------------------\nNo   Variable    Stats / Values           Freqs (% of Valid)   Valid      Missing  \n---- ----------- ------------------------ -------------------- ---------- ---------\n1    hb1         Mean (sd) : 11.3 (1.2)   57 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                              (100.0%)   (0.0%)   \n                 8.3 &lt; 11.3 &lt; 16.6                                                 \n                 IQR (CV) : 1.8 (0.1)                                              \n\n2    hb2         Mean (sd) : 11.2 (1.3)   63 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                              (100.0%)   (0.0%)   \n                 6.1 &lt; 11 &lt; 15.6                                                   \n                 IQR (CV) : 1.8 (0.1)                                              \n\n3    hb3         Mean (sd) : 11.1 (1.2)   57 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                              (100.0%)   (0.0%)   \n                 8 &lt; 11.1 &lt; 15.2                                                   \n                 IQR (CV) : 1.8 (0.1)                                              \n\n4    hb4         Mean (sd) : 11.8 (2.5)   89 distinct values   350        0        \n     [numeric]   min &lt; med &lt; max:                              (100.0%)   (0.0%)   \n                 3.5 &lt; 11.5 &lt; 24.4                                                 \n                 IQR (CV) : 2.4 (0.2)                                              \n-----------------------------------------------------------------------------------\n\n\n\n\n13.0.2 Simple histogram\n\n\nCode\ndf_histo %&gt;% \n    ggplot(aes(x = hb1)) +\n    geom_histogram(\n        col = \"red\", \n        fill = \"snow1\", \n        bins = 12) +\n    labs(\n        x = \"Hemoglobin (mg/dl)\", \n        y = \"Frequency\") +\n    theme_classic()\n\n\n\n\n\n\n\n\nFigure 13.1: Distribution of the first hemoglobins concentration\n\n\n\n\n\n\n\n13.0.3 Histogram with normal curve\n\n\nCode\ndf_histo %&gt;% \n    ggplot(\n        aes(x = hb1)) + \n    geom_histogram(\n        aes(y = after_stat(density)),\n        breaks = seq(7.5, 17.5, by = 1), \n        colour = \"blue\", \n        fill = \"white\") +\n    stat_function(\n        fun = dnorm, \n        args = list(mean = mean(df_histo$hb1), sd = sd(df_histo$hb1)),\n        color = 'red')+\n    labs(\n        x = \"Hemoglobin (mg/dl)\", \n        y = \"Density\") +\n    theme_classic()\n\n\n\n\n\n\n\n\nFigure 13.2: Distribution of the first hemoglobins concentration\n\n\n\n\n\n\n\n13.0.4 Panel histogram\n\n\nCode\ndf_temp &lt;- \n    df_histo %&gt;% \n    pivot_longer(cols = c(hb1, hb2, hb3, hb4)) %&gt;% \n    drop_na(value) %&gt;% \n    mutate(\n        name = factor(\n            name, \n            levels = c(\"hb1\", \"hb2\", \"hb3\", \"hb4\"),\n            labels = c(\"First HB\", \"Second HB\", \"Third HB\", \"Fourth HB\")))\n\ndf_temp %&gt;% \n    ggplot(\n        aes(x = value)) + \n    geom_histogram(\n        aes(y = after_stat(density)),\n        breaks = seq(7.55, 17.5, by = 1), \n        colour = \"blue\", \n        fill = \"white\", \n        bins = 10) +\n    stat_function(\n        fun = dnorm, \n        args = list(\n            mean = mean(df_temp$value), sd = sd(df_temp$value)),\n        color = 'red')+\n    labs(\n        x = \"Hemoglobin (mg/dl)\", \n        y = \"Density\") +\n    theme_bw()+\n    facet_wrap(\n        facets = .~name)+\n    theme(\n        text = element_text(family = \"serif\"),\n        strip.text = element_text(face = \"bold\", color = \"white\"),\n        strip.background = element_rect(fill = \"#4C4CBD\"),\n        plot.title = element_text(face = 'bold'))\n\n\n\n\n\n\n\n\nFigure 13.3: Distribution of the first hemoglobins concentration",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Histogram</span>"
    ]
  },
  {
    "objectID": "gr-densityplot.html",
    "href": "gr-densityplot.html",
    "title": "14  Density Plot",
    "section": "",
    "text": "14.0.1 Import dataset\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\nCode\ndf_bp &lt;- \n    readstata13::read.dta13(\"C:/Dataset/BP.dta\") %&gt;% \n    select(sex, sbp, dbp, saltadd) %&gt;% \n    pivot_longer(\n        cols = c(sbp, dbp), \n        values_to = \"pressure\", \n        names_to = \"bp_type\")\n\ndataF &lt;- readstata13::read.dta13(\"C:/Dataset/olivia_data_wide.dta\")\n\n\n\n\n14.0.2 Primary density plot\n\n\nCode\ndf_bp %&gt;% \n    filter(bp_type == \"sbp\") %&gt;% \n    ggplot(aes(x = pressure)) +\n    geom_density(\n        color = \"blue\", \n        fill = 'red', \n        linetype = \"dashed\", \n        alpha = 0.2) +\n    theme_light()\n\n\n\n\n\n\n\n\nFigure 14.1: Density plot of the Systolic blood pressures\n\n\n\n\n\n\n\n14.0.3 Density with separate colors\n\n\nCode\ndf_bp %&gt;% \n    filter(bp_type == \"sbp\") %&gt;% \n    drop_na(saltadd) %&gt;% \n    ggplot(aes(x = pressure, color = saltadd, fill = saltadd)) +\n    geom_density(\n        linetype = \"dashed\", alpha = 0.2) +\n    theme_light()+\n    scale_color_brewer(palette = \"Dark2\")\n\n\n\n\n\n\n\n\nFigure 14.2: Density plot of the Systolic blood pressures\n\n\n\n\n\n\n\n14.0.4 Densityplot with facets\n\n\nCode\ndf_bp %&gt;% \n    drop_na(saltadd) %&gt;% \n    ggplot(aes(x = pressure, color = saltadd)) +\n    geom_density(aes(fill = saltadd), linetype = \"dashed\", alpha = 0.2) +\n    theme_light()+\n    scale_color_brewer(palette = \"Dark2\") +\n    facet_grid(bp_type ~ sex)\n\n\n\n\n\n\n\n\nFigure 14.3: Density plot of the Systolic blood pressures\n\n\n\n\n\n\n\n14.0.5 ggridges plot\n\n\nCode\ndf_bp %&gt;% \n    drop_na(saltadd) %&gt;% \n    ggplot(aes(x = pressure, fill = bp_type)) +\n    ggridges::geom_density_ridges(aes(y = saltadd), alpha = .3) +\n    labs(x = \"Pressure\", \n         y = \"Salt added to diet\") +\n    ggridges::theme_ridges(font_size = 12) +\n    scale_fill_discrete(\n        name = \"Blood Pressure Type\", \n        labels = c(\"sbp\" = \"Systolic\", \"dbp\" = \"Diastolic\")) +\n    theme(legend.position = \"right\")\n\n\nPicking joint bandwidth of 11.5\n\n\n\n\n\n\n\n\nFigure 14.4: Comparative Systolic and Diastolic Blood Pressue for salt addiotin and sex\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    select(mcv1, mcv2, mcv3, mcv4, mcv5, agecat, id) %&gt;%\n    pivot_longer(cols = mcv1:mcv5, names_to = \"Time\", values_to = \"MCV\") %&gt;% \n    ggplot(aes(x = MCV, fill = Time)) +\n    ggridges::geom_density_ridges(aes(y = agecat), alpha = .5) +\n    labs(x = \"MCV\", \n         y = \"Age Group Category (years)\",\n         title = \"Sequential changes in MCV over the study duration per age category\") +\n    ggridges::theme_ridges() +\n    scale_fill_discrete(name = \"Measure\", \n                        labels = c(\"mcv1\" = \"First\", \n                                   \"mcv2\" = \"Second\", \n                                   \"mcv3\" = \"Third\",\n                                   \"mcv4\" = \"Fourth\",\n                                   \"mcv5\" = \"Fifth\")) +\n    theme(legend.position = \"right\")\n\n\nPicking joint bandwidth of 3.72",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Density Plot</span>"
    ]
  },
  {
    "objectID": "gr-boxplot.html",
    "href": "gr-boxplot.html",
    "title": "15  Boxplot",
    "section": "",
    "text": "First we read in the data\n\n\nCode\nrm(list = ls(all = TRUE))\ndat &lt;- \n    foreign::read.dta(\"C:/Dataset/bea_organ_damage_28122013.dta\")\ndataF &lt;- \n    readstata13::read.dta13(\"C:/Dataset/olivia_data_wide.dta\")\n\n\nWarning in readstata13::read.dta13(\"C:/Dataset/olivia_data_wide.dta\"): \n   Factor codes of type double or float detected in variables\n\n   anemia1, anemia2, anemia3, anemia4, anemia5\n\n   No labels have been assigned.\n   Set option 'nonint.factors = TRUE' to assign labels anyway.\n\n\n\n16 Boxplot\nNext we select three variables for plotting, keep only the complete cases and then store the ggplot() into an object called BP.\n\n\nCode\nBP &lt;- \n  dat %&gt;% \n  select(q12weight, q2idtype, q3sex) %&gt;% \n  na.omit() %&gt;%\n  ggplot(aes(x = q2idtype, y = q12weight, fill = q3sex))\n\n\nNext we draw our boxplot with axis labels, title, axes format, and color specification.\n\n\nCode\nBP + \n  geom_boxplot() +\n    theme_test() +\n    labs(title=\"My Boxplot\", x=\"Case or Control\", y=\"Weight (hgs)\") + \n    theme(plot.title = element_text(size=15, face=\"bold\"), \n          axis.text.x = element_text(size=12), \n          axis.text.y = element_text(size=12),\n          axis.title.x = element_text(size=13),\n          axis.title.y = element_text(size=13)) + \n  scale_color_discrete(name = \"Sex\")\n\n\n\n\n\n\n\n\n\nNewt we set up a similar boxplot but this time use the color option for the ggplot() and not the fill option.\n\n\nCode\nBP &lt;- \n  dat %&gt;% \n  select(q12weight, q2idtype, q3sex) %&gt;% \n  na.omit() %&gt;%\n  ggplot(aes(x = q2idtype, y = q12weight, color = q3sex))\n\n\n\n\nCode\nBP + \n  geom_boxplot() +\n    theme_light() +\n    labs(title = \"My Boxplot\", \n         x = \"Case or Control\", \n         y = \"Weight (hgs)\") + \n    theme(plot.title=element_text(size=15, face=\"bold\"), \n          axis.text.x=element_text(size=12), \n          axis.text.y=element_text(size=12),\n          axis.title.x=element_text(size=13),\n          axis.title.y=element_text(size=13)) + \n  scale_color_discrete(name=\"Sex\")\n\n\n\n\n\n\n\n\n\nCode\nrm(BP, dat)\n\n\nHere we use a different dataset to draw the next boxplot\n\n\nCode\ndf1 &lt;- read.csv(\"C:/Dataset/booking1.csv\")\nglimpse(df1)\n\n\nRows: 50\nColumns: 4\n$ id     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ sex    &lt;chr&gt; \"Male\", \"Male\", \"Female\", \"Male\", \"Male\", \"Female\", \"Female\", \"…\n$ weight &lt;int&gt; 4, 10, 8, 14, 16, 9, 23, 14, 7, 13, 16, 10, 7, 13, 13, 10, 17, …\n$ height &lt;int&gt; 68, 81, 78, 90, 106, 85, 120, 98, 69, 88, 89, 81, 79, 93, 109, …\n\n\nNext we plot two boxplots on one graph\n\n\nCode\ndf1 %&gt;% \n  na.omit() %&gt;% \n  ggplot(aes(x = sex)) + \n    geom_boxplot(aes(y = weight, color=\"red\")) + \n    geom_boxplot(aes(y = height, color = \"steelblue\")) + \n  labs(color = \"Anthropometrics\") +\n  scale_color_manual(labels = c(\"Weight\",\"Height\"),\n                     values = c(\"red\", \"steelblue\"))\n\n\n\n\n\n\n\n\n\nCode\nrm(df1)\n\n\nWe then use the ToothGrowth data for for the next few boxplots\n\n\nCode\ndata(ToothGrowth)\nToothGrowth &lt;-\n  ToothGrowth %&gt;% \n  mutate(dose = factor(dose))\nglimpse(ToothGrowth)\n\n\nRows: 60\nColumns: 3\n$ len  &lt;dbl&gt; 4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5,…\n$ supp &lt;fct&gt; VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, V…\n$ dose &lt;fct&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, …\n\n\nAnd then we form the ggplot object\n\n\nCode\np &lt;- \n  ToothGrowth %&gt;% \n  ggplot(aes(x = dose, y = len))\n\n\nOther renditions of the boxplot is as shown below. First rotated one\n\n\nCode\np + geom_boxplot() + coord_flip()     # Axis rotated\n\n\n\n\n\n\n\n\n\nNotched boxplot\n\n\nCode\np + geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\nCustomizaton of the outlier\n\n\nCode\np + geom_boxplot(outlier.colour=\"red\", \n                 outlier.shape=8, \n                 outlier.size=4)\n\n\n\n\n\n\n\n\n\nWe add a statistic to the plot here\n\n\nCode\np + geom_boxplot() + \n    stat_summary(fun = mean, \n                 geom = \"point\", \n                 shape = 18, \n                 size = 4, \n                 col = \"red\")\n\n\n\n\n\n\n\n\n\nAnd then limit the categories the x axis\n\n\nCode\np + \n  geom_boxplot() + \n  scale_x_discrete(limits=c(\"0.5\", \"2\"))\n\n\nWarning: Removed 20 rows containing missing values or values outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nNext a boxplot with a superimposed dotplot\n\n\nCode\np + \n  geom_boxplot() + \n  geom_dotplot(binaxis='y', \n               stackdir='center', \n               dotsize=0.5, \n               binwidth = 1,\n               col = \"red\",\n               fill = \"red\")\n\n\n\n\n\n\n\n\n\nAnd a boxplot with superimposed jittered points\n\n\nCode\np + \n  geom_boxplot() +\n  geom_jitter(shape=16, position=position_jitter(0.2))\n\n\n\n\n\n\n\n\n\nCode\nrm(p)\n\n\nNext we manually set out own color scale\n\n\nCode\nP &lt;- \n  ToothGrowth %&gt;% \n  ggplot(aes(factor(dose), len, color=dose))\n\n\n\n\nCode\nP + \n    geom_boxplot() +\n  scale_color_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n\n\n\n\n\n\n\n\n\nAnd use one of the color scales\n\n\nCode\nP + \n    geom_boxplot() +\n  scale_color_brewer(palette=\"Dark2\") +\n  scale_fill_brewer(palette=\"Dark2\")\n\n\n\n\n\n\n\n\n\nChange the legend position\n\n\nCode\nP + \n  geom_boxplot() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nAnd remove legend\n\n\nCode\nP + \n  geom_boxplot() +\n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\nChange the order of items in the legend\n\n\nCode\nP + \n  geom_boxplot() +\n  scale_x_discrete(limits=c(\"2\", \"0.5\", \"1\"))\n\n\n\n\n\n\n\n\n\nBox plot with multiple groups: Change box plot colors by groups\n\n\nCode\nggplot(ToothGrowth, aes(x=dose, y=len, fill=supp)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nCode\nrm(P)\n\n\nChange the position of the boxes\n\n\nCode\nP &lt;- \n  ggplot(ToothGrowth, aes(x=dose, y=len, fill=supp)) + \n    geom_boxplot(position=position_dodge(1))\nP\n\n\n\n\n\n\n\n\n\nAnd then we add dots\n\n\nCode\nP + geom_dotplot(binaxis='y', \n                 stackdir='center', \n                 position=position_dodge(1),\n                 binwidth = 1)\n\n\n\n\n\n\n\n\n\nCustomized\n\n\nCode\ndataF %&gt;% \n    select(mcv1, mcv2, mcv3, mcv4, mcv5, agecat, id) %&gt;%\n    pivot_longer(cols = mcv1:mcv5, names_to = \"Time\", values_to = \"MCV\") %&gt;% \n    ggplot(aes(x = Time, y = MCV, col = Time), fill = \"snow1\") +\n    geom_boxplot(\n        outlier.color = 'black', \n        outlier.shape = 23, \n        outlier.fill = \"steelblue2\", \n        outlier.size = 2) +\n    stat_summary(\n        aes(fill=Time), \n        fun.data = mean_se, \n        geom = \"pointrange\", \n        size=0.5, \n        shape =23, \n        color = \"black\", \n        show.legend = F) +\n    scale_color_manual(\n        name = \"Measure\", \n        values = c(\"red\", \"yellow\", \"green\", \"violet\", \"brown\"),\n        labels = c(\"First\",\"Second\", \"Third\", \"Fourth\", \"Fifth\")) +\n    scale_x_discrete(\n        labels =c(\n            \"mcv1\" = \"First MCV\", \n            \"mcv2\" = \"Second MCV\", \n            \"mcv3\" = \"Third MCV\", \n            \"mcv4\" = \"Fourth MCV\", \n            \"mcv5\" = \"Fifth MCV\")) +\n    labs(title = \"Distribution of MCVs over the review periods\") +\n    theme(\n        plot.title = element_text(\n            family = \"serif\", \n            face = \"bold.italic\", \n            size = 14, \n            colour = \"steelblue4\", \n            hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    select(mcv1, mcv2, mcv3, mcv4, mcv5, agecat, id) %&gt;%\n    pivot_longer(cols = mcv1:mcv5, names_to = \"Time\", values_to = \"MCV\") %&gt;% \n    ggplot(aes(x = Time, y = MCV, col = Time), fill = \"snow1\") +\n    geom_boxplot(outlier.color = \"white\", outlier.alpha = 0) +\n    geom_jitter(width =.2, alpha = .2, col=1) +\n    labs(\n        x = \"Time of Sample taking\", \n        y = \"Mean Corpuscular Volume\",\n        title = \"Sequential changes in MCV over the study duration\") +\n    theme_bw() +\n    scale_x_discrete(\n        labels = c(\n            \"mcv1\" = \"First MCV\", \n            \"mcv2\" = \"Second MCV\", \n            \"mcv3\" = \"Third MCV\",\n            \"mcv4\" = \"Fourth MCV\",\n            \"mcv5\" = \"Fifth MCV\"))\n\n\n\n\n\n\n\n\nFigure 16.1: Sequential changes in MCV over the study duration\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    select(mcv1, mcv2, mcv3, mcv4, mcv5, agecat, id) %&gt;%\n    pivot_longer(cols = mcv1:mcv5, names_to = \"Time\", values_to = \"MCV\") %&gt;% \n    ggplot(aes(x = Time, y = MCV, col = Time), fill = \"snow1\") +\n    ggbeeswarm::geom_beeswarm() +\n    labs(x = \"Time of Sample taking\", \n         y = \"Mean Corpuscular Volume\",\n         title = \"Sequential changes in MCV over the study duration\") +\n    theme_bw() +\n    scale_x_discrete(\n        labels = c(\n            \"mcv1\" = \"First MCV\", \"mcv2\" = \"Second MCV\", \"mcv3\" = \"Third MCV\", \n            \"mcv4\" = \"Fourth MCV\", \"mcv5\" = \"Fifth MCV\"))",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Boxplot</span>"
    ]
  },
  {
    "objectID": "gr-barplot.html",
    "href": "gr-barplot.html",
    "title": "16  Barplot",
    "section": "",
    "text": "16.1 Basic barplot\nNext, we make the basic Barplot\nCode\np &lt;- \n  df %&gt;% \n  ggplot(aes(x = dose, y = len)) \n\np + geom_bar(stat=\"identity\")\nNext we flip the barlot horizontal, change the size of the bar width and change the theme\nCode\np + \n  geom_bar(\n      stat = \"identity\", \n      width = 0.8, \n      color = \"blue\", \n      fill = \"grey90\") +\n  coord_flip() +\n  theme_bw()\nNext we limit the observations to just two\nCode\np + \n  geom_bar(\n      stat = \"identity\", \n      width = 0.8, \n      color = \"black\", \n      fill = \"steelblue\") +\n  scale_x_discrete(limits=c(\"D0.5\", \"D2\"))\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`).\nNext we put labels on the bars at the outside and inside\nCode\np +\n    geom_bar(stat=\"identity\", fill=\"steelblue\")+\n    geom_text(\n        aes(label=len), \n        vjust=-0.5, \n        size=4, \n        col = \"black\")+\n    theme_minimal()\nCode\n# Change barplot line colors by groups\np &lt;- \n    ggplot(df, aes(x = dose, y = len, color = dose)) + \n    geom_bar(stat = \"identity\", fill = \"white\") + \n    geom_text(aes(label=len), vjust=1.5, size=5, col = \"red\")\np",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Barplot</span>"
    ]
  },
  {
    "objectID": "gr-barplot.html#use-custom-color-palettes",
    "href": "gr-barplot.html#use-custom-color-palettes",
    "title": "16  Barplot",
    "section": "16.2 Use custom color palettes",
    "text": "16.2 Use custom color palettes\n\n\nCode\np + scale_color_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n\n\n\n\n\n\n\n\n\nUse brewer color palettes\n\n\nCode\np + scale_color_brewer(palette=\"Dark2\")\n\n\n\n\n\n\n\n\n\n\n\nCode\np + scale_color_grey() + theme_classic()\n\n\n\n\n\n\n\n\n\nChange barplot fill colors by groups\n\n\nCode\n# \np &lt;- \n  ggplot(df, aes(x=dose, y=len, fill=dose)) +\n  geom_bar(stat=\"identity\")+theme_minimal()\np\n\n\n\n\n\n\n\n\n\nUse custom color palettes\n\n\nCode\np + scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\np + \n  scale_fill_brewer(palette=\"Dark2\")\n\n\n\n\n\n\n\n\n\nUse grey scale\n\n\nCode\np + scale_fill_grey()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x=dose, y=len, fill=dose))+\n    geom_bar(stat=\"identity\", color=\"black\")+\n    scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\"))+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nChange bar fill colors to blues\n\n\nCode\np + scale_fill_brewer(palette=\"Blues\")\n\n\n\n\n\n\n\n\n\nCode\n    p + theme(legend.position=\"top\")\n\n\n\n\n\n\n\n\n\nCode\n    p + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\nCode\n    p + theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\nChange position of bars\n\n\nCode\np + \n  scale_x_discrete(limits=c(\"D2\", \"D0.5\", \"D1\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndat &lt;- foreign::read.dta(\"C:/dataset/bea_organ_damage_28122013.dta\")\nBC &lt;- \n  dat %&gt;% \n  select(q2idtype, q3sex) %&gt;% \n  na.omit() %&gt;% \n  group_by(q2idtype, q3sex) %&gt;% \n  summarize(Freq = n()) %&gt;% \n  ggplot(aes(x=q2idtype, y=Freq, fill=q3sex))\n\n\n`summarise()` has grouped output by 'q2idtype'. You can override using the\n`.groups` argument.\n\n\nNext we draw the barplot using the economist theme from the ggthemes package\n\n\nCode\nBC +  \n  geom_bar(stat=\"identity\", position= position_dodge()) +\n    geom_text(aes(label=Freq), vjust=1.6, color=\"black\", \n              size=4, position = position_dodge(0.9)) +\n    scale_fill_brewer(palette=\"Reds\") + \n    labs(title=\"My Barplot\", x=\"Case or Control\", y=\"Frequency\") +\n    scale_color_discrete(name=\"Sex\") + \n    ggthemes::theme_stata()\n\n\n\n\n\n\n\n\n\nNext we plot a baroplot with error bars. To do that we first we form the ggplot object that we call BC.\n\n\nCode\nBC &lt;-\n  dat %&gt;% \n  select(Type = q2idtype, Sex = q3sex, q12weight) %&gt;% \n  na.omit() %&gt;% \n  group_by(Type, Sex) %&gt;% \n  summarize(Mean.wgt = mean(q12weight), SD.wgt = sd(q12weight)) %&gt;% \n  ggplot(aes(x=Type, y=Mean.wgt, fill=Sex))\n\n\n`summarise()` has grouped output by 'Type'. You can override using the\n`.groups` argument.\n\n\nAnd then plot the graph\n\n\nCode\nBC +  \n  geom_bar(stat=\"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=Mean.wgt-SD.wgt, ymax=Mean.wgt+SD.wgt), \n                  width=.2, size=0., position=position_dodge(.9)) +\n    labs(title=\"Mean weight with error bars\", \n         x=\"Case or Control\", \n         y=\"Mean(kgs)\") +\n    scale_fill_brewer(palette=\"Paired\") + \n    ggthemes::theme_stata()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf2 &lt;- data.frame(supp=rep(c(\"VC\", \"OJ\"), each=3),\n                dose=rep(c(\"D0.5\", \"D1\", \"D2\"),2),\n                len=c(6.8, 15, 33, 4.2, 10, 29.5))\nhead(df2)\n\n\nTRUE   supp dose  len\nTRUE 1   VC D0.5  6.8\nTRUE 2   VC   D1 15.0\nTRUE 3   VC   D2 33.0\nTRUE 4   OJ D0.5  4.2\nTRUE 5   OJ   D1 10.0\nTRUE 6   OJ   D2 29.5\n\n\n\n\nCode\ndf2 %&gt;% \n  ggplot(aes(x=dose, y=len, fill=supp)) +\n  geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf2 %&gt;% \n  ggplot(aes(x=dose, y=len, fill=supp)) + \n  geom_bar(stat=\"identity\", position=position_dodge())\n\n\n\n\n\n\n\n\n\nChange color manually\n\n\nCode\np &lt;- \n  ggplot(data=df2, aes(x=dose, y=len, fill=supp)) +\n  geom_bar(stat=\"identity\", color=\"black\", position=position_dodge()) +\n  scale_fill_manual(values=c('#999999','#E69F00')) +\n  theme_minimal()\np\n\n\n\n\n\n\n\n\n\nCreate some data\n\n\nCode\ndf_sorted &lt;- \n  tibble(supp = factor(rep(c(\"VC\", \"OJ\"), each=3)),\n         dose = rep(c(\"0.5\", \"1\", \"2\"),2),\n         len = c(6.8, 15, 33, 4.2, 10, 29.5)) %&gt;% \n  arrange(dose, supp) %&gt;% \n  group_by(dose) %&gt;% \n  mutate(label_ypos=cumsum(len))\ndf_sorted\n\n\n# A tibble: 6 × 4\n# Groups:   dose [3]\n  supp  dose    len label_ypos\n  &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1 OJ    0.5     4.2        4.2\n2 VC    0.5     6.8       11  \n3 OJ    1      10         10  \n4 VC    1      15         25  \n5 OJ    2      29.5       29.5\n6 VC    2      33         62.5\n\n\n\n\nCode\ndf_sorted %&gt;% \n  ggplot(aes(x=dose, y=len, fill=supp)) +\n  geom_bar(stat=\"identity\")+\n  geom_text(aes(y=label_ypos, label=len), vjust=1.6, \n            color=\"white\", size=3.5)+\n  scale_fill_brewer(palette=\"Paired\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nPlotting barplot with x-axis treated as continuous variable\n\n\nCode\n# \ndf_sorted %&gt;% \n  mutate(dose = as.numeric(dose)) %&gt;% \n  ggplot(aes(x=dose, y=len, fill=supp)) +\n  geom_bar(stat=\"identity\", position=position_dodge())+\n  scale_fill_brewer(palette=\"Paired\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Axis treated as discrete variable\ndf_sorted %&gt;% \n  mutate(dose = as.factor(dose)) %&gt;% \n  ggplot(aes(x=dose, y=len, fill=supp)) +\n  geom_bar(stat=\"identity\", position=position_dodge())+\n  scale_fill_brewer(palette=\"Paired\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nToothGrowth %&gt;% \n  mutate(dose = as.factor(dose)) %&gt;% \n  group_by(supp, dose) %&gt;% \n  summarise(sd = sd(len), len = mean(len)) %&gt;% \n  ggplot(aes(x=dose, y=len, fill=supp)) + \n  geom_bar(stat=\"identity\", position=position_dodge()) +\n  geom_errorbar(aes(ymin=len-sd, ymax=len+sd), width=.2, \n                position=position_dodge(.9)) +\n  labs(title=\"Plot of length  per dose\", x=\"Dose (mg)\", y = \"Length\")+\n  scale_fill_brewer(palette=\"Paired\") + \n  theme_minimal()\n\n\n`summarise()` has grouped output by 'supp'. You can override using the\n`.groups` argument.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Barplot</span>"
    ]
  },
  {
    "objectID": "gr-scatter.html",
    "href": "gr-scatter.html",
    "title": "17  Scatter Plot",
    "section": "",
    "text": "Code\ndat &lt;- foreign::read.dta(\"C:/Dataset/bea_organ_damage_28122013.dta\")\n\ndataF &lt;- readstata13::read.dta13(\"C:/Dataset/olivia_data_wide.dta\")\n\ndf1 &lt;- read.csv(\"C:\\\\Users\\\\Sbngu\\\\Dropbox\\\\Data for book\\\\booking1.csv\")\n\nSC &lt;- \n  dat %&gt;% \n  select(q12weight, q13waist, q3sex, q10what) %&gt;% \n  drop_na() %&gt;%\n  ggplot(aes(x = q12weight, y = q13waist, color = q3sex))\n\n\n\n\nCode\nSC + \n    geom_point(shape = \"diamond\", size = 2) +\n    labs(\n        x = \"Weight (kgs)\", \n        color = \"Gender\",\n        y = \"Waist Circumference (cms)\") +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\") +\n    theme(\n        axis.title.x = element_text(\n            vjust = 0, \n            size = 14, \n            color = \"blue\", \n            face = \"italic\"),\n        axis.title.y = element_text(\n          vjust = 2, \n          size = 14, \n          color = \"firebrick\", \n          face = \"bold\"),\n        axis.text = element_text(\n          color = \"dodgerblue\", size = 12),\n        axis.text.x = element_text(face = \"italic\"))\n\n\n\n\n\n\n\n\nFigure 17.1: Relationship between weight and waist circunference\n\n\n\n\n\n\n\nCode\nSC +    \n  geom_point(aes(shape = q3sex)) + \n    geom_smooth(method=lm, formula = y~x, se=F) + \n    theme_bw(base_family = \"serif\") +\n    labs(\n        x = \"Weight (kgs)\", \n        y = \"Waist Circumference (cms)\") + \n    theme(\n        plot.title=element_text(size=15, face=\"bold\"), \n        axis.text.x=element_text(size=12), \n        axis.text.y=element_text(size=12),\n        axis.title.x=element_text(size=13),\n        axis.title.y=element_text(size=13), \n        plot.background = element_rect(fill = \"grey90\"),\n        panel.background = element_rect(fill = \"snow1\")) +\n    scale_color_discrete(name=\"Sex\") +\n    scale_shape_discrete(name=\"Sex\")\n\n\n\n\n\n\n\n\nFigure 17.2: Relationship between weight and waist circunference\n\n\n\n\n\n\n\nCode\nSC +    \n    geom_point() + \n    geom_smooth(method=loess, se=TRUE, formula = y~x) + \n    theme_classic() +\n    labs(\n        x = \"Weight (kgs)\", \n        y = \"Waist Circumference (cms)\") + \n    theme(\n        plot.title=element_text(size=15, face=\"bold\"), \n        axis.text.x=element_text(size=12), \n        axis.text.y=element_text(size=12),\n        axis.title.x=element_text(size=13),\n        axis.title.y=element_text(size=13)) + \n  scale_color_discrete(name=\"Sex\")\n\n\n\n\n\n\n\n\nFigure 17.3: Relationship between weight and waist circunference\n\n\n\n\n\n\n\nCode\nSC +    \n  geom_point() + \n    geom_smooth(method=lm, formula = y ~ x, se=F) + \n    theme_minimal() +\n    labs(\n        x = \"Weight (kgs)\", \n        y = \"Waist Circumference (cms)\") + \n    theme(\n        plot.title=element_text(size=15, face=\"bold\"), \n        axis.text.x=element_text(size=12), \n        axis.text.y=element_text(size=12),\n        axis.title.x=element_text(size=13),\n        axis.title.y=element_text(size=13)) + \n    scale_color_discrete(name = \"Sex\") + \n    facet_wrap(~q10what)\n\n\n\n\n\n\n\n\nFigure 17.4: Relationship between weight and waist circunference\n\n\n\n\n\n\n\nCode\nSC + \n  geom_point(color = \"firebrick\") +\n  labs(\n      x = \"Weight (kgs)\", \n      y = \"Waist Circumference (cms)\") +\n  theme(axis.ticks.y = element_blank(),\n        axis.text.y = element_blank())\n\n\n\n\n\n\n\n\nFigure 17.5: Relationship between weight and waist circunference\n\n\n\n\n\nLimit Axes Range\n\n\nCode\ndf1 %&gt;% \n    drop_na(weight, height) %&gt;% \n  ggplot(aes(x = weight, y = height)) +\n    geom_point(aes(color = sex, shape = sex)) + \n    geom_smooth(method = \"lm\", formula = y ~ x, se = T) + \n    labs(x = \"Weight (kgs)\", y = \"Height (cm)\") +\n    theme_light() +\n    theme(\n        plot.title=element_text(size = 16, face = \"bold\"), \n        axis.text.x=element_text(size = 12), \n        axis.text.y=element_text(size = 12),\n        axis.title.x=element_text(size = 12, face = \"bold\"),\n        axis.title.y=element_text(size = 12, face = \"bold\")) + \n    scale_color_discrete(name=\"Gender\") + \n    scale_shape_discrete(name=\"Gender\")\n\n\n\n\n\n\n\n\nFigure 17.6: Plot of Weight versus height\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    mutate(\n        mcv_cat_1 = case_when(\n            mcv1 &lt; 80 ~ \"Microcyte\",\n            mcv1 &gt;= 80 & mcv1 &lt;= 90 ~ \"Normal\",\n            mcv1 &gt; 90 ~ \"Macrocyte\") %&gt;% \n            factor(levels = c(\"Microcyte\", \"Normal\", \"Macrocyte\"))) %&gt;% \n    ggplot(aes(x = hb1, y = hb2)) +\n    geom_point(aes(size = mcv_cat_1, col = mcv_cat_1), alpha = .5) +\n    geom_smooth(formula = y ~ x, method = \"lm\", color = \"black\") +\n    geom_vline(\n        xintercept = 10, \n        color = \"red\", \n        linewidth = 0.5, \n        linetype = \"dashed\") +\n    geom_hline(\n        yintercept = 10, \n        color = \"red\", \n        linewidth = 0.5, \n        linetype = \"dashed\") +\n    geom_abline(\n        intercept = 0, \n        slope = 1, \n        color = \"brown\", \n        linewidth = 0.5, \n        linetype = \"dashed\") +\n    labs(x = \"First Hemoglobin\", y = \"Second Hemoglobin\") +\n    theme_light()\n\n\n\n\n\n\n\n\nFigure 17.7: Relationship between first and second platelet counts showing possible outliers\n\n\n\n\n\n\n\nCode\ndataF.2 &lt;- \n    tibble(\n    lbls = c(\"Kofi\",\"Ama\", \"Yaw\",\"Sammy\", \"Abena\"),\n    hgts = c(176, 154, 136, 144, 165),\n    wgts = c(65, 76,48,77, 65))\n\ndataF.2 %&gt;% \n    ggplot(aes(x = hgts, y = wgts))+\n    geom_point() +\n    annotate(\n        \"text\", \n        x = dataF.2$hgts, \n        y = dataF.2$wgts, \n        label = dataF.2$lbls, \n        vjust = 1, col=1:5) +\n    labs(\n        title = \"Height vrs Weight\", \n        subtitle = \"Yes we can\", \n        caption = \"2020 Data\")+\n    ggthemes::theme_gdocs() +\n    scale_y_continuous(\n        name = \"Weight (kgs)\", \n        limits = c(40, 80), \n        breaks = c(45, 50, 55, 60, 65, 70, 75)) +\n    scale_x_continuous(\n        name = \"Height (kgs)\", \n        limits = c(130, 200), \n        breaks = seq(130, 190, 10)) +\n    geom_label(aes(label = lbls), col = \"grey\", nudge_y = 3)\n\n\n\n\n\n\n\n\nFigure 17.8: Height v. Weight\n\n\n\n\n\n\n\nCode\ndataG &lt;- \n    dataF %&gt;% \n    mutate(is_outlier = (plt1&lt;50 | plt2&lt;100 | plt2&gt;400 | plt1&gt;400)) \n\ndataG %&gt;% \n    ggplot(aes(x = plt1, y = plt2, col = is_outlier)) + \n    geom_point() +\n    labs(\n        x = \"First Platelet Count\",\n        y = \"Second Platelet Count\",\n        title = \"Relationship between first and second platelet counts showing possible outliers\")+\n    theme_bw()+\n    ggrepel::geom_label_repel(\n        data = filter(dataG, is_outlier == TRUE), \n        aes(label=id)) +\n    theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\nFigure 17.9: Relationship between first and second platelet counts showing possible outliers\n\n\n\n\n\n\n\nCode\np1 &lt;-\n    dataF %&gt;% \n    ggplot(aes(x = hb1, y = hb2))+\n    geom_point(col = \"maroon\") +\n    geom_smooth(formula = y~x, method = \"lm\") +\n    theme_bw() +\n    labs(\n        x = \"First HgB measurement (g/dL)\",\n        y = \"Second HgB measurement (g/dL)\")\n\np2 &lt;- \n    dataF %&gt;% \n    ggplot() +\n    geom_histogram(aes(x=hb1),bins = 12, col=\"black\", fill = \"grey\") +\n    labs(x=NULL, y=NULL) +\n    theme_void() +\n    theme(\n        axis.ticks.y = element_blank(),\n        axis.ticks.x  = element_blank(),\n        axis.line.x = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank())\n\np3 &lt;- \n    dataF %&gt;% \n    ggplot() +\n    geom_histogram(aes(x=hb2),bins = 12, col=\"black\", fill = \"grey\") +\n    coord_flip()+\n    labs(x=NULL, y=NULL) +\n    theme_void() +\n    theme(\n        axis.ticks.y = element_blank(),\n          axis.ticks.x  = element_blank(),\n          axis.line.x = element_blank(),\n          axis.line.y = element_blank(),\n          axis.text.x = element_blank(),\n          axis.text.y = element_blank())\n\ncol1 &lt;- (p2/p1) + plot_layout(heights = c(1,4))\ncol2 &lt;- (plot_spacer()/p3) + plot_layout(heights = c(1,4))\n(col1 | col2) +  \n    plot_layout(widths = c(5,1)) +\n    plot_annotation(caption = \"Source: 2021 Data\")\n\n\n\n\n\n\n\n\nFigure 17.10: My special scatterplot with histograms of first and secon HgB\n\n\n\n\n\n\n\nCode\np1 &lt;-\n    dataF %&gt;% \n    ggplot(aes(x=hb1, y = hb2, col = fpreg)) +\n    geom_point() +\n    geom_density_2d(color = \"blue\")\n\np2 &lt;-\n    dataF %&gt;% \n    ggplot(aes(x=hb1, y = hb3, col = fpreg)) +\n    geom_point() +\n    geom_density_2d(color = \"blue\")\n\n(p1 + p2) +\n    plot_annotation(\n        title = \"My special title is here\",\n        subtitle = \"Yes it is here\",\n        caption = \"Why not!\",\n        theme = theme(\n            plot.title = element_text(family =\"serif\", colour = \"red\"),\n            plot.subtitle = element_text(\n                family = \"serif\", color = \"red\", face = \"italic\")),\n        tag_levels = \"A\") + \n    plot_layout(widths = c(1, 2),guides = \"collect\")\n\n\n\n\n\n\n\n\nFigure 17.11: Combining plots\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    mutate(hct3 = ifelse(hct3 &lt; 20, hct3 +40, hct3),\n           hct3 = ifelse(hct3 &gt; 60, hct3 - 20, hct3)) %&gt;% \n    ggplot(aes(x = hct3, y = hb3)) +\n    geom_point(color = \"grey45\") +\n    geom_smooth(aes(x = hct3, y = hb3, col =  \"Observed\"), \n                formula = y~x, method = \"lm\", se = F) + \n    geom_segment(aes(x = min(hct3), y = min(hct3/3), \n                     xend = max(hct3), yend = max(hct3/3), \n                     col =  \"Expected\"))+\n    labs(title = \"Relationship between the third HB and HCT measurements\",\n         subtitle = \"Comparison of observed  and expected regression line if HCT = 3*HB\",\n         x = \"Hematocrit (%)\", y = \"Hemoglobin (mg/dl)\", \n         color = \"Regression Line\") +\n    theme_classic()+\n    theme(plot.title = element_text(face = \"bold\"),\n          plot.subtitle = element_text(face = \"italic\"))\n\n\nWarning in geom_segment(aes(x = min(hct3), y = min(hct3/3), xend = max(hct3), : All aesthetics have length 1, but the data has 350 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    ggplot(size = 0.5) +\n    geom_point(aes(hb3, mcv3, color = mcv1, size = occup, shape = educ)) + \n    guides(color = guide_colorbar(title = \"First MCV\"),\n           shape = guide_legend(title = \"Educational level\"), \n           size = guide_legend(title = \"Occupation\"))\n\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;%\n    mutate(mari = fct_collapse(mari, \n                             \"Married\" = c(\"Married\",\"Cohabiting\"),\n                             \"Single\" = c(\"Widowed\", \"Divorced\"))) %&gt;% \n    ggplot()+\n    geom_point(aes(x = avehb, y = avehct, color = mari), show.legend = F) +\n    geom_smooth(aes(x = avehb, y = avehct), se=F, formula = y~x, \n                method = \"lm\", size = 1, alpha = .5, col = \"grey\")+\n    facet_wrap(~mari, nrow = 2, strip.position = \"left\") +\n    labs(y = \"Hematocrit (%)\", x = \"Hemoglobin (g/dl)\", \n         title = str_glue(\"Relationship between Blood hemoglobin and \",\n                          \"Hematocrit stratified by marital status\"))+\n    theme(panel.background = element_blank(),\n          panel.grid = element_blank(),\n          axis.line = element_line(),\n          strip.placement = \"outside\",\n          strip.background = element_rect(fill = \"#c1d3fe\", color = \"black\"),\n          strip.text = element_text(size = 10, face = \"bold\"),\n          text = element_text(family = \"serif\"),\n          axis.text = element_text(size = 10, face = \"bold\"),\n          axis.title = element_text(size = 10, face = \"bold.italic\"),\n          plot.title = element_text(face = \"bold\"))\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Scatter Plot</span>"
    ]
  },
  {
    "objectID": "gr-line-plot.html",
    "href": "gr-line-plot.html",
    "title": "18  Line Graphs",
    "section": "",
    "text": "Code\ndataD &lt;- readxl::read_excel(\"C:/Dataset/rainfall.xlsx\")\n\nthe_year &lt;- 2001\ndataD %&gt;% \n    janitor::clean_names() %&gt;% \n    rename(date_1 = time) %&gt;% \n    arrange(date_1) %&gt;% \n    mutate(\n        year_1 = lubridate::year(date_1),\n        day = lubridate::day(date_1), \n        mth = lubridate::month(date_1),\n        the_year = year_1 == the_year) %&gt;%\n    group_by(year_1) %&gt;% \n    mutate(cum_rainfall = cumsum(rainfall)) %&gt;% \n    ungroup() %&gt;% \n    mutate(new_date = lubridate::ymd(str_glue(\"2000-{mth}-{day}\"))) %&gt;% \n    ggplot(\n        aes(x = new_date, y = cum_rainfall, \n            group = year_1, \n            size = the_year)) +\n    geom_line(aes(col = the_year)) +\n    labs(\n        y = \"cumulative Rainfall (mm)\")+\n    scale_x_date(name = NULL, date_breaks = \"1 month\", date_labels = \"%b\") +\n    scale_color_manual(\n        name = \"Year\", \n        labels = c(\"Others\", the_year), \n        values = c(\"grey\",\"red\"))+\n    scale_size_manual(breaks = c(F,T), values = c(0.5,0.7), guide = \"none\")+\n    scale_y_continuous(breaks = seq(0,1500, 250), expand = c(0,50)) +\n    theme_classic()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nFigure 18.1: Cumulative rainfall pattern in Kumasi, Ghana (2000 - 2004)\n\n\n\n\n\n\n\nCode\ndataF &lt;- \n    readstata13::read.dta13(\n        \"C:/Dataset/olivia_data_wide.dta\",\n        nonint.factors = TRUE)\n\ndataF %&gt;% \n    group_by(educ) %&gt;% \n    summarize(across(c(mcv1, mcv2, mcv3, mcv4, mcv5), mean)) %&gt;% \n    pivot_longer(col = mcv1:mcv5) %&gt;% \n    mutate(\n        illitrate = ifelse(educ==\"None\", \"Illitrate\",\"Educated\") %&gt;% \n            factor()) %&gt;% \n    ggplot(aes(x = name, y = value, col = illitrate, group = educ)) +\n    geom_line(aes(size=illitrate)) +\n    geom_point(size = 1.5)+\n    labs(title = \"Evolution of mean platelets count over the five measurements\",\n         y = \"Count\",x = NULL)+\n    scale_color_manual(name = \"Educational Status\", values = c(\"grey50\",\"red\"), \n                       label = c(\"Educated\",\"Illitrate\")) +\n    scale_size_manual(name = \"Educational Status\", values = c(0.5, 1)) +\n    scale_y_continuous(limits = c(70, 120)) +\n    theme_bw()+\n    theme(legend.position = \"bottom\")",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Line Graphs</span>"
    ]
  },
  {
    "objectID": "gr-forest-plot.html",
    "href": "gr-forest-plot.html",
    "title": "19  Forest Plot",
    "section": "",
    "text": "Forest plot example\n\n\nCode\nlabel &lt;- paste0(\"X\", 1:6)\nmean  &lt;- c(1.29,0.76,2.43,1.68,1.22,1.7) \nlower &lt;- c(0.84,0.50,1.58,1.1,0.8,1.11)\nupper &lt;- c(1.95,1.16,3.67,2.54,1.85,2.56)\n\ndf &lt;- data.frame(label, mean, lower, upper)\n\n# reverses the factor level ordering for labels after coord_flip()\ndf$label &lt;- factor(df$label, levels=rev(df$label))\n\nlibrary(ggplot2)\nfp &lt;- ggplot(data=df, aes(x=label, y=mean, ymin=lower, ymax=upper)) +\n        geom_pointrange() + \n        geom_hline(yintercept=1, lty=2) +  # add a dotted line at x=1 after flip\n        coord_flip() +  # flip coordinates (puts labels on y axis)\n        xlab(\"Label\") + ylab(\"Mean (95% CI)\") +\n        theme_bw()  # use a white background\nprint(fp)",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forest Plot</span>"
    ]
  },
  {
    "objectID": "gr-population-pyramid.html",
    "href": "gr-population-pyramid.html",
    "title": "20  Population Pyramid",
    "section": "",
    "text": "20.0.0.1 Population Pyramid\n\n\nCode\nreadxl::read_xlsx(\n        \"C:/Dataset/ghana.xlsx\",\n        skip = 3, \n        sheet = \"2000 - 2020\", \n        range = \"A4:ARD262\") %&gt;% \n    select(ends_with(\"20\")) %&gt;% \n    filter(BTOTL_2020==29340248) %&gt;% \n    pivot_longer(cols = BTOTL_2020:F80PL_2020) %&gt;% \n    filter(!name %in% c(\"BTOTL_2020\", \"MTOTL_2020\", \"FTOTL_2020\") ) %&gt;% \n    filter(!str_detect(name, \"^B\")) %&gt;% \n    mutate(\n        sex = str_extract(name, \"^\\\\w\"),\n        agegrp = str_c(str_sub(name, 2, 3),\"-\", str_sub(name, 4,5)),\n        Population = ifelse(sex == \"F\", -value, value)) %&gt;% \n    ggplot(aes(x = agegrp, y = Population, fill = sex)) + \n    geom_bar(stat = \"identity\") + \n    labs(x = \"Age Grouping in Years\", y = NULL, fill = \"Gender\") +\n    scale_y_continuous(\n        breaks = seq(-2000000, 2000000, 500000), \n        labels = paste0(as.character(c(seq(2.0, 0.5, -0.5), \n        seq(0, 2.0, 0.5))), \"m\")) + \n    coord_flip() +\n    scale_fill_brewer(palette = \"Set1\", labels = c(\"Female\",\"Male\")) + \n    theme_classic()\n\n\n\n\n\n\n\n\nFigure 20.1: Population pyramid of Ghana (2020)",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Population Pyramid</span>"
    ]
  },
  {
    "objectID": "gr-miscellaneous.html",
    "href": "gr-miscellaneous.html",
    "title": "21  Miscellaneous",
    "section": "",
    "text": "Code\ndataF %&gt;% \n    ggplot(aes(x = hb1, y = hb2, color = educ, shape = educ)) +\n    geom_point() +\n    geom_smooth(formula = y ~ x, method = \"lm\") +\n    theme_light()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    select(starts_with(\"hb\"), fpreg) %&gt;% \n    GGally::ggpairs(columns = 1:5, aes(colour = fpreg)) + \n    scale_fill_brewer(palette = \"Set1\") +\n    scale_colour_brewer(palette = \"Set1\")\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    mutate(mcv_cat_1 = case_when(mcv1 &lt; 80 ~ \"Microcyte\",\n                                 mcv1 &gt;= 80 & mcv1 &lt;= 90 ~ \"Normal\",\n                                 mcv1 &gt; 90 ~ \"Macrocyte\") %&gt;% \n               factor(levels = c(\"Microcyte\", \"Normal\", \"Macrocyte\"))) %&gt;% \n    ggplot(aes(x = hb1, y = hb2)) +\n    geom_point(aes(size = mcv_cat_1, col = mcv_cat_1), alpha = .5) +\n    geom_smooth(formula = y ~ x, method = \"lm\", color = \"black\") +\n    geom_vline(xintercept = 10, color = \"red\", size = 0.5, linetype = \"dashed\") +\n    geom_hline(yintercept = 10, color = \"red\", size = 0.5, linetype = \"dashed\") +\n    geom_abline(intercept = 0, slope = 1, color = \"brown\", size = 0.5, \n                linetype = \"dashed\") +\n    labs(x = \"First Hemoglobin\", \n         y = \"Second Hemoglobin\", \n         title = \"Hemoglobin on Hemoglobin Distribution\") +\n    theme_light()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    select(mcv1, mcv2, mcv3, mcv4, mcv5, agecat, id) %&gt;%\n    pivot_longer(cols = mcv1:mcv5, names_to = \"Time\", values_to = \"MCV\") %&gt;% \n    ggplot(aes(x = Time, y = MCV, col = Time), fill = \"snow1\") +\n    geom_boxplot(outlier.color = \"white\", outlier.alpha = 0) +\n    geom_jitter(width =.2, alpha = .2, col=1) +\n    labs(x = \"Time of Sample taking\", \n         y = \"Mean Corpuscular Volume\",\n         title = \"Sequential changes in MCV over the study duration\") +\n    theme_bw() +\n    scale_x_discrete(labels =c(\"mcv1\" = \"First MCV\", \n                               \"mcv2\" = \"Second MCV\", \n                               \"mcv3\" = \"Third MCV\",\n                               \"mcv4\" = \"Fourth MCV\",\n                               \"mcv5\" = \"Fifth MCV\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    ggplot(aes(x = mcv1, y = mch1, size = mcv1)) +\n    geom_point(shape = 23, aes(fill = agecat), alpha =.2) +\n    scale_x_continuous(name = \"Initial Mean Corpuscular Volume\",\n                       breaks = seq(50, 130, 10),\n                       labels = c(\"50.0\",\"60.0\",\"70.0\", \"80.0\", \"90.0\", \"100.0\", \n                                  \"110.0\",\"120.0\", \"130.0\"), \n                       position = \"top\") +\n    scale_y_continuous(name = \"Mean Corpuscular Hemoglobin\", \n                       limits = c(15,45),\n                       breaks = c(15, 30, 45), \n                       labels = c(\"15.00\",\"30.00\",\"45.00\"),\n                       position = \"right\") +\n    scale_fill_manual(name = \"Age Category\", \n                      values = c(\"blue\", \"red\", \"green\", \"brown\")) +\n    scale_size_continuous(name = \"MCV\",\n                          range = c(1,4), \n                          limits = c(50, 140), \n                          breaks = c(80, 120, 140),\n                          labels = c(\"Microcyte\", \"Normocyte\", \"Macrocyte\"))\n\n\n\n\n\n\n\n\n\n\n21.0.0.1 Elipse to show grouping\n\n\nCode\ndataF %&gt;% \n    ggplot(size = 0.5) +\n    geom_point(aes(hb3, mcv3, color = mcv1, size = occup, shape = educ)) + \n    guides(color = guide_colorbar(title = \"First MCV\"),\n           shape = guide_legend(title = \"Educational level\"), \n           size = guide_legend(title = \"Occupation\"))\n\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.2 Histogram with density overlay\n\n\nCode\ndataF %&gt;% \n    ggplot(aes(x = hb1, y = ..density..)) +\n    geom_histogram(fill = \"skyblue\", col = \"black\", bins = 15)+\n    geom_density(aes(y = ..density..), col = \"red\", size= 1) +\n    labs(x = \"First HB\", y = \"Density\", title = \"Distribution of HgB\")+\n    theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.3 Histogram with normal overlay\n\n\nCode\ndataF %&gt;% \n    ggplot(aes(x = hb2))+\n    geom_histogram(aes(y = ..density..), bins=10, fill = \"snow\", col = \"red\") +\n    stat_function(fun = dnorm, \n                  args = list(mean = mean(dataF$hb2, na.rm=T), \n                              sd = sd(dataF$hb2)), col = \"blue\",\n                  size = 1.5)\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.4 Scatter plot by the various age groups - Facetting\n\n\nCode\nagecat_label &lt;- \n    c(\"Age: 10-19 years\", \"Age: 20-29 years\",\n      \"Age: 30-39 years\",\"Age: 40-49 years\")\n\nnames(agecat_label) &lt;- c(\"10-19\", \"20-29\", \"30-39\", \"50-59\")\n\ndataF %&gt;%\n    ggplot(aes(hb3, mcv3), size = 0.5) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y~x) +\n    labs(\n        title = \"Relationship between hemoglobin and mean corpuscular volume\",\n        x =  \"Hemoglobin (mg/dl)\",\n        y = \"Mean Corpuscular Volume (fl)\")+\n    theme_bw()+\n    facet_wrap(facets = .~agecat, labeller = labeller(agecat = agecat_label))+\n    theme(\n        text = element_text(family = \"serif\"),\n        strip.text = element_text(face = \"bold\"),\n        strip.background = element_rect(fill = \"white\"),\n        plot.title = element_text(face = 'bold'))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    ggplot(aes(hb3, mcv3), size = 0.5) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y~x) +\n    labs(\n        title = \"Relationship between hemoglobin and mean corpuscular volume\",\n        x =  \"Hemoglobin (mg/dl)\",\n        y = \"Mean Corpuscular Volume (fl)\")+\n    theme_bw() +\n    facet_grid(occup ~ agecat, labeller = labeller(agecat = agecat_label))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    ggplot(aes(hb3, mcv3), size = 0.5) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y~x) +\n    labs(\n        title = \"Relationship between hemoglobin and mean corpuscular volume\",\n        x =  \"Hemoglobin (mg/dl)\",\n        y = \"Mean Corpuscular Volume (fl)\")+\n    theme_bw() +\n    facet_wrap(c(\"occup\", \"agecat\"), nrow = 3, labeller = labeller(agecat = agecat_label))\n\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.5 Venn Diagram\n\n\nCode\ndf &lt;- \n    tibble(x=c(1,2,3), y=c(2,3.5,2), lab1 = c(\"A\",\"B\",\"C\"), counts = 1:3)\ndf %&gt;% \n    ggplot() +\n    ggforce::geom_circle(aes(x0 = x, y0 = y, r = 1.4, fill = lab1), \n                         alpha = .3, size = 1, colour = 'grey') +\n    coord_fixed() +\n    theme_void() +\n    scale_fill_manual(values = c('cornflowerblue', 'firebrick',  'gold')) +\n    scale_colour_manual(values = c('cornflowerblue', 'firebrick', 'gold'), \n                        guide = \"none\") +\n    labs(fill = NULL, title = \"My Venn Diagram I\") + \n     annotate(\"text\", \n              x = c(2, 3.5, 2.7, 1.2,   2,  2, 0.3), \n              y = c(4,   2, 2.7, 2.8, 2.5, 1.5, 1.8), \n              label = 1:7, size = 5, fontface = \"bold\") +\n    theme(plot.title = element_text(hjust = 0.5, family = \"serif\", \n                                    face = \"bold\", size = 16, colour = \"red\"),\n          legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.6 Correlation Plot\n\n\nCode\ndataF %&gt;% \n    select(hb1:hb3, hb4, hb5, hct1:hct3, hct4, hct5) %&gt;% \n    cor() %&gt;% \n    ggcorrplot::ggcorrplot(hc.order = FALSE, \n           type = \"lower\", \n           lab = TRUE, \n           lab_size = 3, \n           method=\"square\", \n           colors = c(\"tomato2\", \"white\", \"springgreen3\"), \n           title=\"Correlogram of blood indices\", \n           ggtheme=theme_bw)\n\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.7 Plotting Prediction Interval\n\n\nCode\ndataLM &lt;- dataF %&gt;% select(hct4, hb4)\n\nlm(hb4 ~ hct4, data = dataLM) %&gt;% \n    predict(interval = \"predict\") %&gt;% \n    as_tibble() %&gt;% \n    bind_cols(dataLM) %&gt;% \n    ggplot(aes(x = hct4, y = hb4)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y~x, se=T)+\n    geom_line(aes(y = lwr), col = \"coral2\", linetype = \"dashed\") +\n    geom_line(aes(y = upr), col = \"coral2\", linetype = \"dashed\") +\n    labs(title = \"Relationship between HB4 and HCT4 with fillted line, prediction and se intervals\",\n         x = \"HCT 4 (%)\", y = \"HB 4 (mg/dl)\", caption = \"Nurse Data 2015\")+\n    theme_bw()\n\n\nWarning in predict.lm(., interval = \"predict\"): predictions on current data refer to _future_ responses\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.8 Color Palletes\n\n\nCode\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    group_by(anemia1, agecat) %&gt;% \n    summarise_each(funs(Mean = mean, SD = sd, se=sd(.)/sqrt(n())), hb1:hb2) %&gt;% \n    mutate(Anemia.1 = case_when(anemia1 == 0 ~ \"No\",\n                                anemia1 == 1 ~ \"Yes\") %&gt;% as_factor()) %&gt;% \n    ggplot(aes(x=Anemia.1, y=hb1_Mean, fill = agecat)) +  \n    geom_errorbar(aes(ymin = hb1_Mean - 1.96*hb1_SD, ymax = hb1_Mean + 1.96*hb1_SD),\n                  position = position_dodge(0.9), width = 0.2, size = 0.8) + \n    geom_bar(stat = \"identity\", position = position_dodge(0.9), col = \"black\") +\n    labs(x = \"First Anemia Present\", y = \"Mean of First HgB (mg/dL)\",\n         title = \"Average initial HgB for first anemia and Age Categories\") +\n    theme_bw()+\n    scale_fill_brewer(name = \"Age Group\", palette = \"Dark2\",\n                      labels= c(\"10-19 yrs\", \"20-29 yrs\", \"30-39 yrs\", \"40-49 yrs\"))\n\n\nWarning: `summarise_each()` was deprecated in dplyr 0.7.0.\nℹ Please use `across()` instead.\n\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.9 Adding text as labels, etc\n\n\nCode\ntemp &lt;-\n    dataF %&gt;% \n    group_by(educ) %&gt;% \n    summarize(across(c(hb1, hb2, hb3, hb4, hb5), mean)) \n\ntemp.2 &lt;- tibble(x = rep(5,4), y = temp$hb5, z = temp$educ)\n    \ntemp %&gt;% \n    pivot_longer(col = hb1:hb5, names_to = \"Period\", values_to = \"hgb\") %&gt;% \n    ggplot(aes(x = Period, y = hgb)) +\n    geom_line(aes(color = educ, group = educ), size = 1)+\n    geom_point(aes(color = educ, group = educ, shape = educ), size =2)+\n    labs(title = \"Average Hemoglobin for each educational level\", x=NULL)+\n    scale_y_continuous(name = \"Hemoglobin (mg/dL)\", limits = c(10,16)) +\n    scale_x_discrete(labels = c(\"hb1\" = \"First \\nMeasure\",\n                                \"hb2\" = \"Second \\nMeasure\",\n                                \"hb3\" = \"Third \\nMeasure\",\n                                \"hb4\" = \"Fourth \\nMeasure\",\n                                \"hb5\" = \"Fifth \\nMeasure\"))+\n    ggrepel::geom_label_repel(data = temp.2, aes(x = x, y = y, label = z))+\n    theme_bw()+\n    theme(legend.position = \"none\",\n          plot.title = element_text(family=\"serif\",colour = \"red\", \n                               hjust =0.5, face = \"bold\", size=16))\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.10 Highlighting one line\n\n\n21.0.0.11 Adding text to special observations\n\n\nCode\ndataG &lt;- \n    dataF %&gt;% \n    mutate(is_outlier = (plt1&lt;50 | plt2&lt;100 | plt2&gt;400 | plt1&gt;400)) \n\ndataG %&gt;% \n    ggplot(aes(x = plt1, y = plt2, col = is_outlier)) + \n    geom_point() +\n    labs(x = \"First Platelet Count\",\n         y = \"Second Platelet Count\",\n         title = \"Relationship between first and second platelet counts showing possible outliers\")+\n    theme_bw()+\n    ggrepel::geom_label_repel(data = filter(dataG, is_outlier == TRUE), \n                              aes(label=id)) +\n    theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.12 Regression line with prediction and regression lines\n\n\nCode\ndataH &lt;- \n    readxl::read_xlsx(\n        \"C:/Dataset/Red cell indices against ferritin.xlsx\"\n        ) %&gt;% \n    mutate(\n        lg.fer = log(Ferritin), \n        MCH = ifelse(is.na(MCH), median(MCH, na.rm=T), MCH)\n        )\n\npreds &lt;- \n    rbind(\n        predict(lm(lg.fer ~ RBC, data = dataH), interval = \"prediction\"),\n        predict(lm(lg.fer ~ HGB, data = dataH), interval = \"prediction\"), \n        predict(lm(lg.fer ~ HCT, data = dataH), interval = \"prediction\"),\n        predict(lm(lg.fer ~ MCV, data = dataH), interval = \"prediction\"), \n        predict(lm(lg.fer ~ MCH, data = dataH), interval = \"prediction\")\n        ) %&gt;% \n    as_tibble()\n\ndataH %&gt;% \n    pivot_longer(cols=RBC:MCH, names_to = \"bld.ind\") %&gt;% \n    mutate(\n        bld.ind = factor(bld.ind, levels = c(\"RBC\", \"HGB\", \"HCT\", \"MCV\", \"MCH\"))\n        ) %&gt;% \n    arrange(bld.ind) %&gt;% \n    bind_cols(preds) %&gt;% \n    ggplot(aes(x = value)) + \n    geom_point(aes(y = lg.fer)) +\n    geom_smooth(aes(y = lg.fer), se=T, method = \"lm\", formula = y~x) +\n    geom_line(aes(y = upr), col = \"red\", linetype = \"dashed\") +\n    geom_line(aes(y = lwr), col = \"red\", linetype = \"dashed\") +\n    facet_wrap(vars(bld.ind), nrow = 2, scales = \"free\") +\n    labs(\n        title = \"Blood indices with prediction lines (red), regression line (blue) and regression error\",\n        y = \"Log of serum ferritin concentration\",\n        x = NULL)\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.13 Follow-up plot - Highly Customised\n\n\nCode\ndataF %&gt;% \n    select(id, contains(\"mcv\")) %&gt;% \n    arrange() %&gt;% \n    pivot_longer(cols = c(mcv1:mcv5)) %&gt;% \n    mutate(tms = unclass(factor(name))) %&gt;% \n    ggplot(aes(x = tms, y = value, group = id, color = avemcv)) +\n    geom_line() +\n    labs(x = NULL, \n         title = \"Variations Of MCV Over The Five Review Periods\") +\n    scale_x_continuous(breaks = c(1:5), \n                       limits = c(1,5),\n                       labels = c(\"First\",\"Second\", \"Third\", \"Fourth\", \"Fifth\"))+\n    scale_y_continuous(name= \"Mean Corposcular Hemoglobin (fl) Measurement\",\n                       breaks = seq(50, 140, 10)) +\n    scale_color_viridis_c(breaks = seq(50, 140, 10)) +\n    theme(\n        plot.background = element_rect(fill = \"black\", colour = \"black\"),\n        panel.background = element_rect(fill = \"black\", color = \"grey\"),\n        panel.grid = element_blank(),\n        axis.text = element_text(colour = \"grey\", face = \"bold\", family = \"serif\"),\n        axis.ticks = element_line(colour = \"grey\"),\n        axis.title = element_text(colour = \"grey\", face = \"bold\", family = \"serif\"),\n        plot.title = element_text(colour = \"grey\",hjust = 0.5, face = \"bold\", family = \"serif\"),\n        legend.background = element_rect(fill = \"black\", colour = \"grey\"),\n        legend.title = element_blank(),\n        legend.text = element_text(colour = \"grey\", face = \"bold\", family = \"serif\"),\n        legend.key.height = unit(0.64, \"in\")\n    )\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.14 Barchart with CIs\n\n\nCode\ndataF %&gt;% \n    mutate(avehb_cat = case_when(avehb &lt; median(avehb) ~ \"Low HB\",\n                                 avehb &gt;= median(avehb) ~ \"High HB\") %&gt;% \n               factor(levels = c(\"Low HB\", \"High HB\"))) %&gt;% \n    select(starts_with(\"mcv\"), avehb_cat) %&gt;% \n    pivot_longer(cols = c(mcv1:mcv5), values_to = \"mcv\", names_to = \"measure\") %&gt;% \n    group_by(avehb_cat, measure) %&gt;% \n    mutate(mean_mcv = mean(mcv), \n           low_mcv = mean_mcv - 1.96*sd(mcv)/sqrt(n()),\n           high_mcv = mean_mcv + 1.96*sd(mcv)/sqrt(n())) %&gt;% \n    ggplot(aes(y = mean_mcv, x = measure, fill = avehb_cat)) +\n    geom_bar(stat = \"identity\", position = position_dodge(0.9)) +\n    geom_errorbar(aes(ymin = low_mcv, ymax = high_mcv), size = 0.8, \n                  width = 0.3, \n                  position = position_dodge(0.9)) +\n    labs(y = \"Mean Corpuscular Volume\",\n         x = NULL,\n         title = \"Variation in MCV per review period (95%CI)\",\n         caption = \"Source: Data One\")+\n    scale_fill_manual(name = \"HGB Status\", values = c(\"grey\", \"grey45\"))+\n    scale_x_discrete(labels = toupper(c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\")))+\n    scale_y_continuous(limits = c(0,130), breaks = seq(0, 130, 10))+\n    theme(\n        panel.background = element_rect(colour = \"black\", fill = \"white\"),\n        plot.background  = element_rect(fill = \"grey\"),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, family = \"serif\"),\n        axis.text = element_text(face = \"bold\", family = \"serif\"),\n        axis.title = element_text(family = \"serif\", face = \"bold\"),\n        plot.caption = element_text(family = \"serif\", face = \"bold\"),\n        legend.text = element_text(family = \"serif\", face = \"bold\"),\n        legend.title = element_text(family = \"serif\", face = \"bold\")\n        )\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.15 Lollipop Plot\n\n\nCode\ndataF %&gt;% \n    summarize(across(contains(c(\"mcv\",\"hb\", \"wbc\", \"mch\")),mean)) %&gt;% \n    pivot_longer(cols = mcv1:avemchc) %&gt;% \n    filter(!(name %in% c(\"avemcv\",\"avehb\", \"avewbc\", \"avemch\", \"avemchc\"))) %&gt;%\n    mutate(name2 = str_extract(name, \"^\\\\D*\"),\n           name = toupper(name)) %&gt;% \n    ggplot(aes(x = name, y = value, color = name2))+\n    geom_segment(aes(xend = name, yend = 0), show.legend = F) +\n    geom_point(size = 6, show.legend = F) +\n    geom_text(aes(label = round(value, 1)), col = \"black\", size =2)+\n    labs(title = \"Blood indices variability for each review period\",\n         y = \"Value\",\n         x = NULL)+\n    theme_light() +\n    theme(\n        axis.text.x = element_text(angle = 90),\n        plot.title  = element_text(hjust = 0.5, face = \"bold\")\n    )\n\n\n\n\n\n\n\n\n\n\n\n21.0.0.16 Plots from the ggstatsplot package\n\n\nCode\ndataF %&gt;% \n    select(hb1, fpreg) %&gt;% \n    mutate(hb1 = round(hb1, 1)) %&gt;% \n    na.omit() %&gt;% \n    ggbetweenstats(\n      y=hb1, x=fpreg, \n      ggtheme = theme_light(),\n      bf.prior = F, \n      xlab = \"First Pregnancy\",\n      ylab = \"Hemoglobin\",\n      title = \"Relationship between first pregnancy and hemoglobin\",\n      outlier.tagging = T,\n      outlier.color = \"red\",\n      outlier.shape = 18)\n\n\nError in integrate(meta.t.like, lower = (lower - mean.delta)/scale.delta,  : \n  non-finite function value\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    ggscatterstats(x = mcv1, y = mcv2, ggtheme = theme_light())\n\n\nRegistered S3 method overwritten by 'ggside':\n  method from  \n  +.gg   GGally\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    ggbarstats(y = educ, x = fpreg, \n               ggtheme = theme_light(),\n               legend.title = \"First \\nPregnancy\",\n               xlab = \"Educational Level\",\n               bf.message = F,\n               title = \"Relationship between educational level and first pregnancy\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n  gghistostats(\n    x = hb1,\n    ggtheme = theme_classic(), \n    normal.curve = T, \n    binwidth = 1,\n    normal.curve.args = list(size = 1, col = \"red\"),\n    bin.args = list(color = \"black\", fill = \"blue\", alpha = 0.1),\n    xlab = \"Hemoglobin\", \n    title = \"Distribution of First Hemoglobins\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlm(hb1 ~ hb2 + hb3 + hb4 + hb5, data=dataF) %&gt;% \n    ggcoefstats(output = \"plot\",\n                exclude.intercept = T, \n                ggtheme = theme_light(), \n                color = \"red\") +\n    labs(y = \"Covariates\", \n         x = \"Estimates\", \n         title = \"Distribution of coefficient estimates (95% CI)\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ndataF %&gt;% \n    select(hb1, hb1, hb3, hb4, hb5, mcv1, mcv2, mcv3, mcv4, mcv5) %&gt;% \n    ggcorrmat(colors = c(\"red\",\"white\",\"blue\"), \n              ggtheme = theme_bw(),\n              matrix.type = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n22 Plots with Dates\n\n\nCode\ndataF %&gt;%\n    mutate(mari = fct_collapse(mari, \n                             \"Married\" = c(\"Married\",\"Cohabiting\"),\n                             \"Single\" = c(\"Widowed\", \"Divorced\"))) %&gt;% \n    ggplot()+\n    geom_point(aes(x = avehb, y = avehct, color = mari), show.legend = F) +\n    geom_smooth(aes(x = avehb, y = avehct), se=F, formula = y~x, \n                method = \"lm\", size = 1, alpha = .5, col = \"grey\")+\n    facet_wrap(~mari, nrow = 2, strip.position = \"left\") +\n    labs(y = \"Hematocrit (%)\", x = \"Hemoglobin (g/dl)\", \n         title = str_glue(\"Relationship between Blood hemoglobin and \",\n                          \"Hematocrit stratified by marital status\"))+\n    theme(panel.background = element_blank(),\n          panel.grid = element_blank(),\n          axis.line = element_line(),\n          strip.placement = \"outside\",\n          strip.background = element_rect(fill = \"#c1d3fe\", color = \"black\"),\n          strip.text = element_text(size = 10, face = \"bold\"),\n          text = element_text(family = \"serif\"),\n          axis.text = element_text(size = 10, face = \"bold\"),\n          axis.title = element_text(size = 10, face = \"bold.italic\"),\n          plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n22.0.0.1 Drawing free lines with legend\n\n\nCode\ndataF %&gt;% \n    mutate(hct3 = ifelse(hct3 &lt; 20, hct3 +40, hct3),\n           hct3 = ifelse(hct3 &gt; 60, hct3 - 20, hct3)) %&gt;% \n    ggplot(aes(x = hct3, y = hb3)) +\n    geom_point(color = \"grey45\") +\n    geom_smooth(aes(x = hct3, y = hb3, col =  \"Observed\"), \n                formula = y~x, method = \"lm\", se = F) + \n    geom_segment(aes(x = min(hct3), y = min(hct3/3), \n                     xend = max(hct3), yend = max(hct3/3), \n                     col =  \"Expected\"))+\n    labs(title = \"Relationship between the third HB and HCT measurements\",\n         subtitle = \"Comparison of observed  and expected regression line if HCT = 3*HB\",\n         x = \"Hematocrit (%)\", y = \"Hemoglobin (mg/dl)\", \n         color = \"Regression Line\") +\n    theme_classic()+\n    theme(plot.title = element_text(face = \"bold\"),\n          plot.subtitle = element_text(face = \"italic\"))\n\n\nWarning in geom_segment(aes(x = min(hct3), y = min(hct3/3), xend = max(hct3), : All aesthetics have length 1, but the data has 350 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.",
    "crumbs": [
      "<span style='font-weight:bold; color: black;'>Graphics</span>",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Miscellaneous</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wang, Xiaofeng, and Xinge Ji. 2020. “Sample Size Estimation in\nClinical Research.” Chest 158 (1): S12–20. https://doi.org/10.1016/j.chest.2020.03.010.",
    "crumbs": [
      "References"
    ]
  }
]